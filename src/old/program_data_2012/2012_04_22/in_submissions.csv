List of All CHI 2012 Interactivity (Juried) Final Submissions

"ID","Decision","Title","Contact given name","Contact family name","Contact Email","Document","Page length","Page size","Non-embedded fonts","Incomplete","Author list","Given name 1","Middle initial 1","Family name 1","Email 1","Primary Affiliation 1 - Institution","Primary Affiliation 1 - City","Primary Affiliation 1 - State or Province","Primary Affiliation 1 - Country","Secondary Affiliation (optional) 1 - Institution","Secondary Affiliation (optional) 1 - City","Secondary Affiliation (optional) 1 - State or Province","Secondary Affiliation (optional) 1 - Country","Given name 2","Middle initial 2","Family name 2","Email 2","Primary Affiliation 2 - Institution","Primary Affiliation 2 - City","Primary Affiliation 2 - State or Province","Primary Affiliation 2 - Country","Secondary Affiliation (optional) 2 - Institution","Secondary Affiliation (optional) 2 - City","Secondary Affiliation (optional) 2 - State or Province","Secondary Affiliation (optional) 2 - Country","Given name 3","Middle initial 3","Family name 3","Email 3","Primary Affiliation 3 - Institution","Primary Affiliation 3 - City","Primary Affiliation 3 - State or Province","Primary Affiliation 3 - Country","Secondary Affiliation (optional) 3 - Institution","Secondary Affiliation (optional) 3 - City","Secondary Affiliation (optional) 3 - State or Province","Secondary Affiliation (optional) 3 - Country","Given name 4","Middle initial 4","Family name 4","Email 4","Primary Affiliation 4 - Institution","Primary Affiliation 4 - City","Primary Affiliation 4 - State or Province","Primary Affiliation 4 - Country","Secondary Affiliation (optional) 4 - Institution","Secondary Affiliation (optional) 4 - City","Secondary Affiliation (optional) 4 - State or Province","Secondary Affiliation (optional) 4 - Country","Given name 5","Middle initial 5","Family name 5","Email 5","Primary Affiliation 5 - Institution","Primary Affiliation 5 - City","Primary Affiliation 5 - State or Province","Primary Affiliation 5 - Country","Secondary Affiliation (optional) 5 - Institution","Secondary Affiliation (optional) 5 - City","Secondary Affiliation (optional) 5 - State or Province","Secondary Affiliation (optional) 5 - Country","Given name 6","Middle initial 6","Family name 6","Email 6","Primary Affiliation 6 - Institution","Primary Affiliation 6 - City","Primary Affiliation 6 - State or Province","Primary Affiliation 6 - Country","Secondary Affiliation (optional) 6 - Institution","Secondary Affiliation (optional) 6 - City","Secondary Affiliation (optional) 6 - State or Province","Secondary Affiliation (optional) 6 - Country","Given name 7","Middle initial 7","Family name 7","Email 7","Primary Affiliation 7 - Institution","Primary Affiliation 7 - City","Primary Affiliation 7 - State or Province","Primary Affiliation 7 - Country","Secondary Affiliation (optional) 7 - Institution","Secondary Affiliation (optional) 7 - City","Secondary Affiliation (optional) 7 - State or Province","Secondary Affiliation (optional) 7 - Country","Given name 8","Middle initial 8","Family name 8","Email 8","Primary Affiliation 8 - Institution","Primary Affiliation 8 - City","Primary Affiliation 8 - State or Province","Primary Affiliation 8 - Country","Secondary Affiliation (optional) 8 - Institution","Secondary Affiliation (optional) 8 - City","Secondary Affiliation (optional) 8 - State or Province","Secondary Affiliation (optional) 8 - Country","Given name 9","Middle initial 9","Family name 9","Email 9","Primary Affiliation 9 - Institution","Primary Affiliation 9 - City","Primary Affiliation 9 - State or Province","Primary Affiliation 9 - Country","Secondary Affiliation (optional) 9 - Institution","Secondary Affiliation (optional) 9 - City","Secondary Affiliation (optional) 9 - State or Province","Secondary Affiliation (optional) 9 - Country","Given name 10","Middle initial 10","Family name 10","Email 10","Primary Affiliation 10 - Institution","Primary Affiliation 10 - City","Primary Affiliation 10 - State or Province","Primary Affiliation 10 - Country","Secondary Affiliation (optional) 10 - Institution","Secondary Affiliation (optional) 10 - City","Secondary Affiliation (optional) 10 - State or Province","Secondary Affiliation (optional) 10 - Country","Contact Author Name","Contact Author Email Address","Stand-alone","Abstract","References","Keywords","(required) Document in Source (Word, LaTeX, etc.)","(optional) Thumbnail Image","(optional) Video Figure","Program Description","Summary of Changes","ACM Classification","Content Complete (AC use only)","Format Complete (Publications chair use only)","Program Number","ACM General Terms (No Longer Required)","Last Update","Notes"

"in102","A","Touché: Enhancing Touch Interaction on Humans, Screens, Liquids, and Everyday Objects","Munehiko","Sato","munehiko@acm.org","","","","","","Munehiko Sato, Ivan Poupyrev, Chris Harrison","Munehiko","","Sato","munehiko@acm.org","Disney Research, Pittsburgh","Pittsburgh","Pennsylvania","United States","The University of Tokyo","Tokyo","","Japan","Ivan","","Poupyrev","hello@ivanpoupyrev.com","Disney Research, Pittsburgh","Pittsburgh","Pennsylvania","United States","","","","","Chris","","Harrison","chris.harrison@cs.cmu.edu","Disney Research, Pittsburgh","Pittsburgh","Pennsylvania","United States","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  3 23:05",""
"in107","A","Herzfassen. A Responsive Object.","Monika","Hoinkis","hello@monikahoinkis.de","inpaper107.pdf","4","letter","Helvetica-Bold","","Monika Hoinkis","Monika","","Hoinkis","hoinkis@fh-potsdam.de","University of Applied Sciences Potsdam","Potsdam","Berlin-Brandenburg","Germany","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Monika Hoinkis","hoinkis@fh-potsdam.de","yes","'Herzfassen' is a self-contained kinetic object that uses physical computing and biometric data to provide a highly aesthetic and sensual experience while still having the outer appearance of an ordinary everyday object. A metal bowl filled with water visualizes the human heartbeat through vibration and according patterns in the water surface. The title 'Herzfassen' derives from the german expression for 'to take heart' thus hints to the haptic and emotional experience with the object. \  \ This paper describes aim and design of the piece, comprising construction, technical function, as well as the interaction cycle respectively the object's dramaturgy. Further, it reports on audience's joyful and emotional experiences with the object within past exhibitions as display and use hence human contact is the main purpose of 'Herzfassen'.","1. Csikszentmihalyi, M. (1990), Flow: The Psychology of Optimal Experience, New York: Harper & Row. \ 2. Gaver, W. W., Beaver, J., Benford, S. (2003), Ambiguity as a Resource for Design, CHI’03, New York: ACM Press. \ 3. Marx, K., The Economic and Philosophic Manuscripts of 1844, online: http://www.marxists.org/ archive/marx/works/1844/manuscripts/preface.htm \ 4. Norman, D. (1988), The Psychology of Everyday Things, New York: Basic Books. \ 5. Rosa, H. (2005), Beschleunigung. Die Veränderung der Zeitstrukturen in der Moderne, Berlin: Suhrkamp. \ ","interaction design; awareness design; design and emotion; information aesthetics; physical computing","infile107-1.odt","infile107-2.jpg","infile107-3.mp4","'Herzfassen' is a kinetic object with the appearance of an everyday item: a metal bowl filled with water visualizes a person's heartbeat through vibration and according patterns in the water surface.","grammar and spelling corrections ","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Haptic I/O  \ ","","FormatComplete","1","","Feb 22 15:15",""
"in112","A","EyeRing: An Eye on a Finger","Suranga","Nanayakkara","suranga@sutd.edu.sg","inpaper112.pdf","4","letter","","","Suranga Nanayakkara, Roy Shilkrot, Pattie Maes","Suranga","","Nanayakkara","suranga@sutd.edu.sg","Singapore University of Technology and Design","Dover","","Singapore","MIT Media Lab","Cambridge","Massachusetts","United States","Roy","","Shilkrot","roys@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","Pattie","","Maes","pattie@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Suranga Nanayakkara","suranga@sutd.edu.sg","yes","Finger-worn devices are a greatly underutilized form of interaction with the surrounding world. By putting a camera on a finger we show that many visual analysis applications, for visually impaired people as well as the sighted, prove seamless and easy. We present EyeRing, a ring mounted camera, to enable applications such as identifying currency and navigating, as well as helping sighted people to tour an unknown city or intuitively translate signage. The ring apparatus is autonomous, however our system also includes a mobile phone or computation device to which it connects wirelessly, and an earpiece for information retrieval. Finally, we will discuss how different finger worn sensors may be extended and applied to other domains.","1. Merrill, D. and Maes, P. Augmenting looking, pointing and reaching gestures to enhance the searching and browsing of physical objects. In Proc. Pervasive'07, (2007) 1–18. \ 2. Lee, J., Lim, S. H., Yoo, J. W., Park, K. W., Choi, H. J. and Park, K. H. A ubiquitous fashionable computer with an i-Throw device on a locationbased service environment. In Proc. AINAW’07, 2 (2007), 59-65. \ 3. Rekimoto, J. Gesturewrist and gesturepad: Unobtrusive wearable interaction devices. In Proc. ISWC '01, (2001), 21-27. \ 4. Chatterjee R. and Matsuno, F. Design of A Touch Sensor Based Single Finger Operated Wearable User-Interface Terminal. In Proc. SICE-ICASE’06, (2006), 4142-4147. \ 5. Chi, L. Y., Ryskamp, R. A., Gomez, L. R. P., Ho, H. and Brin, S. Seeing with your hand. Google Patents, 2011. \ 6. McNeill, D. Language and gesture, Cambridge University Press, 2000. \ 7. Hartley, R. and Zisserman, A. Multiple view geometry in computer vision, Cambridge University Press, 2000. \ 8. Csurka, G., Dance, C.., Fan, L., Willamowski, J. and Bray, C. Visual categorization with bags of keypoints. In Proc. ECCV'04, (2004), 59-74. \ 9. Van de Sande, K., Gevers, T. and Snoek, C.. Evaluation of color descriptors for object and scene recognition. In Proc. CVPR’08, (2008), 1-8.","Pointing-based Interaction; Wearable Assistive Device; Intuitive Interfaces","infile112-1.doc","infile112-2.jpg","","EYERING: a finger-worn personal assistant with  visual analysis capabilities, that aid visually impaired people as well as the sighted.","The authors would like to thank the associate editor and reviewers for their valuable comments and very much appreciate their time and effort. \  \ We have made some minor adjustment to make the paper more readable.  \  \ Comments of the R2 (who is blind) gave us useful insights and we will include them in our future work.","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems \ I.4.8 [Image Processing And Computer Vision]: Scene Analysis \ K.4.2 [Computers And Society]: Social Issues \ ","","FormatComplete","2","","Jan  6 21:34",""
"in113","A","Combiform: Beyond Co-attentive Play, a Combinable Social Gaming Platform","Edmond","Yee","eyee@usc.edu","inpaper113.pdf","4","letter","","incomplete","Edmond Yee, Josh Joiner, Tai An, Andrew Dang","Edmond","","Yee","eyee@usc.edu","University of Southern California","Los Angeles","California","United States","","","","","Josh","","Joiner","jjoiner@usc.edu","University of Southern California","Los Angeles","California","United States","","","","","Tai","","An","taian@usc.edu","University of Southern California","Los Angeles","California","United States","","","","","Andrew","","Dang","adang@usc.edu","University of Southern California","Los Angeles","California","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Edmond Yee","eyee@usc.edu","yes","Combiform is a novel digital gaming console featuring four combinable handheld controllers. It is a new and unique tangible gaming interface that stresses the importance of co-located, co-attentive social interactions among players. In particular, multiple players may freely combine and lock together their handheld game controllers, thereby creating a very flexible collective and transformable tangible interface. Combiform emphasizes social interaction through controller-to-controller contact. The platform and its 10 games introduce novel, tangible and physical co-attentive experiences that are not found in traditional co-located gaming platforms using ‘embodied’ controllers (e.g. Nintendo Wii and Microsoft Kinect). Based on observations, this new interactive technique has successfully transformed typical co-located social play experiences into a multisensory physical activity.","[1] de Kort, Y.A.W., IJesselsteijn, W.A., & Gajadhar, B.J. (2007). People, places and play: A research framework for digital game experience in a socio-spatial context. DiGRA 2007 Proceedings ""Situated Play"", pp. 823-830. \ [2] Gajadhar, B. J, de Kort, Y. A. W., & IJsselsteijn, W. A. (2009). Rules of Engagement: Influence of Co-Player Presence on Player Involvement in Digital Games. International Journal of Gaming and Computer-Mediated Simulations, 1(3), 14-27. \ [3] Gajadhar, B., de Kort, Y.A.W., and IJsselsteijn, W.A. (2008). Shared fun is doubled fun: player enjoyment as a function of social setting. In P. Markopoulos, B. de Ruyter, W. IJsselsteijn, & D. Rowland, Fun and Games (pp. 106-117). New York: Springer.  \ [4] Nielsen Interactive Entertainment (2005). Video gamers in Europe. Research Report Prepared for the Interactive Software Federation of Europe (ISFE). \ [5] Prior Art Links \ [6] Acceleroto Air Hockey http://www.acceleroto.com/airhockey/ \ [7] C.G.C Johann Sebastian Joust! http://gutefabrik.com/joust.html \ [8] Hasbro™ Bop it!® http://www.hasbro.com/games/en_us/bopit/  \ [9] Microsoft® Kinect™ http://www.xbox.com/en-US/kinect \ [10] Nintendo® Wii™ http://www.nintendo.com/wii  \ [11] Hasbro™ Twister® http://www.hasbro.com/games/en_US/twister/  \ [12] Vanden Abeele, V., Gajadhar, B.J., & de Schutter, B. (2009). Gaming Naturally is more Fun Together: the Influence of Controller Type on Player Experience. ACE 2009 \ [13] Video Links \ [14] Blow-it up http://youtu.be/dGkWyUsTAjU  \ [15] Blow-it up http://youtu.be/AVaH5_MyWOw?hd=1  \ [16] My Light, My Game http://youtu.be/x7Kq0Ubazo4  \ [17] T.A.I http://youtu.be/yKuzPV_J8-A   \ [18] Agent Purple http://youtu.be/a7nXlfVrgLM \ [19] Pop Quiz http://youtu.be/7kpB32bsosc?hd=1 \ [20] Firewall http://youtu.be/7a8BfBYBNWU?hd=1  \ [21] Match! http://youtu.be/Gen72As4rqI  \ [22] For Here, To Go http://youtu.be/ej7ZZ0rmWC0?hd=1  \ [23] Unison, http://youtu.be/eCjvmu6xw1o \ [24] Switch http://youtu.be/1MmbDTTRtCo (2 Players version) \ [25] Switch http://youtu.be/ytZ5ttFE7xw (4 Players version) \ [26] Promotional Video http://youtu.be/r92cDygrDiM?hd=1  \ ","game controller; co-attentive; co-located; social gaming; social presence; tangible user interface; joint gesture","infile113-1.doc","infile113-2.jpg","infile113-3.mp4","Combiform is a gaming console that enables players to combine their \ controllers, opening up a new level of collaborative and competitive \ experiences where body-to-body and body-to-screen interactions happen in \ parallel.","","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Input devices and strategies \ ","","FormatComplete","2","","Feb 21 06:33",""
"in114","A","Pygmy: A Ring-like Anthropomorphic Device That Animates The Human Hand","Masayasu","Ogata","ogatite@gmail.com","inpaper114.pdf","4","letter","","","Masayasu Ogata, Yuta Sugiura, Hirotaka Osawa, Michita Imai","Masayasu","","Ogata","ogatite@gmail.com","Keio University","Yokohama","Kanagawa","Japan","","","","","Yuta","","Sugiura","yuta.sugiura@gmail.com","Keio University","Yokohama","Kanagawa","Japan","","","","","Hirotaka","","Osawa","osawa@ayu.ics.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","Michita","","Imai","michita@ayu.ics.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Masayasu Ogata","ogatite@gmail.com","yes","Pygmy is an anthropomorphic device that magnifies hand expressions. It is based on the concept of hand anthropomorphism and it uses finger movements to create the anthropomorphic effect. Wearing the device is similar to having eyes and a mouth on the hand; the wearer’s hand spontaneously expresses their emotions. Interactive manipulation by controllers and sensors make the hand look animated.","1. Desmond Morris: Bodytalk: The Meaning of Human Gestures. Crown, 1995. \ 2. David McNeill: Hand and Mind, Univ of Chicago Press, 1992. \ 3. Liddell, S. K. Spatial representations in discourse: comparing spoken and signed language. Lingua 98, pp. 145-167, 1996. \ 4. Hand painting, Guido Daniele, retrieved from http://www.guidodaniele.com/ \ 5. Kostov, V., Ozawa, J., Matsuura, S., Wearable accessory robot for context aware apprise of personal information. In Proc. RO-MAN 2004, pp. 595-600. \ 6. Tsumaki, Y., Fujita, Y., Kasai, A., Sato, C., Nenchev, D.N., Uchiyama, M., Telecommunicator: a novel robot system for human communications. In Proc. RO-MAN 2002, pp. 35-40. \ 7. Nagao, Y., Yamaguchi, H., Harada, K., Omura, K., Inakage, M., Whadget: Interactive Animation using Personification Gesture Expression of Hand. SIGGRAPH 2008 Posters. \ 8. Sugiura, Y., Fernando, C.L., Withana, A.I., Kakehi, G., Sakamoto, D., Sugimoto, M., Inami, M., Igarashi, T., Inakage, M., An Operating Method for a Bipedal Walking Robot for Entertainment. ACM SIGGRAPH Asia 2009 Emerging Technologies, pp. 79-79. \ 9. Osawa, H., Mukai, J., Imai, M., ""Display Robot"" Interaction between Humans and Anthropomorphized Objects. In Proc. RO-MAN 2007, pp. 451-456. \ 10. Nikodama, Ryota Kuwakubo, retrieved from http://www.mediascot.org/lefttomyowndevices/ryotaku wakubo/ Figure 7. Different gestures for animals: a face, an elephant, a bird, a crab, a fox, a butterfly, an octopus, and a giraffe \ ","Wearable Robot, Finger Expression, Anthropomorphism, Ubiquitous Computing","infile114-1.pdf","infile114-2.jpg","infile114-3.mp4","Pygmy is an anthropomorphic device that magnifies hand expressions. Wearing the device is similar to having eyes and a mouth on the hand; the wearer’s hand spontaneously expresses their emotions.","Though reviewers gave me several advices, as the paper in Interactivity I judge there is no revise required.","H5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous.","","FormatComplete","1","","Feb 22 15:16",""
"in115","A","Interactive Block Device System with Pattern Drawing Capability on Matrix LEDs","Junichi","Akita","akita@is.t.kanazawa-u.ac.jp","inpaper115.pdf","4","letter","","","Junichi Akita","Junichi","","Akita","akita@is.t.kanazawa-u.ac.jp","Kanazawa University","Kanazawa","Ishikawa","Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Junichi Akita","akita@is.t.kanazawa-u.ac.jp","yes","This paper describes an interactive block device with dot-matrix LED, with capabilities of drawing patterns by lights, physical and signal connections of devices with magnet connectors, and interaction using accelerometer and sounder. The pattern drawing is implemented by the technique of using matrix LEDs as light sensor array, which saves the additional hardware cost. Three applications of this block device, pattern morphing, function definable block, and musical box, are also described.","1. Gorbet, M.G., Orth, M., and Ishii, H., Triangles: Tangible Interface for Manipulation and Exploration of Digital Information Topography, Proc. of CHI'98 (1998) 49-56. \ 2. Lee, J., Kakehi, Y., and Naemura, T., Bloxels: Glowing Blocks as Volumetric Pixels, ACM SIGGRAPH 2009 Emerging Technologies (2009), ET 331. \ 3. Suzuki, H., and Kato, H., AlgoBlock: a Tangible Programming Language for Collaborative Learning, Proc. of ED-Media (1994), 770. \ 4. Akita, J., Matrix LED Unit with Pattern Drawing and Extensive Connection, ACM SIGGRAPH 2010 (2010). \ 5. Hudson, S., Using Light Emitting Diode Arrays As Touch Sensitive Input And Output Devices, Proc. UIST2004 (2004), 287-290. \ ","Block Device; Pattern Drawing; Function Definition","infile115-1.doc","","infile115-3.m4v","Draw on dot-matrix LED by light, connect them, and play! \ ","Typo correction (piezzo -> piezo). \ Added development status of Arduino-compatible version hardware platform. \ ","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ ","","FormatComplete","2","","Dec 28 07:26",""
"in116","A","Sifteo Cubes","Emily","Sun","emily@sifteo.com","inpaper116.pdf","4","letter","Helvetica,Bold Arial","","David Merrill, Emily Sun, Jeevan Kalanithi","David","","Merrill","dave@sifteo.com","Sifteo, Inc.","San Francisco","California","United States","","","","","Emily","","Sun","emily@sifteo.com","Sifteo, Inc.","San Francisco","California","United States","","","","","Jeevan","","Kalanithi","jeevan@sifteo.com","Sifteo, Inc.","San Francisco","California","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Emily Sun","emily@sifteo.com","yes","In this paper we describe Sifteo cubes™, a tangible and graphical user interface platform. We note several patterns of use observed in homes and schools and identify design recommendations for display utilization on distributed interfaces like Sifteo cubes. Additionally we discuss the process of commercializing the research prototype to create a marketable game system.","1. Horn, M., Solovey, E., Crouser, R., and Jacob, R. Comparing Tangible and Graphical Programming Interfaces for use in Informal Science Education. In Proc. CHI'09, ACM Press (2009). \ 2. Jordà, S., Geiger, G., Alonso, M., Kaltenbrunner, M. The reacTable: exploring the synergy between live music performance and tabletop tangible interfaces. In Proc. TEI '07, pp. 139-146, ACM Press (2007). \ 3. Merrill, D. Interaction with Embodied Media. Ph.D. thesis. Program in Media Arts and Sciences, MIT (2009). \ 4. Merrill, D., Kalanithi, J., Maes, P. Siftables: Towards Sensor Network User Interfaces. In Proc. TEI’07, Louisiana (2007). Mather, B.D. Making up titles for conference papers. Ext. Abstracts CHI 2000, ACM Press (2000), 1-2. \ 5. Norman, D. Things That Make Us Smart: Defending Human Attributes in the Age. Basic Books, New York (1993). \ 6. Zuckerman, O., Grotzer, T., Leahy, K. Flow blocks as a conceptual bridge between understanding the structure and behavior of a complex causal system. In Proc. ICLS '06, pp. 880-886, ICLS (2006). \ ","Sifteo cubes; tangible user interfaces","infile116-1.doc","infile116-2.jpg","infile116-3.mov","Sifteo cubes™ are a tangible and graphical user interface platform. We note several patterns of use, identify design recommendations for display utilization, and discuss the process of commercializing the research prototype.","Paragraph added on commercialization of Sifteo cubes","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ K.4.0 [Computers and Society] : General","","FormatComplete","1","","Feb 23 11:39",""
"in117","A","SONIK SPRING","J Tomas","Henriques","henriqjt@buffalostate.edu","inpaper117.pdf","4","letter","","","J Tomas Henriques","J Tomas","","Henriques","henriqjt@buffalostate.edu","Buffalo State College","Buffalo","New York","United States","CESEM UNL","Lisbon","","Portugal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Tomas Henriques","henriqjt@buffalostate.edu","yes","The Sonik Spring is an interface for real-time control of sound that directly links gestural motion and kinesthetic feedback to the resulting musical experience. The interface consists of a 15-inch spring with unique flexibility, which allows multiple degrees of variation in its shape and length. These are at the core of its expressive capabilities and wide range of functionality as a sound processor. \ ","1. Wanderley, M.M., Orio, N. Evaluation of Input Devices for Musical Expression: Borrowing Tools from HCI. Computer Music Journal 26, 3, (2002), 62-76. \ 2. Paradiso, J. The brain opera technology: New instruments and gestural sensors for musical interaction and performance. Journal of New Music Research 28, 2 (1999), 130–149. \ 3. Singer, E. Sonic banana: A novel bend-sensor-based MIDI controller. In Proc. NIME 2003, (2003), 85-88. \ 4. Lebel, D., Malloch, J. The G-Spring Controller. In Proc. NIME 2006, (2006), 220-221. \ 5. MIDItron Wireless Interface http://www.miditron.com \ 6. Henriques, T. Meta-EVI: Innovative Performance Paths with a Wind Controller. In Proc. NIME 2008, (2008), 307-310. Figure 8. Joystick attached to coil Figure 9. Fully compressing the Sonik Spring \ ","Digital music instrument; gestural control of sound; sound and music computing","infile117-1.doc","","infile117-3.mov","The Sonik Spring is an interface for real-time control of sound that directly links gestural motion and kinesthetic feedback to the resulting musical experience.","Only one reviewer suggested changes, commenting that it would be interesting to know if the Sonik Spring can attain virtuoso performance levels. I took this point into consideration by writing that the interface allows the user to achieve different levels of performance skills. \  \ ","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ H.5.5 [Information Interfaces And Presentation]: Sound and Music   \ Computing","","FormatComplete","1","","Feb 22 01:16",""
"in121","A","360° Panoramic Overviews for Location-Based Services","Alessandro","Mulloni","mulloni@icg.tugraz.at","","","","","","Alessandro Mulloni, Hartmut Seichter, Andreas Dünser, Patrick Baudisch, Dieter Schmalstieg","Alessandro","","Mulloni","mulloni@icg.tugraz.at","Graz University of Technology","Graz","","Austria","","","","","Hartmut","","Seichter","seichter@icg.tugraz.at","Graz University of Technology","Graz","","Austria","","","","","Andreas","","Dünser","andreas.duenser@hitlabnz.org","HIT Lab NZ","Christchurch","","New Zealand","","","","","Patrick","","Baudisch","patrick.baudisch@hpi.uni-potsdam.de","Hasso Plattner Institute","Potsdam","","Germany","","","","","Dieter","","Schmalstieg","schmalstieg@tugraz.at","Graz University of Technology","Graz","","Austria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 07:39",""
"in126","A","AMARA: THE AFFECTIVE MUSEUM OF ART RESOURCE AGENT","S. Joon","Park","sp347@drexel.edu","inpaper126.pdf","4","letter","Helvetica,Bold Arial","","S. Joon Park, Gunho Chae, Craig MacDonald, Robert Stein, Susan Wiedenbeck, Jungwha Kim","S. Joon","","Park","sp347@drexel.edu","Drexel University","Philadelphia","Pennsylvania","United States","","","","","Gunho","","Chae","agarpe@kaist.ac.kr","KAIST","Daejeon ","Choongchung-nam-do ","Korea, Republic of","","","","","Craig","","MacDonald","cmm353@drexel.edu","Drexel University","Philadelphia","Pennsylvania","United States","","","","","Robert","","Stein","RStein@imamuseum.org","The Indianapolis Museum of Art","Indianapolis","Indiana","United States","","","","","Susan","","Wiedenbeck","sw53@drexel.edu","Drexel University","Philadelphia","Pennsylvania","United States","","","","","Jungwha","","Kim","jwkim21@kaist.ac.kr","KAIST","Daejeon ","Choongchung-nam-do ","Korea, Republic of","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","S. Joon Park","sp347@drexel.edu","yes","This interactive system uses an embedded agent for question-based art collection search on the platform of the Indianapolis Museum of Art website. Unlike a keyword search box, AMARA helps users browse and search for artwork by asking them simple questions with answers mapped to social tags. Thus, the users do not need to be subject matter experts to input specific terms to search. In designing AMARA, we focused on creating an enjoyable browsing experience and helping users to determine their known and unknown art preferences. ","1. Beale, R. and Creed, C. Affective interaction: How emotional agents affect users. Int’l J. of HumanComputer Studies 67 (2009), 755-776. \ 2. Blythe, M., Wright, P. McCarthy, J. and Bertelsen, O.W. Theory and method for experience centered design. In Proc. CHI 2006, ACM Press (2006) \ 3. Chae, G.H. and Kim, J. Can social tagging be a tool to reduce the semantic gap between curators and audiences? In Proc. M&W2011, Archives and Museum Informatics (2011) \ 4. Dehn, D.M. and Mulken, S.V. The impact of animated interface agents: a review of empirical research. Int’l J. of Human-Computer Studies 52 (2000), 1-22. \ 5. Johnson, D., Gardner, J. and Wiles, J. Experience as a moderator of the media equation: the impact of flattery and praise. Int’l J. of Human-Computer Studies 61 (2004), 237-258. \ 6. Marty, P.F., Sayre, S. and Wiles, J. Personal digital collections: Involving users in the co-creation of digital cultural heritage, 285-304. In Handbook of research on technologies and cultural heritage. IGI Global, Hershey, PA, USA, 2011. \ 7. Rayward, W.B., Twidale, M.B. From Docent to Cyberdocent: Education and Guidance in Virtual Museum. Archives and Museum Informatics 13, 1(1999), 23-53. \ 8. Smith, G. Tagging: People-powered metadata for the social web. New Riders, Berkeley, CA, USA, 2008. \ 9. Trant, J. and Wyman, B. Investigating social tagging and folksonomy in art museums with Steve Museum. In WWW’06 (2006) figure 4. AMARA is smiling. Flash animation effects have been applied to AMARA so she makes different facial expressions and gestures. \ ","Agent; emotion; art collection search; online museum ","infile126-1.docx","","infile126-3.mp4","Design of a novel affective art collection search agent ","We have made changes on reviewers' comments about the future study on improving the search algorithm. As our system has been upgraded since the initial submission, we also made some changes for the ""Experience"" section to reflect the user experience of the current system. Another reviewer showed concerns about the questions that the agent asks. We have addressed in the Future Work section that we will continuously craft new questions (remove questions that may not be relevant).    ","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ ","","FormatComplete","2","","Jan 14 14:51",""
"in127","A","Communitysourcing: Engaging Local Crowds to Perform Expert Work Via Physical Kiosks","Kurtis","Heimerl","kheimerl@cs.berkeley.edu","","","","","","Kurtis Heimerl, Brian Gawalt, Kuang Chen, Tapan Parikh, Björn Hartmann","Kurtis","","Heimerl","kheimerl@cs.berkeley.edu","University of California, Berkeley","Berkeley","California","United States","","","","","Brian","","Gawalt","gawalt@eecs.berkeley.edu","University of California, Berkeley","Berkeley","California","United States","","","","","Kuang","","Chen","kuangc@eecs.berkeley.edu","UC Berkeley","Berkeley","California","United States","","","","","Tapan","","Parikh","parikh@berkeley.edu","University of California, Berkeley","Berkeley","California","United States","","","","","Björn","","Hartmann","bjoern@eecs.berkeley.edu","University of California, Berkeley","Berkeley","California","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  4 02:02",""
"in129","A","Rewarding the original: Explorations in joint user-sensor motion spaces","John","Williamson","jhw@dcs.gla.ac.uk","","","","","","John Williamson, Roderick Murray-Smith","John","","Williamson","jhw@dcs.gla.ac.uk","University of Glasgow","Glasgow","","United Kingdom","","","","","Roderick","","Murray-Smith","rod@dcs.gla.ac.uk","University of Glasgow","Glasgow","","United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  5 11:18",""
"in130","A","ShoeSense: A New Perspective on  Hand Gestures and Wearable Applications","Gilles","Bailly","gillesbailly1@gmail.com","inpaper130.pdf","10","letter","","incomplete","Gilles Bailly, Jörg Müller, Michael Rohs, Daniel Wigdor, Sven Kratz, Dennis Guse","Gilles","","Bailly","gillesbailly1@gmail.com","Quality and Usability Lab, Telekom Innovation Laboratories, TU Berlin","Berlin","","Germany","","","","","Jörg","","Müller","joerg.mueller@tu-berlin.de","Quality and Usability Lab, Telekom Innovation Laboratories, TU Berlin","Berlin","Berlin","Germany","","","","","Michael","","Rohs","michael.rohs@ifi.lmu.de","University of Munich","Munich","","Germany","","","","","Daniel","","Wigdor","dwigdor@dgp.toronto.edu","University of Toronto","Toronto","Ontario","Canada","","","","","Sven","","Kratz","koffi82@gmail.com","University of Munich","Munich","","Germany","","","","","Dennis","","Guse","dennis.guse@alumni.tu-berlin.de","Quality and Usability Lab, Telekom Innovation Labs, TU Berlin","Berlin","","Germany","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Gilles Bailly","gillesbailly1@gmail.com","no","When the user is engaged with a real-world task it can be inappropriate or difficult to use a smartphone. To address this concern, we developed ShoeSense, a wearable system consisting in part of a shoe-mounted depth sensor pointing upward at the wearer. ShoeSense recognizes relaxed and discreet as well as large and demonstrative hand gestures. In particular, we designed three gesture sets (Triangle, Radial, and Finger-Count) for this setup, which can be performed without visual attention. The advantages of ShoeSense are illustrated in five scenarios: (1) quickly performing frequent operations without reaching for the phone, (2) discreetly performing operations without disturbing others, (3) enhancing operations on mobile devices, (4) supporting accessibility, and (5) artistic performances. We present a proof-of-concept, wearable implementation based on a depth camera and report on a lab study comparing social acceptability, physical and mental demand, and user preference. A second study demonstrates a 94-99% recognition rate of our recognizers.","1. Adidas Megalizer: http://popsop.com/44586 \ 2. Amft O. and Lukowicz, P. 2009. From Backpacks to Smartphones: Past, Present, and Future of Wearable Computers. IEEE Pervasive Computing 8, 3 (July 2009), 8-13. \ 3. Apple Inc., Take Nike + iPod on your Run. In Apple. As of 2011.9.9 from http://www.apple.com/ipod/nike/run.html \ 4. Ashbrook, D. L., Clawson, J., Lyons, K., Patel, N., Starner, T. 2008. Quickdraw: the impact of mobility and on-body placement on device access time. CHI '08, 219-222. \ 5. Augsten, T., Kaefer, K., Meusel, R., Fetzer, C. Kanitz, D. .Stoff, T., Becker, T., Holz, C., Baudisch, P. 2010. Multitoe: high-precision interaction with back-projected floors based on high-resolution multitouch input. ACM UIST'10, 209-218. \ 6. Bailly, G. Lecolinet, E, Nigay, L.. 2008. Flower menus: a new type of marking menu with large menu breadth, within groups and efficient expert mode memorization. AVI'08, 15-22. \ 7. Bailly, G., Lecolinet, E., Guiard, Y. 2010. Finger-count & radial-stroke shortcuts: 2 techniques for augmenting linear menus on multi-touch surfaces. ACM CHI '10, 591-594. \ 8. Bailly, G., Walter, R., Müller, J., Ning, T., Lecolinet, E. 2011. Comparing Free Hand Menu Techniques for Distant Displays using Linear, Marking and Finger-Count Menus. IFIP INTERACT'11. 248-262. \ 9. Baudel T., Beaudouin-Lafon, M. 1993. Charade: remote control of objects using free-hand gestures. Commun. ACM 36, 7, 28-35. \ 10. Benko, H. and Wilson, A. D. (2010). Multi-Point Interactions with Immersive Omnidirectional Visualizations in a Dome. ACM ITS '10. 1928. \ 11. Brett, B., MIT student arrested at Logan in bomb scare. The Boston Globe. 2011.9.9 from http://www.boston.com/news/ globe/city_region/breaking_news/2007/09/mit_student_arr.html. \ 12. Buxton, W. 1986. Chunking and phrasing and the design of humancomputer dialogues, IFIP WCG, 475-480. \ 13. Camurri, A., Mazzarino, B., Ricchetti, M., Timmers, R. Volpe, G. 2004. Multimodal analysis of expressive gesture in music and dance performances. Gest.-based. Com. in Hum. -Comp. Int. vol. 2915. 357-358 \ 14. Conseil, S. Bourennane, S., Martin, L. 2007 Comparison of Fourier Descriptors and Hu Moments for Hand Posture Recognition. EUSIPCO’07. \ 15. Fitzpatrick, P. and Kemp C. C. 2003. Shoes as a Platform for Vision. IEE ISWC '03. 231-233. \ 16. Foxlin, E. M. 2002. Generalized architecture for simultaneous localization, auto-calibration, & map-building. IEEE/RJS. Vol.1. 527-533. \ 17. Guernsey, L., At Airport Gate, a Cyborg Unplugged. In The New York Times. As of 2011.9.9, from http://www.nytimes.com /2002/03/14/technology/circuits/14MANN.html. \ 18. Gustafson, S., Bierwirth, D. Baudisch, P. 2010. Imaginary interfaces: spatial interaction with empty hands and without visual feedback. ACM UIST'10, 3-12. \ 19. Harrison, C. and Hudson, S.E. 2009 Abracadabra: wireless, highprecision, and unpowered finger input for very small mobile devices. ACM UIST’09, 121–124. \ 20. Harrison, C. Tan, D., Morris, D. 2010. Skinput: appropriating the body as an input surface. ACM CHI '10, 453-462. \ 21. Healey, J., Picard, R. 1998. Startlecam: A cybernetic wearable camera, Tech. Rep. 468, October 1998. \ 22. Hedge, A., Anthropometry and Workspace Design, in DEA 325/651. 2002, Cornell. \ 23. Hendry J, 1984. Shoes: the early learning of an important distinction in Japanese society, Europe Interprets Japan, 215-222 \ 24. Higuchi, H. and Nojima, T. 2010 Shoe-shaped i/o interface. ACM UIST '10. 423-424. \ 25. Hinckley, K. 2007. Input technologies and techniques. Chapter 9. In The human-computer interaction handbook, 2nd edition. \ 26. Hudson S., Harrison, C, Harrison, B., LaMarca, A. 2010. Whack gestures: inexact and inattentive interaction with mobile devices. ACM TEI '10. 109-112. \ 27. ISO/DIS 9241-9. 2000. Ergonomic requirements for office work with visual display terminals (VDTs) - Part 9. ISO. \ 28. Kratz, S. Rohs, M. 2009. Hoverflow: exploring around-device interaction with IR distance sensors. ACM MobileHCI'09. 1-4. \ 29. Krupenkin, T., Taylor, J. 2011. Reverse electrowetting as a new approach to high-power energy harvesting. Nat. Commun. 2:448 \ 30. Kurtenbach, G., Buxton, W. 1991. Issues in combining marking and direct manipulation techniques. ACM UIST'91, 137-144. \ 31. Kymissis, J., Kendall, C., Paradiso, J., Gershenfeld, N. 1998. Parasitic Power Harvesting in Shoes. ISWC'98, 132-139. \ 32. Lepinski, G. J., Grossman, T., Fitzmaurice, G. 2010. The design and evaluation of multitouch marking menus. ACM CHI’10. 2233-2242. \ 33. Loclair, C., Gustafson, S., Baudisch, P. 2010. PinchWatch: A Wearable Device for One-Handed Microinteractions, ACM MobileHCI’10 workshop on Ensembles of on-body devices. \ 34. Mann, S. 1995. Privacy Issues of Wearable Cameras Versus Surveillance Cameras. Newsweek, 86(11), 21-22. \ 35. Mayol, W., Tordoff, B., Murray, D. 2000. Towards wearable active vision platforms. Trans. Syst. Man. Cyber. V. 3, (Oct. 2000), 1627-1632. \ 36. Mayol, W., Tordoff, B., Murray, D. 2009. On the choice and placement of wearable vision sensors. Trans. Sys. Man Cyber. 39, 2. 414-425. \ 37. Mistry, P., Maes, P., Chang, L. 2009. WUW-wear Ur world: a wearable gestural interface. ACM CHI EA '09. 4111-4116. \ 38. NASA TLX, NASA Ames Research Center, Moffet Field, California, 1988. \ 39. Ni, T., Baudisch, P. 2009. Disappearing mobile devices. ACM UIST '09. 101-110 \ 40. Paradiso, J. and Hu, E. 1997. Expressive Footwear for ComputerAugmented Dance Performance. IEEE ISWC '97, 13-14. \ 41. Pierce, J., Mahaney, H. 2004 Opportunistic Annexing for Handheld Devices: Opportunities and Challenges. HCIC04. \ 42. Pook, S., Lecolinet, E., Vaysseix, G., Barrilot, E. 2000. Control menus: execution and control in a single interactor. ACM CHI EA'00, 263-264. \ 43. Rico, J. and Brewster S. 2010. Usable gestures for mobile interfaces: evaluating social acceptability. ACM CHI '10, 887-896. \ 44. Ruiz, J., Li, Y., Lank, E. 2011. User-defined motion gestures for mobile interaction. ACM CHI '11, 197-206. \ 45. Schiele B. and Pentland, A. 1999. Attentional objects for visual context understanding. Tech. Rep. 500, MIT media Lab, 1999. \ 46. Shiratori, T., Park, H. S., Sigal, L., Sheikh, Y., Hodgins, J. K. 2011. Motion Capture from-Mounted Cameras. SIGGRAPH. 10 pages. \ 47. Siek, Roger, Y., Connelly, K. 2005. Fat finger worries: How older and younger users physically interact with PDAs. INTERACT ’05. 267-280. \ 48. Starner, T. 1996. Human-powered wearable computing. IBM Syst. J. 35, 3-4 (September 1996), 618-629. \ 49. Starner, T., Wearer, J., Pentland, A. 1998. Real-Time American Sign Language Recognition Using Desk and Wearable Computer Based Video. IEEE Trans. Pat. Anal. Mach. Intell. 20, 12 (Dec. 98), 1371-1375. \ 50. Starner, T., Auxier, J., Ashbrook, D., Gandy, M.2000. The Gesture Pendant: A Self-illuminating, Wearable, Infrared Computer Vision System for Home Automation Control and Medical Monitoring. IEEE ISWC '00, 87-94. \ 51. Trigo, T. Pellegrino, S. 2010 An Analysis of Features for Hand-Gesture Classification. IWSSIP’10. 412-415 \ 52. Vardy, A., Robinson, J., Cheng, L. 1999. The WristCam as Input Device. IEEE ISWC '99, 199-202. \ 53. Wilson, A. D. 2006. Robust computer vision-based detection of pinching for one and two-handed gesture input. ACM UIST'06, 255-258. \ 54. Wobbrock, J., Morris, M., Wilson, A. 2009. User-defined gestures for surface computing. ACM CHI '09, 1083-1092. \ 55. Wu, M., Shen, C., Ryall, K., Forlines, C., Balakrishnan, R. 2006. Gesture registration, relaxation, and reuse for multi-point direct-touch surfaces. IEEE TableTop’06. p. 183.190. \ ","Wearable; Gestures; gesture set; shoe; sensor placement; mobile","infile130-1.doc","","","Participants perform hand gesture in the air for controlling interactive applications such as Keynote or iTunes","","H.5.2 [Information Interfaces And Presentation]: User Interfaces - Interaction styles;","","","2","","Jan  9 10:13",""
"in134","A","The Urban Musical Game: Using Sport Balls as Musical Interfaces","Nicolas","Rasamimanana","nicolas.rasamimanana@ircam.fr","inpaper134.pdf","4","letter","","","Nicolas Rasamimanana, Frederic Bevilacqua, Julien Bloit, Norbert Schnell, Emmanuel Flety, Andrea Cera, Uros Petrevski, Jean-Louis Frechin","Nicolas","","Rasamimanana","nicolas@phonotonic.net","Phonotonic, Paris","Paris","","France","IRCAM, Paris","Paris","","France","Frederic","","Bevilacqua","frederic.bevilacqua@ircam.fr","IRCAM","Paris","","France","","","","","Julien","","Bloit","julien.bloit@ircam.fr","IRCAM","Paris","","France","","","","","Norbert","","Schnell","norbert.schnell@ircam.fr","IRCAM","Paris","","France","","","","","Emmanuel","","Flety","emmanuel.flety@ircam.fr","IRCAM","Paris","","France","","","","","Andrea","","Cera","andreawax@yahoo.it","IRCAM","Paris","","France","","","","","Uros","","Petrevski","studio@nodesign.net","NoDesign","Paris","","France","","","","","Jean-Louis","","Frechin","studio@nodesign.net","NoDesign","Paris","","France","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Nicolas Rasamimanana","nicolas@phonotonic.net","yes","We present Urban Musical Game, an installation using augmented sports balls to manipulate and transform an interactive music environment. The interaction is based on playing techniques, a concept borrowed from traditional music instruments and applied here to non musical objects. ","[1]	Bevilacqua, F., Zamborlin, B., Sypniewski, A., Schnell, N., Guédy, F., and Rasamimanana, N. Continuous realtime gesture following and recognition. LNCS 5934, (2010), 73–84. \ [2]	Blaine, T. and Fels, S. Collaborative Musical Experiences for Novices. Journal of New Music Research 32, 4 (2003), 411-428. \ [3]	Buxton, B. Sketching user experiences: getting the design right and the right design. MK, 2007. \ [4]	Fdili Alaoui, S., Caramiaux, B., and Serrano, M. From dance to touch: movement qualities for interaction design. CHI, ACM (2011), 1465–1470. \ [5]	Jordà, S., Geiger, G., Alonso, M., and Kaltenbrunnera, M. The ReacTable: Exploring the synergy between live music performance and tabletop tangible interfaces. Proceedings of TEI, (2007). \ [6]	Miranda, E. and Wanderley, M. New Digital Musical Instruments: Control and Interaction beyond the Keyboard. A-R, 2006. \ [7]	Nelson, W.L. Physical principles for economies of skilled movements. Journal Biological Cybernetics 46, 2 (1983), 135-147. \ [8]	Newton-Dunn, H., Nakano, H., and Gibson, J. Block jam: A tangible interface for interactive music. Journal of New Music Research 32, 4 (2003), 383-393. \ [9]	Petersen, M.G., Iversen, O.S., and Krogh, P.G. Aesthetic Interaction — A Pragmatist ’ s Aesthetics of Interactive Systems. Proceedings of DIS, (2004), 269-276. \ [10]	Schnell, N., Röbel, A., Schwarz, D., Peeters, G., and Borghesi, R. MuBu & Friends - Assembling Tools for Content Based Real-Time Interactive Audio Processing in Max/MSP. Proceedings of ICMC, (2009). \ [11]	Wanderley, M. and Orio, N. Evaluation of input devices for musical expression: Borrowing tools from HCI. Computer Music Journal 26, 3 (2002), 62-76.  \ ","Digital Arts, Music, Game, Expressive, Collaborative, Instruments.","infile134-1.doc","infile134-2.jpg","infile134-3.m4v","Dribble, throw and spin the ball to play music. \ These are real life digital games \ ","Typos correction.","H.5.5 [Information Interfaces And Presentation]: Sound and Music Computing \ ","","FormatComplete","1","","Feb 22 15:18",""
"in136","A","MUSTARD: A Multi User See Through AR Display","Abhijit","Karnik","abe.karnik@gmail.com","","","","","incomplete","Abhijit Karnik, Walterio Mayol-Cuevas, Sriram Subramanian","Abhijit","","Karnik","abe.karnik@gmail.com","University of Bristol","Bristol","","United Kingdom","","","","","Walterio","","Mayol-Cuevas","wmayol@cs.bris.ac.uk","University of Bristol","Bristol","","United Kingdom","","","","","Sriram","","Subramanian","sriram@cs.bris.ac.uk","University of Bristol","Bristol","","United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Abhijit Karnik","abe.karnik@gmail.com","no","","","","","","","","","","","","2","","Jan  6 21:16",""
"in137","A","Lovely Rita","Romy","Achituv","romy@inch.com","inpaper137.pdf","4","letter","","","Minhye Lee, Romy Achituv (advisor)","Minhye","","Lee","minahopy@gmail.com","HongIk University","Jochiwon","","Korea, Republic of","WCU, National Research Foundation of Korea","Daejon","","Korea, Republic of","Romy","","Achituv (advisor)","romy@inch.com","HongIk University","Jochiwon","","Korea, Republic of","WCU, National Research Foundation of Korea","Daejon","","Korea, Republic of","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Romy Achituv","romy@inch.com","yes","“Lovely Rita” is a dress constructed solely out of variations on a single modular unit: a zipper and the embedded light array it controls. The zipper module is both the fundamental structural unit of the garment as well as a versatile interactive design element, which provides the wearer with the flexibility to dynamically shape the look and feel of the dress.","[1] http://meetsebastian.com/index.php?seccion=5&proy=85 \ [2] http://www.ngocrump.com/works_zipper.html \ [3] Lev Manovitch, The Language of New Media (The MIT Press, 2001), 49-63.","Wearable computing, interaction, hybrid art, fashion design","infile137-1.odt","","infile137-3.mp4","“Lovely Rita” is a dress constructed of zippers and the embedded light arrays they control.","No changes were suggested; the project description was nonetheless extended."," H.5.2. [Information Interfaces and Presentation]: User Interfaces - Miscellaneous.","","FormatComplete","1","","Jan  9 02:26",""
"in142","A","BinCam – A Social Persuasive System to Improve Waste Behaviors","Anja","Thieme","anja-thieme@gmx.de","inpaper142.pdf","10","letter","Arial,Bold Times_New_Roman,Bold Times_New_Roman Times_New_Roman,Italic Arial Arial,Italic","incomplete","Anja Thieme, Rob Comber, Nick Taylor, Ashur Rafiev, Patrick Olivier","Anja","","Thieme","anja.thieme@newcastle.ac.uk","Newcastle University, Newcastle upon Tyne, United Kingdom","","","","","","","","Rob","","Comber","robert.comber@newcastle.ac.uk","Newcastle University","Newcastle upon Tyne","","United Kingdom","","","","","Nick","","Taylor","nick.taylor@newcastle.ac.uk","Newcastle University","Newcastle upon Tyne","","United Kingdom","","","","","Ashur","","Rafiev","ashur.rafiev@newcastle.ac.uk","Newcastle University, Newcastle upon Tyne, United Kingdom","","","","","","","","Patrick","","Olivier","p.l.olivier@ncl.ac.uk","Newcastle University","Newcastle upon Tyne","","United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Anja Thieme","anja.thieme@ncl.ac.uk","no","BinCam is a social persuasive system to motivate reflection and behavioral change in the food waste and recycling habits of young adults. The system replaces an existing kitchen refuse bin and automatically logs disposed of items through digital images captured by a smart phone installed on the underside of the bin lid. Captured images are uploaded to a BinCam application on Facebook where they can be explored. Engagement with BinCam is designed to fit into the existing structure of users’ everyday life, with the intention that reflection on waste and recycling becomes a playful and shared group activity. Results of a user study reveal an increase in both users’ awareness of, and reflection about, their waste management and their motivation to improve their waste-related skills. With BinCam, we explore informational and normative social influences as a source of change, which has to date been underexplored in persuasive HCI.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Home \ User Studies \ User Interface Design \ Sustainability","infile142-1.pdf","infile142-2.mp4","infile142-3.jpg","","","No ACM Classifications were found.  Perhaps they are not formatted correctly?  The classifications should be formatted like this: \  \   A.1.2 [Second level descriptor]: Third level descriptor - Fourth level descriptor; \  \ with the code, then the second level descriptor in brackets, then a colon, then the third level descriptor, then a hyphen, then the fourth level descriptor, then a semicolon at the very end. \ ","","","2","","Mar 19 02:45",""
"in144","A","RobotBuddha","Romy","Achituv","romy@inch.com","inpaper144.pdf","4","letter","","","Woosuk Choi, Romy Achituv (advisor)","Woosuk","","Choi","cwoosuk7@nate.com","HongIk University","Jochiwon","","Korea, Republic of","WCU, National Research Foundation of Korea","Daejon","","Korea, Republic of","Romy","","Achituv (advisor)","romy@inch.com","HongIk University","Jochiwon","","Korea, Republic of","WCU, National Research Foundation of Korea","Daejon","","Korea, Republic of","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Romy Achituv","romy@inch.com","yes","Using a dedicated twitter account, participants are encouraged to send their prayers, blessings and wishes to the RobotBuddha shrine. Incoming messages are converted to Morse code and “chanted” by the robotic arms, i.e., played back on Korean Moktaks – traditional wooden percussion instruments ritualistically used by Buddhist clergy.","Citations \ [1] http://www.boundlesswayzen.org/teishos/tarrantteisho/tarrant-BlackStone.html \ [2] http://www.press.uchicago.edu/Misc/Chicago/borghayl.html","Interactive Installation, Interactive Art, Physical Computing, Mediated Communication","infile144-1.odt","","infile144-3.mp4","Twitter messages are converted to Morse code and played back by robotic arms on Moktaks - traditional percussive instruments used by Buddhist clergy.","Additions: \ 1. A visual reference to the original use of the Moktaks \ 2. Extended project description","H.5.2. [Information Interfaces and Presentation]: User Interfaces - Miscellaneous. \ ","","FormatComplete","1","","Feb 22 15:18",""
"in145","A","Hanging off a Bar","Florian","Mueller","floyd@floydmueller.com","inpaper145.pdf","4","letter","","","Florian Mueller, Cagdas ""Chad"" Toprak, Eberhard Graether, Wouter Walmink, Bert Bongers, Elise van den Hoven","Florian","","Mueller","floyd@floydmueller.com","RMIT University","Melbourne","","Australia","","","","","Cagdas ""Chad""","","Toprak","cain.kinris@gmail.com","RMIT University","Melbourne","","Australia","","","","","Eberhard","","Graether","egraether.mmt-b2009@fh-salzburg.ac.at","RMIT University","Melbourne","Victoria","Australia","","","","","Wouter","","Walmink","wouter@walmink.com","RMIT University","Melbourne","","Australia","","","","","Bert","","Bongers","bertbon@xs4all.nl","University Technology Sydney","Sydney","","Australia","","","","","Elise","","van den Hoven","e.v.d.hoven@tue.nl","Eindhoven University of Technology","Eindhoven","Noord-Brabant","Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Florian Mueller","floyd@floydmueller.com","yes","Exertion Games involve physical effort and as a result can facilitate physical health benefits. We present Hanging off a Bar, an action hero-inspired Exertion Game in which players hang off an exercise bar over a virtual river for as long as possible. Initial observations from three events with audiences ranging from the general public to expert game designers suggest that Hanging off a Bar can be engaging for players and facilitate intense exertion within seconds. Furthermore, we collected suggestions for what game elements players believe could entice them to increase their physical effort investment. These suggestions, combined with Hanging off a Bar as research vehicle due to the easy measurement of exertion through hanging time, enable future explorations into the relationship between digital game elements and physical exertion, guiding designers on how to support exertion in digital games.","[1]	Apple Nike + iPod, http://www.apple.com/ipod/nike. \ [2]	Graves, L., Ridgers, N. and Stratton, G. The contribution of upper limb and total body movement to adolescents’ energy expenditure whilst playing Nintendo Wii. European Journal of Applied Physiology, 104 (4). (2008), 617-623. \ [3]	Guy, S., Ratzki-Leewing, A. and Gwadry-Sridhar, F. Moving Beyond the Stigma: Systematic Review of Video Games and Their Potential to Combat Obesity. (2011). \ [4]	Mueller, F., Agamanolis, S. and Picard, R., Exertion Interfaces: Sports over a Distance for Social Bonding and Fun. CHI '03, 561-568. \ [5]	Mueller, F., Edge, D., Vetere, F., Gibbs, M.R., Agamanolis, S., Bongers, B. and Sheridan, J.G., Designing Sports: A Framework for Exertion Games. CHI '11, 2651-2660. \ [6]	Nintendo. Wii Balance Board, 2009. http://www.nintendo.com/wii/console/accessories/balanceboard. \ [7]	Weinberg, R.S. and Gould, D. Foundations of Sport and Exercise Psychology. Human Kinetics, Champaign, IL, USA, 2006. \ ","Exertion games; exertion interfaces; whole-body interaction; exergames; sport; game design","infile145-1.doc","infile145-2.jpg","infile145-3.mp4","Hanging off a Bar is a game where the player hangs over a digital river and jumps on rafts. This game enables investigations into how game elements promote increased exertion. ","N/A","H.5.2. [Information Interfaces and Presentation]: User Interfaces - Miscellaneous","","FormatComplete","2","","Jan  9 07:36",""
"in147","A","Using Augmented Snapshots for Viewpoint Switching and Manipulation in Augmented Reality","Mengu","Sukan","mengu@cs.columbia.edu","inpaper147.pdf","4","letter","","","Mengu Sukan, Steven Feiner","Mengu","","Sukan","mengu@cs.columbia.edu","Columbia University","New York","New York","United States","","","","","Steven","","Feiner","feiner@cs.columbia.edu","Columbia University","New York","New York","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Mengu Sukan","mengu@cs.columbia.edu","yes","SnapAR is a magic-lens–based hand-held augmented reality application that allows its user to store snapshots of a scene and revisit them virtually at a later time. By storing a still image of the unaugmented background along with the 6DOF camera pose, this approach allows augmentations to remain dynamic and interactive. This makes it possible for the user to quickly switch between vantage points at different locations from which to view and manipulate virtual objects, without the overhead of physically traveling between those locations.","1. D. Bowman, E. Kruijff, J. LaViola, and I. Poupyrev, 3D user interfaces: Theory and practice. AddisonWesley, 2005. \ 2. O. Oda and S. Feiner, “Goblin XNA Framework.” [Online].http://goblinxna.codeplex.com/. [Accessed: 26-Nov-2011]. \ 3. VTT, “ALVAR tracking subroutines library.” [Online].http://www.vtt.fi/multimedia/alvar.html. [Accessed: 26-Nov-2011]. \ 4. P. Georgel, P. Schroeder, and N. Navab, “Navigation Tools for Viewing Augmented CAD Models,” IEEE CG&A, vol. 29, no. 6, 65-73, Nov. 2009. \ 5. D. Schmalstieg, L. M. Encarnação, and Z. Szalavári, “Using transparent props for interaction with the virtual table,” Proc ACM I3D, 1999, 147-153. \ 6. S. Guven, S. Feiner, and O. Oda, “Mobile augmented reality interaction techniques for authoring situated media on-site,” Proc. IEEE ISMAR, 2006, pp. 235-236. \ 7. K. Phillips and W. Piekarski, “Possession techniques for interaction in real-time strategy augmented reality games,” Proc ACM ACE, 2005, 10. \ 8. M. Sukan and S. Feiner, “SnapAR: Storing snapshots for quick viewpoint switching in hand-held augmented reality,” Proc. IEEE ISMAR, 2010, 273-274.","3D interaction techniques, augmented reality, travel","infile147-1.doc","infile147-2.jpg","infile147-3.m4v","SnapAR is a magic-lens–based hand-held augmented reality application that allows its user to store snapshots of a scene and revisit them virtually at a later time.","No changes.  None were required.","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities; H.5.2 [Information Interfaces and Presentation]: User Interfaces—Input devices and strategies, Interaction Styles; I.3.6 [Computer Graphics]: Methodology and Techniques—Interaction techniques","","FormatComplete","2","","Jan  9 21:29",""
"in148","A","A Virtual Reality Dialogue System For The Treatment Of Social Phobia","Willem-Paul","Brinkman","W.P.Brinkman@tudelft.nl","inpaper148.pdf","4","letter","Helvetica-Bold","","Willem-Paul Brinkman, Dwi Hartanto, Ni Kang, Daniel de Vliegher, Isabel L. Kampmann, Nexhmedin Morina, Paul G.M. Emmelkamp, Mark Neerincx","Willem-Paul","","Brinkman","w.p.brinkman@tudelft.nl","Delft University of Technolugy","Delft","","Netherlands","Brunel University","London","","United Kingdom","Dwi","","Hartanto","d.hartanto@tudelft.nl","Delft University of Technology","Delft","","Netherlands","","","","","Ni","","Kang","n.kang@tudelft.nl","Delft University of Technology","Delft","","Netherlands","","","","","Daniel","","de Vliegher","netwin@hetnet.nl","Delft University of Technology","Delft","","Netherlands","","","","","Isabel L.","","Kampmann","i.l.kampmann@uva.nl","University of Amsterdam","Amsterdam","","Netherlands","","","","","Nexhmedin","","Morina","n.morina@uva.nl","University of Amsterdam","Amsterdam","","Netherlands","","","","","Paul G.M.","","Emmelkamp","p.m.g.emmelkamp@uva.nl","University of Amsterdam","Amsterdam","","Netherlands","","","","","Mark","","Neerincx","mark.neerincx@tno.nl","TNO Human Factors","Soesterberg","","Netherlands","Delft University of Technology","Delft","","Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","Willem-Paul Brinkman","w.p.brinkman@tudelft.nl","yes","People with social phobia have a severe fear of everyday social situations. In this paper we describe a virtual reality exposure therapy system specifically designed to expose patients with social phobia to various social situations. Patients can engage in a free speech dialogue with avatars while being monitored by a therapist. To control phobic stressors, therapists can control the avatar’s gaze, the avatar’s dialogue style and the narrative stories that are embedded throughout the exposure. The system uses the Delft remote virtual reality exposure therapy platform which allows remote treatment. "," \ WARNING: Reference 9 is very long.  Please check it. \  \ 1. Bouchard, S., St-Jacques, J., Robillard, G. and Renaud, P. Anxiety increases the feeling of presence in virtual reality. Presence-Teleoperators and Virtual Environments 17, 4 (2008), 376-391. \ 2. de Graaf, R., Ten Have, M., van Gool, C. and van Dorsselaer, S. Prevalence of mental disorders and trends from 1996 to 2009. Results from the Netherlands Mental Health Survey and Incidence Study-2. Soc Psychiatry Psychiatr Epidemiol, 2011. \ 3. Garcia-Palacios, A., Botella, C., Hoffman, H. and Fabregat, S. Comparing acceptance and refusal rates of virtual reality exposure vs. in vivo exposure by patients with specific phobias. Cyberpsychol Behav 10, 5 (2007), 722-724. \ 4. Klinger, E., Bouchard, S., Legeron, P., Roy, S., Lauer, F., Chemin, I. and Nugues, P. Virtual reality therapy versus cognitive behavior therapy for social phobia: a preliminary controlled study. Cyberpsychol Behav 8, 1 (2005), 76-88. \ 5. Powers, M.B. and Emmelkamp, P.M. Virtual reality exposure therapy for anxiety disorders: A meta-analysis. J Anxiety Disord 22, 3 (2008), 561-569. \ 6. Robillard, G., Bouchard, S., Dumoulin, S., Guitard, T. and Klinger, E. Using virtual humans to alleviate social anxiety: preliminary report from a comparative outcome study. Stud Health Technol Inform 154 (2010), 57-60. \ 7. Slater, M., Pertaub, D.P. and Steed, A. Public speaking in virtual reality: Facing an audience of avatars. Ieee Computer Graphics and Applications 19, 2 (1999), 69. \ 8. ter Heijden, N. and Brinkman, W.P. Design and evaluation of a virtual reality exposure therapy system with automatic free speech interaction. Journal of CyberTherapy and Rehabilitation 4, 1 (2011), 44-55. \ 9. ter Heijden, N., Qu, C., Wiggers, P. and Brinkman, W.P. Developing a dialogue editor to script interaction between virtual chracters and social phobic patients. in Proc. of the ECCE2010 workshop - Cognitive engineering for technology in mental health care and rehabilitation, Mediamatica, Delft University of Technology, Delft, The Netherlands (2010), 111-123. \ ","Virtual reality exposure therapy; mental health computing; social phobia; DRVRET","infile148-1.doc","","infile148-3.mp4","A virtual reality exposure therapy system designed to expose patients with social phobia to various social situations. Patients can engage in a free speech dialogue with avatars while being monitored.","not applicable","H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems \ ","","FormatComplete","2","","Jan  9 17:17",""
"in153","A","Joggobot: A Flying Robot as Jogging Companion","Eberhard","Graether","egraether.mmt-b2009@fh-salzburg.ac.at","inpaper153.pdf","4","letter","","","Eberhard Graether, Florian Mueller","Eberhard","","Graether","egraether.mmt-b2009@fh-salzburg.ac.at","RMIT University","Melbourne","Victoria","Australia","","","","","Florian","","Mueller","floyd@floydmueller.com","RMIT University","Melbourne","","Australia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Eberhard Graether","egraether.mmt-b2009@fh-salzburg.ac.at","yes","Exertion activities, such as jogging, provide many health benefits, but exercising on your own can be considered disengaging. We present our system 'Joggobot', a flying robot accompanying joggers. Our design process revealed preliminary insights into how to design robots for exertion and how to address emerging design challenges. We summarize these insights into the four themes: ‘embodiment’, ‘control’, ‘personality’ and ‘communication’, which mark initial starting points towards understanding how to design robots for exertion activities. We hope our work guides and inspires designers when facilitating the benefits of exertion through robots.","1. O’Brien, S., & Mueller, F. F. (2007). Jogging the distance. Proceedings of the SIGCHI conference on Human factors in computing systems CHI 07, 523. \ 2. Mueller, F. F., O’Brien, S., & Thorogood, A. (2007). Jogging over a distance. CHI 07 extended abstracts on Human factors in computing systems CHI 07, 2579. \ 3. Higuchi, K., Ishiguro, Y., & Rekimoto, J. (2011). Flying Eyes : Free-Space Content Creation Using Autonomous Aerial Vehicles. Information Systems Journal, 561-570. \ 4. Higuchi, K., Shimada, T., & Rekimoto, J. (2011). Flying sports assistant: external visual imagery representation for sports training. In Proceedings of the 2nd Augmented Human International Conference (AH '11), Article 7, 4 pages. \ 5. Breazeal, C. (2003). Toward sociable robots. Robotics and Autonomous Systems, 42(3-4), 167-175. \ ","jogging; remote controlled Quadrotor; drone; exertion games","infile153-1.doc","infile153-2.jpg","infile153-3.mp4","Joggobot is a flying robot as jogging companion. It enables investigations into how robotic systems relate to jogging and how they need to be designed to create an engaging experience.","We thank the reviewers for the insightful comments.  \  \ As suggested, we included all the references the reviewers suggested and added a paragraph to our introduction section. We believe this makes the submission a much stronger argument. Furthermore, the references to commercial products have been removed from the references and some minor cutbacks helped to fit the paper into the page limit again. \  \ We have discussed with the conference logistics team to organize a suitable space where we can exhibit Joggobot beyond the default space requirements. We have tested how to showcase Joggobot in our lab, which has similar dimensions of around 10mx10m. Although we understand that we cannot simulate a full jogging experience, we believe, based on our experience, that (slowly) jogging with Joggobot, involving movements forward, backward and sideways within a restricted space, can already be an engaging and novel experience for most attendees that richly conveys the experience what it is like to exercise with a robot, which is difficult to describe otherwise (such as in a paper). If concerns arise in terms of exercising and liability, we can also focus on power-walking or just walking, which we also have demonstrated in our lab, and we also found participants reported engaging experiences, so we can also envision a more leisurely speed and hence scenario if this helps realizing the experience. We also have developed a backup plan for manual control if environmental issues restrict usage so that we are able to accomodate any issues that might arise in a busy environment. \  \ Again, we thank the reviewers for their insightful comments and look forward to demonstrate Joggobot to the attendees.","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ ","","FormatComplete","2","","Jan  9 16:41",""
"in159","A","Surround Haptics: Tactile Feedback for Immersive Gaming Experiences","Ali","Israr","israr@disneyresearch.com","inpaper159.pdf","4","letter","","","Ali Israr, Seung-Chan Kim, Jan Stec, Ivan Poupyrev","Ali","","Israr","israr@disneyresearch.com","Disney Research Pittsburgh","Pittsburgh","Pennsylvania","United States","Disney Research","Pittsburgh","Pennsylvania","United States","Seung-Chan","","Kim","kimscster@gmail.com","Disney Research Pittsburgh","Pittsburgh","Pennsylvania","United States","Disney Research Pittsburgh","Pittsburgh","Pennsylvania","United States","Jan","","Stec","janstec@gmail.com","Disney Research","Pittsburgh","Pennsylvania","United States","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","Ivan","","Poupyrev","ipoupyrev@gmail.com","Disney Research Pittsburgh","Pittsburgh","Pennsylvania","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Ali Israr","israr@disneyresearch.com","yes","In this paper we propose an architecture for rendering rich and high-resolution haptic feedback on the user’s body while playing interactive games. The haptic architecture consists of three main elements, namely, haptic engine, haptic API/codec, and haptic display. The haptic engine extracts events from the game, assigns haptic feedback to these events, and sends coded packets to haptic API/codec. The haptic API/codec translates the coded packets and computes driving signals based on carefully evaluated algorithms derived from psychophysical modeling of tactile perception. The driving signals are then routed to the haptic display embedded with an array of vibratory transducers. A user feels high resolution and refined tactile sensations on the body through the display. We have integrated the Surround Haptics system with a driving simulation game to provide an enjoyable gaming experience.","1. Israr, A. and Poupyrev, I. Exploring Surround Haptics Displays. In Proc. of the CHI, Work-in-progress, 2010. ACM. pp. 4171-4176. \ 2. Israr, A. and Poupyrev, I. Tactile Brush: Drawing on Skin with Tactile Grid Display. In Proc. of CHI, 2011. ACM. pp. 2019-2028. \ 3. Israr, A. and Poupyrev, I. Control Space of Apparent Haptic Motion. In Proc. of World Haptics Conference, 2011. IEEE. pp. 457-462. Figure 6. Snapshots of gaming events as the user maneuvers the car through different levels of the game and interacts with other characters and objects. \ ","tactile feedback, surround haptics, interactive games, haptic API/codec, haptic architecture","infile159-1.doc","infile159-2.png","infile159-3.mp4","Come and enjoy high quality haptic feedback on your body as you drive through different phases of a driving game. Feel engine rumbles, car motion, tire traction, environment, and many more. ","Although no specific and explicit requests were made by the AC in the Meta Review, but based on the reviewers' feedback we have made following changes. \  \ We have cleared out the text of the Introduction section and referenced prior papers that describe psychophysical modeling of tactile illusions. This would provide more insight to the readers interested in understanding mathematical formulation and use of illusion in digital framework. \  \ We have edited text format as suggested by reviewers. \  \ We have also modified the description of the architecture, specifically, noted that ""haptic engine could reside in the game engine or operate separately"" to reduce compilation time as suggested by a reviewer. \  \ We have also references gaming events shown in Figure 5 and Figure 6 in the text. \  \ Based on reviewer's suggestion, we will also bring a small prototype that explains and demonstrates the core technology behind surround haptics \  \ We would like to thank primary and external reviewers for their insight and constructive feedback on the submitted work, and we hope to excite the CHI community with the novel and seamless haptic experience integrated with an interactive game.  \ ","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Haptic I/O  \ ","","FormatComplete","2","","Feb 22 09:22",""
"in160","A","hipDisk: Experiencing the Value of Ungainly, Embodied, Performative, Fun.","danielle","wilde","d@daniellewilde.com","inpaper160.pdf","4","letter","","","Danielle Wilde","Danielle","","Wilde","d@daniellewilde.com","independent pracititioner","Melbourne","","Australia","RMIT University","Melbourne","VIC","Australia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Danielle Wilde","d@daniellewilde.com","yes","hipDisk is a wearable interface that extends the hips and torso horizontally to give the moving body musical capabilities. The device prompts wearers to move in strange ways, bypassing norms of self-constraint, to actuate sound. The result is sonically and physically ungainly, yet strangely compelling, and often prompts spontaneous laughter. hipDisk emerged from an embodied, performative research approach. It began as a single user device, and evolved to support social interaction and co-creation, as well as creatively engaged, embodied discovery and learning. Using, and also observing hipDisk in use, affords insight into how ungainly, embodied, performative fun may be a powerful vehicle for embodied knowledge generation and learning. ","1. Gaver, W., Beaver, J., Benford, S. Ambiguity as a Resource for Design. Proc. CHI, ACM Press 2003 \ 2. Heidegger, M. Being and Time, trans. Macquarrie, J., Robinson, E. New York: Harper & Row, 1962. \ 3. Levisohn, A. The Body as a Medium: Reassessing the Role of Kinesthetic Awareness in Interactive Applications. Proc. MM, ACM Press 2007. \ 4. Mueller, F., Agamanolis, S., Picard, R. Exertion interfaces: sports over a distance for social bonding and fun. Proc. SIGCHI, ACM Press 2003. \ 5. Merzenich, M.M., Cortical plasticity contributing to childhood development. In McClelland, J.L., Siegler, R.S., eds. Mechanisms of cognitive development; Behavioral and neural perspectives. (2001), 68. Mahwah, NJ: Lawrence Erlbaum Associates. \ 6. Sheets-Johnstone, M. Why is Movement Therapeutic? Keynote Address, 44th American Dance Therapy Association Conference, Portland, OR, 1. 2009 \ 7. Shklovsky, Viktor. Art as Technique. In Russian Formalist Criticism: Four Essays. Translated by L. Lemon, L., Reis, M. Lincoln: University of Nebraska Press, 1965 (1917). \ 8. Wilde, D. hipDisk: using sound to encourage physical extension, exploring humour in interface design. IJPADM, 4(1), 7-26 Intellect 2008 \ 9. Wilde, D. (in press) hipDisk: Understanding the value of Ungainly, Embodied, Performative, Fun. Proc. CHI, ACM Press 2012. \ 10. Wilde, The Hipdiskettes : Learning (through) Wearables. Proc. OZCHI 08, ACM Press 2008. \ 11. Wilde, D. Swing That Thing : moving to move. The poetics of embodied engagement. PhD Diss., Monash University, Melbourne Australia with CSIRO, Australia (2011). See also http://www.daniellewilde.com \ ","Wearable technologies; embodied engagement; performative research; awkwardness; poetics; play; learning","infile160-1.docx","","infile160-3.mov","hipDisk is an ungainly musical body extension that prompts awkward engagement to facilitate embodied learning. The research champions process-driven, performative research methodologies, epistemologically different to qualitative and quantitative approaches. ","the paper has been tidied up to reflect reviewer comments and reference the larger alt-chi paper","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Interaction Styles, Theory and Methods, Usercentered Design  \ ","","FormatComplete","1","","Feb 22 15:18",""
"in163","A","Vignette: Interactive Texture Design and Manipulation with Freeform Gestures for Pen-and-Ink Illustration","Rubaiat Habib","Kazi","rubaiat@comp.nus.edu.sg","inpaper163.pdf","10","letter","","","Rubaiat Habib Kazi, Takeo Igarashi, Shengdong Zhao, Richard Davis","Rubaiat Habib","","Kazi","rubaiat@comp.nus.edu.sg","National University of Singapore","Singapore","","Singapore","JST ERATO Igarashi Design Interface Project","Tokyo","","Japan","Takeo","","Igarashi","takeo@acm.org","The University of Tokyo","Bunkyo","Tokyo","Japan","JST ERATO Igarashi Design Interface Project","Bunkyo","Tokyo","Japan","Shengdong","","Zhao","zhaosd@comp.nus.edu.sg","National University of Singapore","Singapore","","Singapore","","","","","Richard","","Davis","rcdavis@smu.edu.sg","Singapore Management University","Singapore","","Singapore","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Rubaiat Habib Kazi","rubaiat@comp.nus.edu.sg","no","Vignette is an interactive system that facilitates texture creation in pen-and-ink illustrations. Unlike existing systems, Vignette preserves illustrators’ workflow and style: users draw a fraction of a texture and use gestures to automatically fill regions with the texture. We currently support both 1D and 2D synthesis with stitching. Our system also has interactive refinement and editing capabilities to provide a higher level texture control, which helps artists achieve their desired vision. A user study with professional artists shows that Vignette makes the process of illustration more enjoyable and that first time users can create rich textures from scratch within minutes. ","1. Barla P, Breslav S, Thollot J, Sillion F and Markosian L. Learning Style Translation for the Style of a Drawing. ACM Transactions of Graphics 22,1 (2003), 33 - 46 \ 2. Barla, P., Breslav, S., Thollot, J. and Markosian, L. Interactive hatching and stippling by example. INRIA Technical Report (2006) \ 3. Deussen, O., Hiller, S., Overveld, C. and Strothotte, T. Floating Points: A Method for Computing Stipple Drawings. IEEE Computer Graphics Forum 19,3 (2000), 41 - 50 \ 4. Efros, A.A. AND Freeman W.T. Image quilting for Texture Synthesis and Transfer. In Proc. ACM SIGGRAPH (2001), 341 - 346 \ 5. Efros, A.A. and Leung, T.K. Texture Synthesis by Nonparametric sampling. IEEE Computer Vision Vol.2 (1999), 1033 – 1038 \ 6. Gröller, E. and Szirmay-Kalos, L. Stroke Pattern Analysis and Synthesis. EUROGRAPHICS, 25 (2006), Number 3 \ 7. Guptill A.L. Rendering with pen and ink. Watsom-Guptill Publications, New York, 1976. \ 8. Hertzmann, A., Oliver, N., Curless, B., Seitz, S.M. Curve Analogies. In Proc. Rendering Techniques (2002), 233- 246 \ 9. Igarashi, T. and Hughes, J.F. Clothing Manipulation In Proc. ACM UIST (2002), 91- 100 \ 10. Igarashi, T., Moscovich, T. and Hughes, J.F. As-rigid-aspossible Shape Manipulation. In Proc. ACM SIGGRAPH 24 ,3 (2005), 1134 - 1141 \ 11. Ijiri, T., Mech, R., Miller, G. and Igarashi, T. An examplebased procedural system for element arrangement. Computer Graphics Forum 27,2 (EUROGRAPHICS 2008), 429 - 436 \ 12. Kalnins, R.D., Markosian, L., Meier, B.J., Kowalski, M.A., Lee, J.C., Davidson, P.L., Webb, M., Hughes, J.F. and Finkelstein, A. WYSIWYG NPR: Drawing Strokes Directly on 3D Models. In Proc. ACM SIGGRAPH in Transactions on Graphics 21,3 (2002), 755-762 \ 13. Kazi, R.H., Chua, K.C., Zhao, S., Davis, R., Lim, K. SandCanvas: A multi-touch art medium inspired by sand animation. ACM CHI 2011. pp. 1283-1292. \ 14. Kopf, J., Fu, C., Chohen-Or, D., Deussen, O., Lischinski, D. and Wong, T. Solid Texture Synthesis from 2D exemplars. In Proc. ACM SIGGRAPH 26, 3 (2007), 21- 29 \ 15. Ma, C., Wei, L. and Tong, X. Discrete Element Textures. In Proc. ACM SIGGRAPH 30, 4 (2011), Article 62 \ 16. McCloud, S. Making comics. Harper Paperbacks, 2006. \ 17. McCloud, S. Understanding Comics. Harper Paperbacks, 1994. \ 18. Nelson Chu WB, Li-Yi Wei, and Naga Govindaraju. Detailpreserving paint modeling for 3D brushes. NonPhotorealistic Animation and Rendering 2010. \ 19. Nice, C. Drawing in Pen and Ink. North Light Books, 1997 \ 20. Ryokai K, Marti S, and Ishii H. I/O brush: drawing with everyday objects as ink. In. Proc. of CHI 2004, 303-310. \ 21. Salisbury, M., Anderson, S., Barzel, R. and Salesin, D. Interactive pen and ink rendering. In Proc. ACM SIGGRAPH (1994), 101 - 108 \ 22. Salisbury, M.P., Wong, M.T., Hughes, J.F. and Salesin, D.H. Orientable Textures for Image-Based Pen-and-Ink Illustration. In Proc. ACM SIGGRAPH (1997), 401- 406 \ 23. Schwarz, M., Isenberg, T., Mason, K. and Carpendale, S. Modeling with Rendering Primitives: An Interactive NonPhoto Realistic Canvas. Non-Photorealistic Animation and Rendering (2007), 15 - 22 \ 24. Simmons, G. The Technical Pen. Watson-Guptill, 1992. \ 25. Turk, G. Texture synthesis on surfaces. In Proc. ACM SIGGRAPH (2001), 347 - 354 \ 26. Vandoren P, et al. FluidPaint: an interactive digital painting system using real wet brushes. In. Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces 2009, ACM (2009), 53-56. \ 27. Vandoren P, et al. IntuPaint: Bridging the Gap between Physical and Digital Painting. IEEE TABLETOP 2008(2008). \ 28. Wei, L. and Levoy, M. Fast texture synthesis using treestructured vector quantization. In Proc. ACM SIGGRAPH (2000), 479 - 488 \ 29. Wei, L., Lefebvre, S., Kwatra, V. and Turk, G. State of the Art in Example-Based Texture Synthesis. Eurographics (2009) \ 30. Winkenbach, G. and Salesin, D. Computer Generated Pen and Ink illustration. In Proc. ACM SIGGRAPH (1994), 91 - \ 31. Winkenbach, G. and Salesin, D.H. Rendering Parametric Surfaces in Pen and Ink. In Proc. ACM SIGGRAPH in Computer Graphics (1996), 469 – 476 \ 32. Winnemoller, H., Orzan, A., Boissieux, L. and Thollot, J. Texture Design and Draping in 2D images. Computer Graphics Forum. In Proc. Eurographics 28, 4 (2009), 1091 Figure 16: Different artworks with Vignette. The artworks took 16, 13 and 19 minutes respectively, completely from scratch \ ","pen-and-ink illustration, sketch, vignette","infile163-1.doc","","infile163-3.mp4","Presents a sketch-based application for interactive pen-and-ink illustration. The novel interaction and workflow enables to create a wide range of paintings easily and quickly, along with preserving personal artistic style.","NA","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Interaction styles \ ","","","2","","Jan  9 10:02",""
"in164","A","Embroidered Confessions: An interactive quilt of the secrets of strangers","Julynn","Benedetti","julynn.benedetti@gmail.com","inpaper164.pdf","4","letter","","","Julynn Benedetti","Julynn","","Benedetti","julynn.benedetti@gmail.com","Parsons The New School for Design","New York","New York","USA","frog design","New York","New York","USA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Julynn Benedetti","julynn.benedetti@gmail.com","yes","The condition of anonymity creates a private space within a public space as a person feels the freedom to act without attribution. This phenomenon holds true in both physical and digital spaces. People feel free to post their most intimate secrets on the Internet with the belief that their confessions are ephemeral and intangible. In reality, this data is perpetually archived and cached on distant servers. A disconnect exists between the perception of the transitory quality of digital data and the truth of its enduring existence. Through the weaving of the stories and secrets of strangers from the Internet into a material artifact, Embroidered Confessions represents the physical manifestation of the duality of digital information.","1. Antoni, Janine. Slumber, installation and performance, MASS MoCA, North Adams, MA, 1993. \ 2. Lawson, Bryan. The language of space. Oxford; Boston: Architectural Press, 2001. \ 3. Mayer-Schonberger, Viktor. Delete: the virtue of forgetting in the digital age. Princeton, Princeton University Press, 2009. \ 4. Ovid. Metamorphoses: Book 11 – The Musical Contest of Pan and Apollo. Translated by Brookes More. Boston: Cornhill Publishing Co, 1922. \ 5. Tobin, Jacqueline L. and Dobard, Raymond G., Hidden in Plain View: A Secret Story of Quilts and the Underground Railroad. New York: Anchor Books, 1999. \ ","Craft and Technology; Tangible Interface; Narrative","infile164-1.doc","infile164-2.jpg","infile164-3.mov","Embroidered Confessions is an installation that curates, archives, and physically embodies digital secrets. Secrets from the Internet are accessed through embroidered QR codes that have been integrated into a quilt.","Added additional information regarding the interactivity of the installation. Shortened paper to meet the 4 page maximum. Added music credit to video.","H.5.2. [Information Interfaces and Presentation]: User Interfaces – Miscellaneous; J.5. Computer Applications: Arts & Humanities – Fine arts","","FormatComplete","1","","Feb 22 15:19",""
"in169","A","Enabling Concurrent Dual Views on Common LCD Screens","Xiang","Cao","xiangc@microsoft.com","","","","","","Seokhwan Kim, Xiang Cao, Haimo Zhang, Desney Tan","Seokhwan","","Kim","compedian@gmail.com","Microsoft Research Asia","Beijing","","China","University of Tsukuba","Tsukuba","Ibaraki","Japan","Xiang","","Cao","xiangc@microsoft.com","Microsoft Research Asia","Beijing","","China","","","","","Haimo","","Zhang","zh.hammer@gmail.com","Microsoft Research Asia","Beijing","","China","National University of Singapore","Singapore","","Singapore","Desney","","Tan","desney@microsoft.com","Microsoft Research","Redmond","Washington","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 06:15",""
"in171","A","iRotate: Automatic Screen Rotation based on Face Orientation","Lung-Pan","Cheng","xmanlch@gmail.com","","","","","","Lung-Pan Cheng, Fang-I Hsiao, Yen-Ting Liu, Mike Y. Chen","Lung-Pan","","Cheng","xmanlch@gmail.com","National Taiwan University","Taipei","","Taiwan","","","","","Fang-I","","Hsiao","kamebkj@gmail.com","National Taiwan University","Taipei","","Taiwan","","","","","Yen-Ting","","Liu","andrewliu33@gmail.com","National Taiwan University","Taipei","","Taiwan","","","","","Mike Y.","","Chen","mikechen@csie.ntu.edu.tw","National Taiwan University","Taipei","","Taiwan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 07:14",""
"in173","A","MelodicBrush: A Cross-Modal Link between Ancient and Digital Art Forms","Michael Xuelin","Huang","csxhuang@comp.polyu.edu.hk","inpaper173.pdf","4","letter","Helvetica,Bold Arial","","Michael Xuelin Huang, Will W. W. Tang, Kenneth W.K. Lo, C. K. Lau, Grace Ngai, Stephen Chan","Michael Xuelin","","Huang","csxhuang@comp.polyu.edu.hk","The Hong Kong Polytechnic University, Kowloon","Hong Kong","","Hong Kong","","","","","Will W. W.","","Tang","cswwtang@comp.polyu.edu.hk","The Hong Kong Polytechnic University","Kowloon","","Hong Kong","","","","","Kenneth W.K.","","Lo","cskenneth@comp.polyu.edu.hk","The Hong Kong Polytechnic University","Kowloon","","Hong Kong","","","","","C. K.","","Lau","cscklau@comp.polyu.edu.hk","The Hong Kong Polytechnic University, Kowloon","Hong Kong","","Hong Kong","","","","","Grace","","Ngai","csgngai@comp.polyu.edu.hk","The Hong Kong Polytechnic University","Kowloon","","Hong Kong","","","","","Stephen","","Chan","csschan@comp.polyu.edu.hk","The Hong Kong Polytechnic University","Kowloon","","Hong Kong","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Michael Xuelin Huang","csxhuang@comp.polyu.edu.hk","yes","MelodicBrush is a novel cross-modal musical system that connects two ancient art forms: Chinese ink-brush calligraphy and Chinese music. Our system endows the process of calligraphy writing with a novel auditory representation in a natural and intuitive manner to create a novel artistic experience. The writing effect is simulated as though the user were writing on an infinitely large piece of paper viewed through a viewport. The real-time musical generation effects are motivated by principles of metaphoric congruence and statistical music modeling","1. HyperScore. http://www.hyperscore.com/ \ 2. Izadi S., Kim D., Hilliges O., Molyneaux D., Newcombe R., Kohli P., Shotton J., Hodges S., Freeman D., Davison A., and Fitzgibbon A. KinectFusion: realtime 3D reconstruction and interaction using a moving depth camera. In Proc. UIST 2011, ACM Press (2011), 559-568. \ 3. Jordà, S., Geiger G., Alonso M. and Kaltenbrunner M. The reacTable: exploring the synergy between live music performance and tabletop tangible interfaces. In Proc. TEI 2007, ACM Press (2007), 139-146. \ 4. Jo, K. DrawSound: a drawing instrument for sound performance. In TEI 2008, ACM Press (2008), 59-62. \ 5. Kang L. and Chien H.Y. Hé: Calligraphy as a Musical Interface. In Proc. NIME 2010. \ 6. Nichols E., Morris D., and Basu S. Data-driven exploration of musical chord sequences. In Proc. IUI 2009, ACM Press (2009), 227-236. \ 7. Obrenovic Z. A flexible system for creating music while interacting with the computer. In Proc. MM 2005, ACM Press (2005), 996-1004. \ 8. Sonic wire sculptors. http://sws.cc/index.html \ 9. Simon I., Morris D. and Basu S. MySong: automatic accompaniment generation for vocal melodies. In Procs. CHI 2008, ACM Press (2008), 725-734. \ 10. Vandoren P., Claesen L., Laerhoven T.V., Taelman J., Raymaekers C., Flerackers E., and Reeth F.V. FluidPaint: an interactive digital painting system using real wet brushes. In Proc. ITS 2009, ACM Press (2009), 53-56. \ 11. Wilson A.D. Using a depth camera as a touch sensor. In Proc. ITS 2010, ACM Press (2010). 69-72. \ ","Cross-modal Interaction; Chinese calligraphy; Chinese music","infile173-1.docx","infile173-2.jpg","infile173-3.mp4","MelodicBrush is a novel cross-modal musical system connecting Chinese ink-brush calligraphy and Chinese music. It endows calligraphy writing with a novel auditory representation to create an artistic experience.","1.	Minor expression in abstract has been changed: “Chinese ink-brush calligraphy and Chinese music, by endowing the process of calligraphy writing with a novel auditory representation in a natural and intuitive manner to create a novel artistic experience. Our system simulates the effect of writing on an infinitely large piece of paper viewed through a viewport.” to “Chinese ink-brush calligraphy and Chinese music. Our system endows the process of calligraphy writing with a novel auditory representation in a natural and intuitive manner to create a novel artistic experience. The writing effect is simulated as though the user were writing on an infinitely large piece of paper viewed through a viewport. ” \  \ 2.	Minor expression in “Music generation” has been changed: “The order of presentation of the notes was randomized to eliminate order effects.” to “The order of presentation of the notes was randomized and the experiments repeated multiple times to eliminate order effects.” \  \ 3.	Acknowledgements has been changed to: “We would like to acknowledge the late Dr. Jenny C.C. Chung, who was part of the inspiration for this project; Simon S.H. Lui and Jason T.P. Tse, who worked on early precursors of the model; the experiment subjects for their help, and the anonymous referees for their comments, suggestions and encouragements.” \  \ 4.	Figure 5 has been replaced. \ ","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ H.5.5 [Information Interfaces And Presentation]: Sound and Music Computing \ ","","FormatComplete","1","","Feb 22 09:21",""
"in174","A","Mobile ActDresses: Programming Mobile Devices by Accessorizing","Mattias","Jacobsson","majac@sics.se","inpaper174.pdf","4","letter","","","Mattias Jacobsson, Ylva Fernaeus, Stina Nylander","Mattias","","Jacobsson","majac@sics.se","Mobile Life @ SICS","Kista","","Sweden","","","","","Ylva","","Fernaeus","ylva@sics.se","Mobile Life @ SICS","Kista","","Sweden","KTH","Stockholm","","Sweden","Stina","","Nylander","stny@sics.se","Mobile Life @ SICS","Kista","","Sweden","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Mattias Jacobsson","majac@sics.se","yes","Mobile ActDresses is a design concept where existing practices of accessorizing, customization and manipulation of a physical mobile device is coupled with the behaviour of its software. With this interactivity demonstrator we will provide a hands on experience of doing this kind of playful manipulation. We provide two examples for how to implement Mobile ActDresses using quick’n dirty hacks to create custom shells and jewellery for controlling the behaviour of the phone.","1. Fernaeus, Y. and Jacobsson, M. (2009). Comics, Robots, Fashion and Programming: outlining the concept of actDresses. TEI'09, Cambridge, UK, ACM. \ 2. Fernaeus, Y., Tholander, J., et al. (2008). ""Beyond representations: Towards an action-centric perspective on tangible interaction."" International Journal of Arts and Technology 1(3/4): 249-267. \ 3. Jacobsson, M. (2009). Play, Belief and Stories about Robots: A Case Study of a Pleo Blogging Community Ro-Man, IEEE. \ 4. Jacobsson, M., Fernaeus, Y., et al. (2010). The Look, the Feel and the Action: Making Sets of ActDresses for Robotic Movement DIS'10. \ 5. Katz, J. E. and Sugiyama, S. (2006). ""Mobile phones as fashion statements: evidence from student surveys in the US and Japan."" New Media Society 8(2): 321337. \ 6. Ljungstrand, P., Redström, J., et al. (2000). WebStickers: using physical tokens to access, manage and share bookmarks to the Web. DARE, ACM \ 7. Sung, J., Grinter, R. E., et al. (2009). ""Pimp My Roomba"": designing for personalization. CHI'09. Boston, MA, USA, ACM: 193-196. \ 8. Ullmer, B., Ishii, H., et al. (1998). mediaBlocks: physical containers, transports, and controls for online media. Computer graphics and interactive techniques, ACM \ ","Mobile Devices; Tangible Interaction; Accessorizing","infile174-1.doc","","","Mobile ActDresses is a design concept where existing practices of accessorizing, customization and manipulation of a physical mobile device is coupled with the behaviour of its software.","No major changes made. We will however carefully reflect upon the reviewers comments and make sure that the audience gets hands on experience of trying out the Mobile ActDresses concept as well as discuss some of the broader implications.","H.5.2 [Information Interfaces And Presentation]: User Interfaces - Interaction styles;","","FormatComplete","2","","Jan  9 08:19",""
"in177","A","Scoop! A Movement-based Math Game Designed to Reduce Math Anxiety","Katherine","Isbister","isbister@poly.edu","inpaper177.pdf","4","letter","","","Katherine Isbister, Mike Karlesky, Jonathan Frye, Rahul Rao","Katherine","","Isbister","isbister@poly.edu","NYU-Poly","New York","New York","United States","Polytechnic Institute of NYU","Brooklyn","New York","United States","Mike","","Karlesky","mike@karlesky.net","Polytechnic Institute of NYU","Brooklyn","New York","United States","","","","","Jonathan","","Frye","jonathanmfrye@gmail.com","New York University","New York","New York","United States","","","","","Rahul","","Rao","rao.rahul@hotmail.com","Polytechnic Institute of NYU","Brooklyn","New York","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Katherine Isbister","katherine.isbister@gmail.com","yes","In this paper, we describe Scoop!, a movement-based game designed to reduce math anxiety. The game makes use of research on the effects of ‘power poses’ to explore whether movement mechanics can shift feelings about math for players. The Interactivity demonstration includes both a ‘high power’, Kinect-driven version of the game, and a ‘low power’, track-pad-driven version of the game. CHI attendees can try out both versions to physically experience the effects. ","[1]	Games for Learning Institute (http://g4li.org).  \ [2]	Ashcroft, M.H. (2002). Math Anxiety: Personal, Educational, and Cognitive Consequences. Current Directions in Psychological Science October 2002 11(5):181-185. \ [3]	Carney, D.R., Cuddy, A.J.C., and Yap, A.J. (2010). Power posing: Brief nonverbal displays affect neuroendrocrine levels and risk tolerance. Psychological Science 21, 10 (October 2010), 1363-1368. \ [4]	Churchill, E. (2011). Missing the point. Interactions 18(5): 80-83. \ [5]	Isbister, K. and DiMauro, C. (2011). Waggling the Form Baton: Analyzing Body- Movement-Based Design Patterns in Nintendo Wii Games, Toward Innovation of New Possibilities for Social and Emotional Experience. In Whole Body Interaction, Springer. \ [6]	Isbister, K. (2011). Emotion and Motion: Games as Inspiration for Shaping the Future of Interface. Interactions, September/October 2011. \ [7]	Isbister, Schwekendiek, Frye. (2011). Wriggle: An Exploration of Social and Emotional Effects of Movement. Work in Progress presented at CHI 2011. \ [8]	Isbister, Rao, Schwekendiek, Hayward, Lidasan. (2011). Is More Movement Better? A Controlled Comparison of Movement-based Games. Poster presented at Foundations of Digital Gaming 2011, Bordeaux, France.  \  \ ","Movement-based games, whole body interaction, games for learning, affective computing.","infile177-1.doc","infile177-2.jpg","infile177-3.mov","Scoop! is a movement-based game designed to reduce math anxiety. Scoop! uses research on effects of ‘power poses’ to explore whether movement mechanics can shift feelings about math for players.  \ ","We read over reviews and did not see any changes that needed to be made. We plan to look for movement-game citations that we will use for the full paper once study results are in, and thank the reviewers for asking us to look out for these. ","No ACM Classifications were found.  Perhaps they are not formatted correctly?  The classifications should be formatted like this: \  \   A.1.2 [Second level descriptor]: Third level descriptor - Fourth level descriptor; \  \ with the code, then the second level descriptor in brackets, then a colon, then the third level descriptor, then a hyphen, then the fourth level descriptor, then a semicolon at the very end. \ ","","FormatComplete","2","","Jan 14 14:52",""
"in180","A","Augmenting the Scope of Interactions with Implicit and Explicit Graphical Structures","Stéphane","Conversy","conversy@gmail.com","","","","","","Raphaël Hoarau, Stéphane Conversy","Raphaël","","Hoarau","raphael.hoarau@enac.fr","Université de Toulouse - ENAC/IRIT","Toulouse","","France","","","","","Stéphane","","Conversy","stephane.conversy@enac.fr","Université de Toulouse - ENAC/IRIT, Toulouse","Toulouse","","France","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 10:15",""
"in182","A","Interactive Paper Substrates to Support Musical Creation","Jérémie","Garcia","jeremie.garcia@lri.fr","","","","","","Jérémie Garcia, Theophanis Tsandilas, Carlos Agon, Wendy Mackay","Jérémie","","Garcia","jeremie.garcia@lri.fr","INRIA","Orsay","","France","IRCAM","Paris","","France","Theophanis","","Tsandilas","fanis@lri.fr","INRIA","Orsay","","France","","","","","Carlos","","Agon","carlos.agon@ircam.fr","IRCAM","Paris","","France","","","","","Wendy","","Mackay","mackay@lri.fr","INRIA","Paris","","France","Stanford University","Palo Alto","California","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 10:29",""
"in184","A","Beyond Stereo: An Exploration of Unconventional Binocular Presentation for Novel Visual Experience","Haimo","Zhang","zh.hammer@gmail.com","","","","","","Haimo Zhang, Xiang Cao, Shengdong Zhao","Haimo","","Zhang","zh.hammer@gmail.com","Microsoft Research Asia","Beijing","","China","National University of Singapore","Singapore","","Singapore","Xiang","","Cao","xiangc@microsoft.com","Microsoft Research Asia","Beijing","","China","","","","","Shengdong","","Zhao","zhaosd@comp.nus.edu.sg","National University of Singapore","Singapore","","Singapore","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 10:45",""
"in186","A","Miniature Alive: Augmented Reality-based Interactive DigiLog Experience in Miniature Exhibition","Woontack","Woo","wwoo@gist.ac.kr","inpaper186.pdf","4","A4","Verdana Arial-BoldMT Verdana-Bold Verdana-Italic ArialMT","","Taejin Ha, Kiyoung Kim, Nohyoung Park, Sangchul Seo, Woontack Woo","Taejin","","Ha","tha@gist.ac.kr","KAIST U-VR Lab.","Daejeon","","Korea, Republic of","","","","","Kiyoung","","Kim","kkim@gist.ac.kr","GIST CTI","Gwangju","","Korea, Republic of","","","","","Nohyoung","","Park","npark@gist.ac.kr","KAIST U-VR Lab.","Gwangju","","Korea, Republic of","","","","","Sangchul","","Seo","scseo@gist.ac.kr","GIST CTI","Gwangju","","Korea, Republic of","","","","","Woontack","","Woo","wwoo@gist.ac.kr","KAIST U-VR Lab.","Daejeon","","Korea, Republic of","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Woontack Woo","wwoo@kaist.ac.kr","yes","In this paper, we present Miniature Alive, a next-generation interactive miniature exhibition that provides a DigiLog experience that combines aesthetic/spatial feelings with an analog miniature and dynamic interaction with digitalized 3D content by exploiting augmented reality (AR) technology. Using our Miniature Alive, exhibition visitors can enjoy virtual storytelling in the physical miniature by turning a page of an e-book, interacting with augmented 3D objects through their mobile phones, and even change the original story. Our work is useful in guiding the design and implementation of new miniature exhibitions.","[1]	T. Ha, Y. Lee, and W. Woo, “Digilog Book for Temple Bell Tolling Experience based on Interactive Augmented Reality with Culture Technology,” Virtual Reality (Springer), 15(4), pp. 295-309, 2010. \ [2]	K. Kim, Y. Park, and W. Woo, “Digilog Miniature: Real-time, Immersive, and Interactive AR on Miniatures,” VRCAI, pp. 161-167, 2010. \ [3]	D. Wagner, T. Pintaric, F. Ledermann, D. Schmalstieg, “Towards Massively Multi-User Augmented Reality on Handheld Devices,” Pervasive, pp. 208-219, 2005.  \ ","Augmented Reality; DigiLog Experience; Interactive Storytelling; Markerless Tracking; 3D Interaction","infile186-1.docx","infile186-2.jpg","infile186-3.wmv","A next-generation interactive miniature exhibition that provides a DigiLog experience that combines aesthetic/spatial feelings with an analog miniature and dynamic interaction with digitalized 3D content by exploiting augmented reality technology.","- We added and mentioned a related work suggested by reviewers. \ - We updated a little bit writing on the future work.  \ - We followed the fortmating guidelines.","H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems \ H.5.2 [Information Interfaces And Presentation]: User Interfaces \ ","","FormatComplete","2","","Jan  9 19:40",""
"in189","A","An Approach and Evaluation of Interactive System synchronizing change of taste and visual contents","","","","","","","","","Hiromi Nakamura, Homei Miyashita","Hiromi","","Nakamura","hirominakamura.b@gmail.com","Meiji University","Kawasaki City","Kanagawa","Japan","","","","","Homei","","Miyashita","homei@isc.meiji.ac.jp","Meiji University","Kawasaki City","Kanagawa","Japan","CREST","5 Sanban-cho, Chiyoda-ku","Tokyo","Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 19:04",""
"in190","A","TEROOS: A Wearable Avatar to Enhance Joint Activities","Tadakazu","Kashiwabara","kashi@ayu.ics.keio.ac.jp","inpaper190.pdf","4","letter","","","Tadakazu Kashiwabara, Hirotaka Osawa, Kazuhiko Shinozawa, Michita Imai","Tadakazu","","Kashiwabara","kashi@ayu.ics.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","Hirotaka","","Osawa","osawa@ayu.ics.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","Kazuhiko","","Shinozawa","shino@atr.jp","ATR Intelligent Robotics and Communication Laboratories","Soraku-gun","Kyoto","Japan","","","","","Michita","","Imai","michita@ayu.ics.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Tadakazu Kashiwabara","kashi@ayu.ics.keio.ac.jp","no","This paper proposes a wearable avatar named TEROOS, which is mounted on a person's shoulder. TEROOS allows the users who wear it and control it to share a vision remotely. Moreover, the avatar has an anthropomorphic face that enables the user who controls it to communicate with people co-located with the user who wears it. We have a field test by using TEROOS and observed that the wearable avatar innovatively assisted the users to communicate during their joint activities such as route navigating and buying goods at a shop. The user controlling TEROOS could give the user wearing it appropriate route instructions on the basis of the situation around TEROOS. In addition, both users could easily identify objects that they discussed. Moreover, shop staff members communicated with the user controlling TEROOS and behaved as they normally would when the user asked questions about the goods.","1. Adalgeirsson, S. O., and Breazeal, C. Mebot: a robotic platform for socially embodied presence. In Proc. HRI ’10, ACM Press (2010), 15–22. \ 2. Anybots’ QB. https://www.anybots.com/. \ 3. Li, L., Cox, B., Diftler, M., Shelton, S., and Rogers, B. Development of a telepresence controlled ambidextrous robotfor space applications. In Proc. IEEE ICRA ’96 (1996), 58–63. \ 4. Michaud, F., Boissy, P., Corriveau, H., Grant, A., Lauria, M. andLabonte, D., Cloutier, R., Roux, M., Royer, M., and Iannuzzi, D. Telepresence robot for home care assistance. In Proc. AAAI-06 (2006), 15–22. \ 5. Sekiguchi, D., Inami, M., and Tachi, S. Robotphone: Rui for interpersonal communication. In Proc. CHI EA ’01, ACM Press (2001), 277–278. \ 6. Tsai, T., Hsu, Y., Ma, A., King, T., and Wu, C. Developing atelepresence robot for interpersonal communication with theelderly in a home environment. Telemedicine and e-Health 13, 4 (2007), 407–424. \ 7. Tsumaki, Y., Fujita, Y., Kasai, A., Sato, C., Nenchev, D. N., and Uchiyama, M. Telecommunicator: A novel robot system for human communications. In Rroc. IEEE RO-MAN’02 (2002), 35–40. \ ","Wearable avatar; avatar communication; shared vision; social \ response; field test.","infile190-1.tex","infile190-2.jpg","infile190-3.mp4","The note describes what communication style a wearable robot avatar \ offers to daily life situations. Two users can communicate by sharing \ their vision via the robot avatar.","Since PC's letter indicated that we should revise English problems in our \ paper and that we should mention that our work needs further evaluations, \ we modified our paper along the indication. \  \ First, we added a new paragraph at the end of ""DISCUSSION AND CONCLUSION"" \ (at the bottom of right column, page4, line 22-line 30). Main weak point \ of our paper is that we had only one pair of users to evaluate of our \ system. Thus, we wrote that we must conduct a further evaluation by \ gathering more participants to obtain general conclusions. Moreover, we \ would like to improve our system by implementing technical functions. So, \ we wrote  functions expected to improve TEROOS. \  \ Second, a native English speaker checked our paper and we revised it \ based on the check. \  \ We hope that this revision satisfies the AC's consideration.","H.5.3 [Information Interfaces And Presentation]: Group and Organization Interfaces \ ","","","2","","Jan  9 12:21",""
"in197","A","Animating Paper Craft using Shape Memory Alloys","Jie","Qi","jieqi@mit.edu","","","","","","Jie Qi, Leah Buechley","Jie","","Qi","jieqi@mit.edu","MIT Media Lab","Cambridge","MA","02139","","","","","Leah","","Buechley","leah@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 18:49",""
"in198","A","Stackables: Faceted Browsing with Stacked Tangibles","Raimund","Dachselt","dachselt@acm.org","inpaper198.pdf","4","letter","","","Petra Isenberg, Stefanie Klum, Ricardo Langner, Jean-Daniel Fekete, Raimund Dachselt","Petra","","Isenberg","petra.isenberg@inria.fr","INRIA","Paris","","France","","","","","Stefanie","","Klum","stefanie.klum@steelis.net","University of Magdeburg","Magdeburg","","Germany","","","","","Ricardo","","Langner","rlangner@ovgu.de","University of Magdeburg","Magdeburg","","Germany","","","","","Jean-Daniel","","Fekete","Jean-Daniel.Fekete@inria.fr","INRIA","Paris","","France","","","","","Raimund","","Dachselt","dachselt@acm.org","University of Magdeburg, Magdeburg, Germany","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Raimund Dachselt","dachselt@acm.org","yes","We demonstrate Stackables, tangible widgets designed for individual and collaborative faceted browsing. In contrast, current interfaces for browsing and search in large data spaces largely focus on supporting either individual or collaborative activities. Each stackable facet token represents search parameters that can be shared amongst collaborators, modified, and stored. We show how individuals or multiple people can interact with Stackables and combine them to formulate queries on realistic datasets. We have successfully used and evaluated Stackables in a user study with a dataset of over 1500 books and 12 facets with ranges of thousands of facet values.","1. C. Ahlberg and B. Shneiderman. The alphaslider: a compact and rapid selector. In Proc. of CHI, 365–371, New York, NY, USA, 1994. ACM. \ 2. P. G. Anick, J. D. Brennan, R. A. Flynn, R. R. Hanssen, B. Alvey, and J. M. Robbins. A direct manipulation interface for boolean information retrieval via natural language query. In Proc. SIGIR, 135–150. ACM, 1990. \ 3. P. Baudisch, T. Becker, and F. Rudeck. Lumino: Tangible blocks for tabletop computers based on glass ﬁber bundles. In Proc. of CHI, 1165–1174, USA, 2010. ACM. \ 4. R. Dachselt, M. Frisch, and M. Weiland. Facetzoom: A continuous multi-scale widget for navigating hierarchical metadata. In Proc. of CHI, 1353–1356, USA, 2008. ACM. \ 5. P. Isenberg, D. Fisher, M. Ringel Morris, K. Inkpen, and M. Czerwinski. An Exploratory Study of Co-located Collaborative Visual Analytics around a Tabletop Display. In Proc. of VAST, 179–186. IEEE, 2010. \ 6. H.-C. Jetter, J. Gerken, M. Zöllner, H. Reiterer, and N. Milic-Frayling. Materializing the query with facet-streams: A hybrid surface for collaborative search on tabletops. In Proc. of CHI, 3013–3022, USA, 2011. ACM. \ 7. B. Lee, G. Smith, G. G. Robertson, M. Czerwinski, and D. S. Tan. Facetlens: Exposing trends and relationships to support sensemaking within faceted datasets. In Proc. of CHI, 1293–1302, USA, 2009. ACM. \ 8. B. Ullmer, H. Ishii, and R. J. K. Jacob. Tangible query interfaces: Physically constrained tokens for manipulating database queries. In Proc. of Interact, 279–286, Netherlands, 2003. IOS Press. \ 9. D. Young and B. Shneiderman. A graphical ﬁlter/ﬂow representation of boolean queries: A prototype implementation and evaluation. Journal of the American Society for Information Science and Technology, 44:327–339, 1993. \ ","Tangible User Interfaces; Faceted Browsing & Search; Co-located Collaboration; Collaborative Search; Embodied Interaction \ ","infile198-1.tex","infile198-2.jpg","infile198-3.mp4","We demonstrate Stackables - tangible widgets designed for \ individual and collaborative faceted browsing. Each stackable facet token represents search parameters and can be combined to formulate queries on realistic datasets. \ ","Thanks for the helpful reviews. With regards to the comments of the meta reviewer we made the following changes \  \ - Did a more thorough literature review in the field of IR and included Anick et al. 1990, Young & Shneiderman 1993. Of course, on four pages of an interactivity paper, more than nine references are hard to handle (but we are quite aware of other work, too). \ - Carefully rewrote parts of the paper to address the mentioned concerns \ - Emphasized the individual OR collaborative usage of stackables, which differentiates our solution from traditional GUI solutions. Tangibles, which can be manipulated and stacked individually and later combined collaboratively to express powerful queries, really differ in their almost casual way of usage. \  \ We finally invite you to step by our CHI booth and try the difference between a stacked tangibles solution vs. a traditional GUI interface yourself. We hope, you will be convinced. \ ","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  \ Input devices and strategies","","FormatComplete","2","","Jan  9 18:54",""
"in199","A","GraphTrail: Analyzing Large Multivariate, Heterogeneous Networks while Supporting Exploration History","Cody","Dunne","cdunne@cs.umd.edu","","","","","","Cody Dunne, Nathalie Henry Riche, Bongshin Lee, Ronald Metoyer, George Robertson","Cody","","Dunne","cdunne@cs.umd.edu","Microsoft Research","Redmond","Washington","United States","University of Maryland","College Park","Maryland","United States","Nathalie","","Henry Riche","nath@microsoft.com","Microsoft Research","Redmond","Washington","United States","","","","","Bongshin","","Lee","bongshin@microsoft.com","Microsoft Research","Redmond","Washington","United States","","","","","Ronald","","Metoyer","metoyer@eecs.oregonstate.edu","Oregon State University","Corvallis","Oregon","United States","Microsoft Research","Redmond","Washington","United States","George","","Robertson","ggr@microsoft.com","Microsoft Research","Redmond","Washington","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Feb 21 11:04",""
"in200","A","Cooking with ""panavi"": Challenging to Professional Culinary Arts","Daisuke","Uriu","uriu@kmd.keio.ac.jp","","","","","incomplete","Daisuke Uriu, Mizuki Namai, Satoru Tokuhisa, Ryo Kashiwagi, Masahiko Inami, Naohito Okude","Daisuke","","Uriu","uriu@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Keio-NUS CUTE Center","","","","Mizuki","","Namai","mizukichen@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Keio-NUS CUTE Center","","","","Satoru","","Tokuhisa","dangkang@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Keio-NUS CUTE Center","","","","Ryo","","Kashiwagi","kashiwagi@toyo.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Keio-NUS CUTE Center","","","","Masahiko","","Inami","inami@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Keio-NUS CUTE Center","","","","Naohito","","Okude","okude@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Keio-NUS CUTE Center","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","uriu@kmd.keio.ac.jp","uriu@kmd.keio.ac.jp","no","","","","","","","","","","","","2","","Jan  9 19:50",""
"in202","A","Design of an Exergaming Station for Children with  Cerebral Palsy","","","","","","","","","Hamilton Hernandez, Nicholas Graham","Hamilton","","Hernandez","hamilton@cs.queensu.ca","Queen's University","Kingston","Ontario","Canada","","","","","Nicholas","","Graham","graham@cs.queensu.ca","Queen's University","Kingston","Ontario","Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 20:00",""
"in205","A","The Chocolate Machine","Marc","Hassenzahl","marc.hassenzahl@folkwang-uni.de","","","","","","Flavius Kehr, Marc Hassenzahl, Matthias Laschke, Sarah Diefenbach","Flavius","","Kehr","flavius.kehr@web.de","University of Koblenz-Landau","Landau","","Germany","","","","","Marc","","Hassenzahl","marc.hassenzahl@folkwang-uni.de","Folkwang University of Arts","Essen","","Germany","","","","","Matthias","","Laschke","matthias.laschke@folkwang-uni.de","Folkwang University of the Arts","Essen","","Germany","","","","","Sarah","","Diefenbach","sarah.diefenbach@folkwang-uni.de","Folkwang University of Arts","Essen","","Germany","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","1","","Jan  9 14:04",""
"in206","A","Discovery-based Games for Learning Software","Tao","Dong","dongtao@umich.edu","","","","","","Tao Dong, Mira Dontcheva, Diana Joseph, Karrie Karahalios, Mark Newman, Mark Ackerman","Tao","","Dong","dongtao@umich.edu","University of Michigan","Ann Arbor","Michigan","United States","","","","","Mira","","Dontcheva","mirad@adobe.com","Adobe Systems","San Francisco","California","United States","","","","","Diana","","Joseph","dmjoseph@adobe.com","Adobe Systems","San Jose","California","United States","","","","","Karrie","","Karahalios","kkarahal@cs.uiuc.edu","University of Illinois","Urbana","Illinois","United States","","","","","Mark","","Newman","mwnewman@umich.edu","University of Michigan","Ann Arbor","Michigan","United States","","","","","Mark","","Ackerman","ackerm@umich.edu","University of Michigan","Ann Arbor","Michigan","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 13:05",""
"in207","A","PINOKY: A Ring That Animates Your Plush Toys","Yuta","Sugiura","yuta.sugiura@gmail.com","","","","","incomplete","Yuta Sugiura, Calista Lee, Masayasu Ogata, Anusha Withana, Yasutoshi Makino, Daisuke Sakamoto, Masahiko Inami, Takeo Igarashi","Yuta","","Sugiura","yuta.sugiura@gmail.com","Keio University","Yokohama","","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","","Japan","Calista","","Lee","calistalxy@gmail.com","Keio University","Yokohama","Kanagawa","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","Tokyo","Japan","Masayasu","","Ogata","ogatite@gmail.com","Keio University","Yokohama","","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","","Japan","Anusha","","Withana","anusha@kmd.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","Yasutoshi","","Makino","makino@sdm.keio.ac.jp","Keio University","Yokohama","","Japan","","","","","Daisuke","","Sakamoto","d.sakamoto@gmail.com","The University of Tokyo","Bunkyo","Tokyo","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","Tokyo","Japan","Masahiko","","Inami","inami@inami.info","Keio University","Yokohama","Kanagawa","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","","Japan","Takeo","","Igarashi","takeo@acm.org","The University of Tokyo","Bunkyo","Tokyo","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","Tokyo","Japan","","","","","","","","","","","","","","","","","","","","","","","","","Yuta Sugiura","yuta.sugiura@gmail.com","no","","","","","","","","","","","","1","","Jan  9 14:25",""
"in209","A","Virtual Projection: Exploring Optical Projection as a Metaphor for Multi-Device Interaction","Dominikus","Baur","dominikus.baur@ifi.lmu.de","","","","","","Dominikus Baur, Sebastian Boring, Steven Feiner","Dominikus","","Baur","dominikus.baur@ifi.lmu.de","University of Munich LMU","Munich","","Germany","","","","","Sebastian","","Boring","sebastian.boring@ucalgary.ca","University of Calgary","Calgary","Alberta","Canada","","","","","Steven","","Feiner","feiner@cs.columbia.edu","Columbia University","New York","New York","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 13:41",""
"in210","A","IllumiShare: Sharing Any Surface","Sasa","Junuzovic","sasa.junuzovic@microsoft.com","","10","letter","","incomplete","Sasa Junuzovic, Kori Inkpen, Tom Blank, Anoop Gupta","Sasa","","Junuzovic","sasa.junuzovic@microsoft.com","Microsoft Research","Redmond","Washington","United States","","","","","Kori","","Inkpen","kori@microsoft.com","Microsoft Research","Redmond","Washington","United States","","","","","Tom","","Blank","tomblank@microsoft.com","Microsoft Research","Redmond","Washington","United States","","","","","Anoop","","Gupta","anoop@microsoft.com","Microsoft Research","Redmond","Washington","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Sasa Junuzovic","sasa.junuzovic@microsoft.com","no","","","","infile210-1.docx","","","","","","","","2","","Feb 19 23:33",""
"in215","A","Touchbox: Intriguing Touch between Strangers","Mads","Hobye","mads.hobye@mah.se","inpaper215.pdf","4","letter","","","Mads Hobye","Mads","","Hobye","mads.hobye@mah.se","Medea Collaborative Media Initiative","Malmo","","Sweden","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","mads hobye","mads.hobye@mah.se","yes","The Touchbox is about facilitating intriguing touch interaction between strangers. The Participants each wear a pair of headphones, and when they touch each others bare skin, they both hear a complex sound pattern. Previous (successful) work involved a skilled Performer and one Participant; the Touchbox was designed to be played by pairs of pristine Participants exploring the interaction situation on their own. It turned out that their interaction experiences were quite engaging albeit more varied in mood and character. The Touchbox illustrates a novel approach to embodied interaction design where social norms are transcended by means of daring and captivating interactions.","1. Dourish, P. Where the Action Is: The Foundations of Embodied Interaction. Cambridge: The MIT Press, 2004. \ 2. Gaver, W. and Beaver, J. Ambiguity as a resource for design. In Proceedings of the SIGCHI, 2003. \ 3. Hobye, M. Mediated body: Designing for embodied experience. ACM CiE, To be published. \ 4. Hobye, M. and L¨owgren, J. Touching a stranger: Designing for engaging experience in embodied interaction. Int. J. Design, 5(3), 2011. \ 5. Salen, K., and Zimmerman, E. Rules of play: Game design fundamentals. Cambridge, MA: MIT Press., 2004. \ ","Social play, pushing norms, interactive sound, embodied interaction, bare-skin touch.","infile215-1.zip","infile215-2.jpeg","infile215-3.m4v","The Touchbox is about facilitating intriguing touch interaction between strangers.  When the participants touch each others bare skin, they both hear a complex sound pattern. ","Added: 978-1-4503-1016-1/12/05. \ Due to size limits the pdf has been compressed. If you need a larger version for print you can find it here: \  \ http://dl.dropbox.com/u/2025544/Touchbox4.pdf","H.5.m [Information interfaces and presentation (e.g., HCI)]: Miscellaneous.","","FormatComplete","1","","Feb 22 15:20",""
"in220","A","The Bohemian Bookshelf: Supporting Serendipitous Book Discoveries through Information Visualization","Uta","Hinrichs","uhinrich@ucalgary.ca","","","","","","Alice Thudt, Uta Hinrichs, Sheelagh Carpendale","Alice","","Thudt","alice.thudt@googlemail.com","University of Munich","Munich","Bavaria","Germany","","","","","Uta","","Hinrichs","uhinrich@ucalgary.ca","University of Calgary","Calgary","Alberta","Canada","","","","","Sheelagh","","Carpendale","sheelagh@ucalgary.ca","University of Calgary ","Calgary","Alberta","Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 14:57",""
"in229","A","Artistic Robot Please Smile","Hye Yeon","Nam","hnam@gatech.edu","inpaper229.pdf","4","letter","","","Hye Yeon Nam, Changhyun Choi","Hye Yeon","","Nam","hnam@gatech.edu","Georgia Institute of Technology","Atlanta","Georgia","United States","","","","","Changhyun","","Choi","cchoi@cc.gatech.edu","Georgia Institute of Technology, Atlanta, United States","Atlanta","Georgia","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Hye Yeon Nam","hnam@gatech.edu","yes","This paper explains how people interpret artistic robots as more than mere machines in the theory of intentionality and introduces the implementation of the artistic robot, Please Smile, which consists of five robotic skeleton arms that gesture in response to a viewer’s facial expressions. ","1. Brentano, F. Psychology from an Empirical Standpoint. Routledge, London and New York, 1995. \ 2. Dalal, N., Triggs, B. Histograms of oriented gradients for human detection, in IEEE Conference on Computer Vision and Pattern Recognition, (San Diego, CA, USA, 2005), IEEE CS Press, 1. 886-893. \ 3. Dennett, D. C. The Intentional Stance. The MIT Press, 1989. \ 4. Dodd, J. Robots: The New ""Steel Collar"" Workers. Personnel Journal, 60. (1981). 688-695. \ 5. Fu, K. S., Gonzalez, R. C., and Lee, C.S.G., Robotics: Control, Sensing, Vision, and Intelligence. Mcgraw-Hill Book Company, 1987. \ 6. Hunt, H. A., Hunt, T.L. The Robots are Coming. Upjohn Institute Press, Kalamazoo, MI, 1983. \ 7. The MPLab GENKI Database, GENKI-4K. Retrieved February 26, 2012, from Machine Perception Laboratory, University of California, San Diego: http://mplab.ucsd.edu/. \ 8. Viola, P. and Jones, M. J. Robust real-time face detection, International Journal of Computer Vision, 57 (2). (2004). 137–154. \ ","Artistic robots, computer vision, robotic arts, skeleton arms, smile detection algorithms","infile229-1.doc","infile229-2.jpg","","When a person steps in front of “Please Smile”, the skeleton arms point at the person and follow his/her movements. When someone smiles at it, the arms wave their hands.","Even though my reviews were positive, I updated this paper by editing smooth transitions and checked reference formats and styles. ","D.2.6 [Software Engineering]: Programming Environments \ H.5.2 [Information Interfaces And Presentation]: User Interfaces \ I.5.4 [Pattern Recognition]: Applications \ ","","FormatComplete","1","","Feb 22 15:21",""
"in231","A","A Visual Display of Sociotechnical Data","Yanni","Loukissas","yanni@mit.edu","inpaper231.pdf","4","letter","","","Yanni Loukissas, David Mindell","Yanni","","Loukissas","yanni@mit.edu","Massachusetts Institute of Technology","Cambridge","Massachusetts","United States","","","","","David","","Mindell","mindell@mit.edu","Massachusetts Institute of Technology","Cambridge","Massachusetts","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Yanni Loukissas","yanni@mit.edu","yes","Can visualization bring entangled social and technical relationships into sharper view for the broad range of professionals who study, design, or operate within complex human-machine systems? This interactive project demonstrates how visual tools can illuminate the changing meaning and importance of human presence in remote or autonomous operations. Using historical data sets from the 1969 Apollo 11 moon landing, the project presents opportunities and challenges in the visual display of sociotechnical data: integrating qualitative and quantitative sources, flattening data into graphics without losing interpretive depth, using a visual composition to tell non-linear stories. It introduces a timely and long-term endeavor, the development of a visual language and interface connecting researchers, designers, and operators in the study of human-machine teams.","Card, Stuart K., Jock Mackinlay, and Ben Shneiderman. 1999. Readings in Information Visualization: Using Vision to Think. 1st ed. San Francisco: Morgan Kaufmann, February 8. \  \ Mindell, David. Digital Apollo: Human and Machine in Spaceflight. Cambridge: MIT Press, 2008. \  \ NASA. 'Apollo 11 Range Data.' Houston, Tex.:NASA Manned Spacecraft Center, 1969. (Provided by Don Eyles) \  \ Sheridan, Thomas B. 2002. Humans and Automation: System Design and Research Issues. 1st ed. New York: Wiley-Interscience, July 11. \  \ Suchman, Lucille. 2007. Human-Machine Reconfigurations: Plans and Situated Actions. New York: Cambridge University Press. \  \ Tufte, Edward R. The Visual Display of Quantitative Information. Cheshire: Graphics Press, 2001. \ ","Human-machine Relationships; Social Studies of Technology; Data Visualization","infile231-1.doc","infile231-2.tiff","infile231-3.mp4","Using historical data sets from the 1969 Apollo 11 moon landing, the project presents opportunities and challenges in the visual display of sociotechnical data.","We sincerely appreciate all of the comments provided by reviewers. However, the short form of the extended abstract prevents us from elaborating on the project in all the ways we would have liked. In following with the reviewers' recommendations, we have succinctly explained the various ways of interacting with the project as well as how we see the general method being employed in future work.","H.1.2 [MODELS NAD PRINCIPLES]: User/Machine Systems---Human factors \ I.3.4 [COMPUTER GRAPHICS]: Methodology and Techniques  \ ","","FormatComplete","2","","Jan  9 17:40",""
"in236","A","Sketch It, Make It: Sketching Precise Drawings for Laser Cutting","Gabe","Johnson","gabe.johnson@gmail.com","inpaper236.pdf","4","letter","","","Gabe Johnson, Mark Gross, Ellen Yi-Luen Do, Jason Hong","Gabe","","Johnson","johnsogg@cmu.edu","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","Mark","","Gross","mdgross@cmu.edu","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","Ellen Yi-Luen","","Do","ellendo@gatech.edu","Georgia Institute of Technology","Atlanta","Georgia","United States","","","","","Jason","","Hong","jasonh@cs.cmu.edu","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Gabe Johnson","johnsogg@cmu.edu","yes","Sketch It, Make It (SIMI) is a modeling tool that enables non-experts \ to design items for fabrication with laser cutters. SIMI recognizes \ rough, freehand input as a user iteratively edits a structured vector \ drawing. The tool combines the strengths of sketch-based interaction \ with the power of constraint-based modeling. Several interaction \ techniques are combined to present a coherent system that makes it \ easier to make precise designs for laser cutters.","1. Bae, S.-H., Balakrishnan, R., and Singh, K. EverybodyLovesSketch: 3D sketching for a broader audience. In Proc. of ACM UIST 2009 (2009), 59–68. \ 2. Fitzgibbon, A. W.and Pilu, M., and Fisher, R. B. Direct least-squares ﬁtting of ellipses. IEEE Trans. Pattern Analysis and Machine Intelligence 21, 5 (1999), 476–480. \ 3. Igarashi, T., Matsuoka, S., Kawachiya, S., and Tanaka, H. Interactive beautiﬁcation: a technique for rapid geometric design. In Proc. of ACM UIST 1997, ACM (New York, NY, USA, 1997), 105–114. \ 4. Johnson, G., Gross, M. D., and Do, E. Y.-L. Flow selection: A time-based selection and operation technique for sketching tools. In 2006 Conference on Advanced Visual Interfaces (Venice, Italy, 2006), 83–86. \ 5. Naya, F., Contero, M., Aleixos, N., and Company, P. Parsketch: a sketch-based interface for a 2d parametric geometry editor. In Proc. Intnl conf. of HCI 2007, HCI’07, Springer-Verlag (Berlin, Heidelberg, 2007), 115–124. \ 6. Wolin, A., Paulson, B., and Hammond, T. Sort, merge, repeat: An algorithm for eﬀectively ﬁnding corners in hand-sketched strokes. In Proceedings of Eurographics 6th Annual Workshop on Sketch-Based Interfaces and Modeling (2009). \ 7. Zeleznik, R. C., Bragdon, A., Liu, C.-C., and Forsberg, A. Lineogrammer: creating diagrams by drawing. In Proc. of ACM UIST 2008, ACM (New York, NY, USA, 2008), 161–170. \ ","sketching, design, rapid fabrication, laser cutter","infile236-1.zip","","","Sketch It, Make It is a modeling tool that lets non-experts to design specifications for items for fabrication with laser cutters.","Meta-review made no demands. \  \ Addressed most of R1 and R2's comments. Clarified the contributions and context. Directly addressed R2's list of 3 items.  \  \ ** Updated the title to use capital letters on Feb 26 **","I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling \ ","","FormatComplete","2","","Jan  9 16:43",""
"in238","A","TAP & PLAY: An End-User Toolkit for Authoring Interactive Pen and Paper Language Activities","Anne Marie","Piper","ampiper@gmail.com","","","","","","Anne Marie Piper, Nadir Weibel, James Hollan","Anne Marie","","Piper","ampiper@gmail.com","University of California, San Diego","La Jolla","California","United States","","","","","Nadir","","Weibel","weibel@ucsd.edu","University of California San Diego","La Jolla","California","United States","","","","","James","","Hollan","hollan@cogsci.ucsd.edu","University of California, San Diego","La Jolla","California","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 20:59",""
"in242","A","AHNE : A Novel Interface for Spatial Interaction","Koray","Tahiroglu","koray.tahiroglu@aalto.fi","inpaper242.pdf","4","letter","","","Matti Niinimäki, Koray Tahiroglu","Matti","","Niinimäki","matti.niinimaki@aalto.fi","Aalto University","Helsinki","","Finland","","","","","Koray","","Tahiroglu","koray.tahiroglu@aalto.fi","Aalto University","Helsinki","","Finland","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Koray Tahiroglu","koray.tahiroglu@aalto.fi","yes","In this paper we describe AHNE (Audio-Haptic Navigation Environment). It is a three-dimensional user interface (3D UI) for manipulating virtual sound objects with natural gestures in a real environment. AHNE uses real-time motion tracking and custom-made glove controllers as input devices, and auditory and haptic feedback as the output. We present the underlying system and a possible use for the interface as a musical controller.","1. Bowman, D. A., Chen, J., Wingrave, C. A., Lucas, J., Ray, A., Polys, N. F., Li, Q., et al. New Directions in 3D User Interfaces. The International Journal of Virtual Reality, 5(2), (2006), 3–14. \ 2. Jacob, R. J. K., Girouard, A., Hirshfield, L. M., Horn, M. S., Shaer, O., Solovey, E. T., and Zigelbaum, J. Reality-based interaction: unifying the new generation of interaction styles. Ext. Abstracts CHI 2007. ACM (2007). \ 3. Jacob, R. J. K., Girouard, A., Hirshfield, L. M., Horn, M. S., Shaer, O., Solovey, E. T., and Zigelbaum, J. Reality-based interaction: a framework for post-WIMP interfaces. In Proc. CHI 2008. ACM (2008), 201-210. \ 4. Magnusson, C., Danielsson, H., and RassmusGröhn, K. Non Visual Haptic Audio Tools for Virtual Environments. Haptic and Audio Interaction Design. Springer Berlin / Heidelberg (2006), 111–120. \ 5. OpenNI. http://www.openni.org/. \ 6. OSCeleton. https://github.com/Sensebloom/OSCeleton. \ 7. Xu, C., Israr, A., Poupyrev, I., Bau, O., & Harrison, C. Tactile display for the visually impaired using TeslaTouch. Ext. Abstracts CHI 2011, ACM (2011), 317–322. \ ","AHNE, Audio-haptic, non-visual, 3D UI, Reality Based Interaction, augmented reality, music, mobile.","infile242-1.docx","","infile242-3.mov","AHNE is a novel interface for spatial interaction that allows the user to locate and manipulate virtual sound objects with natural gestures in a real environment.","ACM Classification Keywords, Acknowledgements","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Interaction Styles, Auditory (non-speech) Feedback, Haptic I/O \ ","","FormatComplete","2","","Jan 10 02:15",""
"in245","A","The Envisioning Cards: A Toolkit for Catalyzing Humanistic and Technical Imaginations","Batya","Friedman","batya@uw.edu","","","","","","Batya Friedman, David Hendry","Batya","","Friedman","batya@uw.edu","University of Washington","Seattle","Washington","United States","","","","","David","","Hendry","dhendry@u.washington.edu","University of Washington ","Seattle","Washington","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","1","","Jan  9 20:15",""
"in246","A","BodiPod: Interacting with 3D Human Anatomy via a 360° Cylindrical Display","Roel","Vertegaal","roel@cs.queensu.ca","inpaper246.pdf","4","letter","","","John Bolton, Peng Wang, Kibum Kim, Roel Vertegaal","John","","Bolton","bolton@cs.queensu.ca","Human Media Lab, Queen's University","Kingston","Ontario","Canada","","","","","Peng","","Wang","peng@cs.queensu.ca","Human Media Lab, Queen's University, Kingston","Kingston","Ontario","Canada","","","","","Kibum","","Kim","kibum@cs.queensu.ca","Human Media Lab, Queen's University","Kingston","Ontario","Canada","","","","","Roel","","Vertegaal","roel@cs.queensu.ca","Human Media Lab, Queen's University","Kingston","Ontario","Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Roel Vertegaal","roel@cs.queensu.ca","yes","We present BodiPod, a 3D 360 degree stereoscopic human anatomy browser. Our cylindrical display allows users to view a human anatomy volume at full scale from any perspective. Shutter glasses are only required if users want to examine the data stereoscopically. Users can change views simply by walking around the display volume, and interact with the human anatomy model inside the display through gesture and speech interactions, which include scaling, rotation, peeling, slicing and labeling. Our demonstration shows that using a cylindrical display has the benefits of providing stereoscopic rendering of human anatomy models at life-size scale that can be examined from any angle, while allowing interactions from an appropriate viewing distance. ","1. Benko, H. Beyond Flat Surface Computing: Challenges of Depth-aware and Curved Interfaces. In Proc. MM 2009, ACM Press (2009), 935-944. \ 2. Beyer, G., et al. Audience Behavior Around Large Interactive Cylindrical Screens. In Proc CHI '11. ACM Press (2011), 1021-1030. \ 3. Downing, E., Hesselink, L., Ralston, J. and Macfarlane, R. A Three-Color, Solid-State, Three-Dimensional Display. Science 273, (1996) 1185-1189. \ 4. DynaScan’s 360° display. http://www.dynascanusa.com/ \ 5. Gibson, E. J., Gibson, J. J., Smith, O. W., and Flock, H. Motional Parallax as a Determinant of Perceived Depth. Journal of Exp Psychology 58 1 (1959), 40-51. \ 6. Jones, A., Bolas, M., McDowall, I., Yamada, H., and Debevec, P. Rendering for an Interactive 360 Degree Light Field Display, In Proc. SIGGRAPH 2007, ACM Press (2007). \ 7. Litefast MAGIC display. http://www.litefastdisplay.com/ \ 8. TurboSquid. http://www.turbosquid.com/ \ 9. Williams, R.D., Wefer, F.L., and Clifton, T.E. Direct Volumetric Visualization. In Proc. IEEE Visualization (1992), 99-106. Figure 5. Labeling Interaction. \ ","Cylindrical Displays; Human Anatomy; Organic User Interfaces","infile246-1.doc","infile246-2.jpg","infile246-3.mov","BodiPod is a cylindrical display that features stereoscopic browsing of a 3D human anatomy model preserving full 360 degree motion parallax, allowing users to walk around the model.","N/A","H5.2 [Information interfaces and presentation]: User Interfaces – Miscellaneous.","","FormatComplete","2","","Jan  9 21:12",""
"in249","A","ZeroTouch: An Optical Multi-Touch and Free-Air Interaction Architecture","Jonathan","Moeller","jmoeller@gmail.com","","","","","incomplete","Jonathan Moeller, Andruid Kerne, William Hamilton, Andrew Webb, Nicholas Lupfer","Jonathan","","Moeller","jmoeller@gmail.com","Interface Ecology Lab","College Station","Texas","United States","Texas A&M University","College Station","Texas","United States","Andruid","","Kerne","andruid@ecologylab.net","Interface Ecology Lab, Center for Study of Digital Libraries, Texas A&M Computer Science Department","College Station","Texas","United States","Texas A&M University","College Station","Texas","United States","William","","Hamilton","luin.uial@gmail.com","Interface Ecology Lab, Texas A&M University","College Station","Texas","United States","Interface Ecology Lab, Texas A&M University","College Station","Texas","United States","Andrew","","Webb","awebb@cs.tamu.edu","Interface Ecology Lab, Texas A&M University","College Station","Texas","United States","Texas A&M University","College Station","Texas","United States","Nicholas","","Lupfer","nlupfer@tamu.edu","Interface Ecology Lab, Texas A&M University","College Station","Texas","United States","Texas A&M University","College Station","Texas","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Jon Moeller","jmoeller@gmail.com","no","","","","","","","","","","","","2","","Jan  9 20:10",""
"in252","A","QuickDraw : Improving Drawing Experience for Geometric Diagrams","Salman","Cheema","salmanc@cs.ucf.edu","","","","","","Salman Cheema, Sumit Gulwani, Joseph LaViola","Salman","","Cheema","salmanc@cs.ucf.edu","University of Central Florida","Orlando","Florida","United States","","","","","Sumit","","Gulwani","sumitg@microsoft.com","Microsoft","Redmond","WA","USA","","","","","Joseph","","LaViola","jjl@cs.ucf.edu","University of Central Florida","Orlando","Florida","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 19:11",""
"in253","A","FlexCam – Using Thin-film Flexible OLED Color Prints as a Camera Array","Connor","Dickie","connord@media.mit.edu","inpaper253.pdf","4","letter","","","Connor Dickie, Nicholas Fellion, Roel Vertegaal","Connor","","Dickie","connor@cs.queensu.ca","Human Media Lab, Queen's University.","Kingston","Ontario","Canada","","","","","Nicholas","","Fellion","nick.fellion@gmail.com","Human Media Lab, Queen's University.","Kingston","Ontario","Canada","","","","","Roel","","Vertegaal","roel@cs.queensu.ca","Human Media Lab, Queen's University.","Kingston","Ontario","Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Connor Dickie","connord@alumni.media.mit.edu","yes","FlexCam is a novel compound camera platform that explores interactions with color photographic prints using thinfilm flexible color displays. FlexCam augments a thinfilm color Flexible Organic Light Emitting Diode (FOLED) photographic viewfinder display with an array of lenses at the back. Our prototype allows for the photograph to act as a camera, exploiting flexibility of the viewfinder as a means to dynamically re-configure images captured by the photograph. FlexCam’s flexible camera array has altered optical characteristics when flexed, allowing users to dynamically expand and contract the camera's field of view (FOV). Integrated bend sensors measure the amount of flexion in the display. The degree of flexion is used as input to software, which dynamically stitches images from the camera array and adjusts viewfinder size to reflect the virtual camera’s FOV. Our prototype envisions the use of photographs as cameras in one aggregate flexible, thin-film device.","[1] Mann, S. Picard, R. W. Video Orbits of the Projective Group: A Simple Approach to Featureless Estimation of Parameters. IEEE Transactions on Image Processing 6, 9 (1997). 1281-95. \ [2] Nomura, Y. Zhang, L. Nayar, S. Scene Collages and Flexible Camera Arrays. In Proc. Eurographics Symposium on Rendering 2007. \ [3] Schwesig, C. Poupryev, I. Mori, E. Gummi: A bendable computer. In Proc. CHI 2004. ACM Press (2004). 263-270. \ [4] Lahey, B. Girouard, A. Burleston, W. Vertegaal, R. Paperphone: Understanding the Use of Bend Gestures in Mobile Devices with Flexible Electronic Paper Displays. In Proc. CHI 2011, ACM Press (2011). \ [5] Unibrain Fire-i, http://www.unibrain.com/  \ [6] MAX/MSP/Jitter, http://cycling74.com/","Organic User Interfaces; Flexible Camera Arrays; Flexible Displays; Tangible User Interfaces.","infile253-1.doc","infile253-2.jpg","infile253-3.mov","FlexCam uses flexion to dynamically reconfigure the camera’s optical characteristics and as input to a realtime image-stitching algorithm enabling a dynamic viewfinder parametric to the camera’s physical configuration.","nil.","H.5.2 [Information Interfaces And Presentation]: User Interfaces - Interaction styles;","","FormatComplete","2","","Jan  9 20:51",""
"in254","A","Toolset to explore visual motion designs in a video game","David","Milam","dma35@sfu.ca","inpaper254.pdf","4","letter","Helvetica-Bold Helvetica","","David Milam, Magy Seif El-Nasr, Lyn Bartram, Matt Lockyer, Chao Feng, Perry Tan","David","","Milam","dma35@sfu.ca","School of Interactive Arts + Technology (SIAT)","Surrey","British Columbia","Canada","","","","","Magy","","Seif El-Nasr","magy@northeastern.edu","Northeastern University","Boston","Massachusetts","USA","","","","","Lyn","","Bartram","lyn@sfu.ca","School of Interactive Arts and Technology","Surrey","British Columbia","Canada","","","","","Matt","","Lockyer","mlockyer@sfu.ca","School of Interactive Arts + Technology (SIAT), Surrey","Surrey","British Columbia","Canada","","","","","Chao","","Feng","chao_feng@sfu.ca","School of Interactive Arts + Technology (SIAT), Surrey","Surrey","British Columbia","Canada","","","","","Perry","","Tan","pta13@sfu.ca","School of Interactive Arts + Technology (SIAT), Surrey","Surrey","British Columbia","Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","David Milam","dma35@sfu.ca","yes","We describe a research toolset to explore visual designs in a video game. We focus specifically on visual motion, defined by attributes of motion, and their effect on accessibility, which may lead to a diminished experience for novice players. Eight expert game designers evaluated the tool embedded into a simple point and click game. Specifically they controlled attributes of speed, size of game elements, and amount of elements on screen associated to game targets, distractions, and feedback.  The tool allowed experts to define difficulty settings and expose patterns, which they verified. As a game, we then investigated the effect of visual motion on accessibility in a formal user study comprised of 105 participants. As a follow-up to this work, we expanded the toolset to include 8 additional attributes of motion.","WARNING: Reference 15 is very long.  Please check it. \  \ 1. A. Rodriguez and K. Steiner, “Exploring Eye Tracking for Games User Research: A case study of lessons learned,” Ann Arbor MI, 2010. \ 2. M. Seif El-Nasr and S. Yan, “Visual Attention in 3D Video Games,” presented at the SIGCHI international conference on advances in computer entertainment, Hollywood, 2006. \ 3. H. Desurvire and C. Wiberg, “User Experience Design for Inexperienced Gamers: GAP - Game Approachability Principles,” in Evaluating User Experiences in Games, London: Springer-Verlag, 2010. \ 4. R. Smith, “Helping Your Players Feel Smart: Puzzles as User Interface,” Game Developers Conference, San Francisco, 2009. \ 5. M. Seif El-Nasr, T. Vasilakos, C. Rao, and Z. Joseph, “Dynamic Intelligent Lighting for Directing Visual Attention in Interactive 3D Scenes,” IEEE Transactions on Computational Intelligence and AI in Games, vol. 1, no. 2, 2009. \ 6. B. Phillips, “Player Experience Panel: Peering into the BlackBox,” Game Developers Conference, San Francisco, 2010. \ 7. A. Drachen and A. Canossa, “Analyzing Spatial user Behavior in Computer Games using Geographic Information Systems,” presented at the MindTrek, Tampere, Finland, 2009. \ 8. J. Zupko, “System for Automated Lighting,” PhD, Pennsylvania State University, University Park, PA, 2009. \ 9. D. Milam, M. Seif El-Nasr, D. Barbosa, and L. Bartram, “Effect of Camera and Object Motion on Visual Load in 3D Games,” presented at the 10th International Conference on Entertainment Computing, Vancouver, Canada, 2011. \ 10. L. Bartram and C. Ware, “Filtering and Brushing with Motion,” Information Visualization,, vol. 1, no. 1, pp. 66–79, 2002. \ 11. J. Duncan and G. W. Humphreys, “Visual search and stimulus similarity,” Psychological Review, vol. 96, no. 3, pp. 433–458, 1989. \ 12. A. Kingstone and W. F. Bischof, “Perceptual grouping and motion coherence in visual search,” Psychological Science, vol. 10, no. 2, pp. 151– 156, 1999. \ 13. D. Milam, M. Seif El-Nasr, L. Bartram, B. Aghabeigi, F. Upton, and P. Tan, “Visual Motion Game: Design and Effects on Visual Load (in review),” presented at the Foundations of Digital Games, Raleigh, North Carolina, 2012. \ 14. R. Pagulayan, K. Keeker, F. Thomas, D. Wixon, and R. Romero, “User Centered Design in Games,” in Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies, and Emerging Applications, A. Sears and J. Jacko, Eds. New York: Lawrence Erlbaum Associates, 2008. \ 15. S. G. Hart and L. E. Staveland, “Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research,” in Human Mental Workload, A. Hancock and N. Meshkati, Eds. Amsterdam: North Holland Press, 1988. ","Game Design \ Visual Design \ Cognitive Load \ Games User Research","infile254-1.doc","infile254-2.jpg","infile254-3.mp4","Tool to adapt the visual complexity of a simple mouse-click game. Evaluated by 8 expert game designers and 105 players. Supports visual perception theories within the context of a game. \ ","Reference ID 15 was flagged as being too long. The caption text for the image references on page 4 were somehow included, so I removed these. The following is the correct text for reference 15: \  \ 15. S. G. Hart and L. E. Staveland, “Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research,” in Human Mental Workload, A. Hancock and N. Meshkati, Eds. Amsterdam: North Holland Press, 1988. ","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Screen design \ K.8.0 [Personal Computing]: General \ ","","FormatComplete","2","","Jan  9 20:28",""
"in259","A","A Handle Bar Metaphor for Virtual Object Manipulation with Mid-Air Interaction","Wooi Boon","Goh","aswbgoh@ntu.edu.sg","","","","","","Peng Song, Wooi Boon Goh, William Hutama, Chi-Wing Fu, Xiaopei Liu","Peng","","Song","song0083@e.ntu.edu.sg","Nanyang Technological University","Singapore","","Singapore","","","","","Wooi Boon","","Goh","aswbgoh@ntu.edu.sg","Nanyang Technological University","Singapore","","Singapore","","","","","William","","Hutama","hwilliam@ntu.edu.sg","Nanyang Technological University","Singapore","","Singapore","","","","","Chi-Wing","","Fu","cwfu@ntu.edu.sg","Nanyang Technological University","Singapore","","Singapore","","","","","Xiaopei","","Liu","liuxp@ntu.edu.sg","Nanyang Technological University, Singapore","Singapore","","Singapore","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 23:31",""
"in265","A","DisplayStacks: Interaction Techniques for Stacks of Flexible Thin-Film Displays","Roel","Vertegaal","roel@cs.queensu.ca","","","","","","Aneesh Tarun, Audrey Girouard, Roel Vertegaal","Aneesh","","Tarun","aneesh@cs.queensu.ca","Human Media Lab, Queen's University","Kingston","Ontario","Canada","","","","","Audrey","","Girouard","audrey_girouard@carleton.ca","Carleton University","Ottawa","Ontario","Canada","","","","","Roel","","Vertegaal","roel@cs.queensu.ca","Human Media Lab, Queen's University","Kingston","Ontario","Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 23:35",""
"in266","A","TeleHuman: Effects of 3D Perspective on Gaze and Pose Estimation with a Life-size Cylindrical Telepresence Pod","Roel","Vertegaal","roel@cs.queensu.ca","","","","","","John Bolton, Kibum Kim, Jeremy Cooperstock, Audrey Girouard, Roel Vertegaal","John","","Bolton","bolton@cs.queensu.ca","Human Media Lab, Queen's University","Kingston","Ontario","Canada","","","","","Kibum","","Kim","kibum@cs.queensu.ca","Human Media Lab, Queen's University","Kingston","Ontario","Canada","","","","","Jeremy","","Cooperstock","jer@cim.mcgill.ca","McGill University","Montreal","Quebec","Canada","","","","","Audrey","","Girouard","audrey_girouard@carleton.ca","Carleton University","Ottawa","Ontario","Canada","","","","","Roel","","Vertegaal","roel@cs.queensu.ca","Human Media Lab, Queen's University","Kingston","Ontario","Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Jan  9 23:46",""
"in267","A","DiskPlay: In-Track Navigation on Turntables","Florian","Heller","flo@cs.rwth-aachen.de","","","","","","Florian Heller, Justus Lauten, Jan Borchers","Florian","","Heller","flo@cs.rwth-aachen.de","RWTH Aachen University","Aachen","NRW","Germany","","","","","Justus","","Lauten","justus.lauten@rwth-aachen.de","RWTH Aachen University","Aachen","NRW","Germany","","","","","Jan","","Borchers","borchers@cs.rwth-aachen.de","RWTH Aachen University","Aachen","NRW","Germany","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","no","","","","","","","","","","","","2","","Feb 21 04:29",""
"in270","A","Murmur Study","Christopher","Baker","info@christopherbaker.net","inpaper270.pdf","4","letter","","","Christopher Baker","Christopher","","Baker","info@christopherbaker.net","School of the Art Institute of Chicago","Chicago","Illinois","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Christopher Baker","info@christopherbaker.net","yes","Murmur Study is an art installation that examines the rise of micro-messaging technologies such as Twitter and Facebook’s status updates. One might describe these messages as a type of digital small talk.  But unlike face to face conversations, these fleeting thoughts are accumulated, archived and digitally indexed by corporations, governments and research institutions.  While the long-term impact of these archives remains to be seen, the sheer volume of publicly accessible, personal, and often emotional expressions should give us pause.","1. Baker, Christopher. Urban Echo (2007-2009). http://christopherbaker.net/projects/urbanecho/. \ 2. Baker, Christopher. Hello World! or: How I Learned to Stop Listening and Love the Noise (2008). http://christopherbaker.net/projects/helloworld/. \ 3. Baker, Christopher. Murmur Study (2009-2012). http://christopherbaker.net/projects/murmur-study/. \ 4. Twitter. http://twitter.com. \ 5. Rubin, B., Hanson, M. Listening Post (2002). http://earstudio.com/2010/09/29/listening-post/. \ 6. Harris, J., Kamvar, S. We Feel Fine (2006). http://www.wefeelfine.org/. \ 7. Twitter Donates Entire Tweet Archive to Library of Congress. Press Release. http://www.loc.gov/today/pr/2010/10-081.html. \ 8. Fry, B., Reas, C., Processing Library for Visual Arts and Design. http://processing.org/. \ 9. Twitter REST API. https://dev.twitter.com/docs/api. \ 10. Northern Lights. http://northern.lights.mn/. \ 11. Kitchen Budapest Innovation Lab. http://www.kitchenbudapest.hu/. \ ","art; sculpture; visualization; twitter;","infile270-1.docx","infile270-2.jpg","infile270-3.mov","Murmur Study is an art installation that examines the rise of micro-messaging technologies such as Twitter and Facebook’s status updates.","Final upload.","J.5 [Arts and Humanities]: Fine Arts;","","FormatComplete","1","","Feb 25 07:58",""
"in271","A","HWD corporation - a collection of 100 re-wired joysticks from the last 30 years  of gaming culture","Roger","Ibars","roger.ibars@gmail.com","inpaper271.pdf","4","letter","","","Roger Ibars","Roger","","Ibars","roger.ibars@gmail.com","Microsoft Research Asia","Beijing","","China","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Roger Ibars","roger.ibars@gmail.com","yes","HWD (Hard-wired devices) Corporation is a collection of 100 electronic devices, each consisting of a travel alarm clock connected to a different game controller selected from the last 30 years of gaming culture. For each device a new interaction has been crafted by hard-wiring the functions of the alarm clock onto the digital switches of the controller. As a result the basic functionalities of the alarm clock – set up time, set up alarm, light on and off, alarm off - can be controlled with the joysticks. This project is a journey through the history of game controllers, to celebrate both its revolutionary successes and remarkable failures.","1. Joysticks - Eine illustrierte Geschichte der GameController 1972-2004, Gameplan, 2004 See also http://www.rogeribars.com \ ","Joystick; Game Controller; Input Device; Alarm clock; Device Art","infile271-1.docx","infile271-2.jpg","","HWD Corporation is a collection of 100 electronic devices, each consisting of an alarm clock connected to a different game controller selected from the last 30 years of gaming culture. ","Chair's comments incorporated into the final version.","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ ","","FormatComplete","1","","Feb 25 03:22",""
"in272","A","Scorelight & scoreBots","Alvaro","CASSINELLI","cassinelli.alvaro@gmail.com","inpaper272.pdf","4","letter","","","Alvaro CASSINELLI, Daito  MANABE, Stephane  PERRIN, Alexis Zerroug, Masatoshi  ISHIKAWA","Alvaro","","CASSINELLI","Alvaro_Cassinelli@ipc.i.u-tokyo.ac.jp","University of Tokyo","Tokyo","","Japan","","","","","Daito ","","MANABE","daito@rhizomatics.com","Rhyzomatics","Tokyo","Tokyo","Japan","","","","","Stephane ","","PERRIN","perrin.japan@gmail.com","Independent Artist","Tokyo","Tokyo","Japan","","","","","Alexis","","Zerroug","alexis@k2.t.u-tokyo.ac.jp","University of Tokyo","Tokyo","","Japan","","","","","Masatoshi ","","ISHIKAWA","Masatoshi_Ishikawa@ipc.i.u-tokyo.ac.jp","University of Tokyo","Tokyo","","Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Alvaro Cassinelli","cassinelli.alvaro@gmail.com","yes","""scoreLight"" and ""scoreBots"" are two experimental platforms for performative sound design and manipulation. Both are essentially synesthetic interfaces – synesthetic musical instruments - capable of translating free-hand drawings into a sonic language of beats and pitches, all in real time. While scoreLight uses a modified ""smart"" laser scanner to track the figure's relevant features (in particular contours), scoreBots rely on one or more tiny line-follower robots to do the same. ","1. A. Cassinelli, S. Perrin, and M. Ishikawa. Smart laser-scanner for 3d human-machine interface. In CHI '05, pp: 1138-1139 (2005). \ 2. G. Levin and Z. Lieberman. Sounds from shapes: audiovisual performance with hand silhouette contours in the manual input sessions. In NIME '05, pp: 115-120 (2005). \ 3. A. Cassinelli, Y. Kuribara, A. Zerroug, D. Manabe and M. Ishikawa, scoreLight: playing with a human sized laser pickup, NIME ’10, Sydney, Australia, pp:144-149 (2010) \ 4. S. Jorda, G. Geiger, M. Alonso, and M. Kaltenbrunner. The reactable: exploring the synergy between live music performance and tabletop tangible interfaces. In TEI '07, NY, pp: 139-146 (2007). \ 5. W. Kohler. Gestalt psychology. Psychological Research, 31(1):XVIII-XXX, March (1967). \ 6. Wilde, D., Cassinelli, A., Zerroug, A., Helmer, R J N., Ishikawa, M. Light Arrays: a system for extended engagement. Proc. ICDVRAT with ArtAbilitation Viña del Mar/Valparaíso, Chile. (2010). \ ","Synesthesia; sound manipulation; sound generation; tangible interface; tabletop interface; physical interaction; musical instrument; laser scanner; laser projection; line-follower robot","infile272-1.docx","infile272-2.jpg","infile272-3.wmv","""scoreLight"" and ""scoreBots"" are two experimental platforms for performative sound design and manipulation, the first using lasers and the seconds using small line-following robots (premiered at the venue). ","as discussed with chair","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Interaction Styles \ H.5.5 [Information Interfaces And Presentation]: Sound and Music Computing \ ","","FormatComplete","1","","Feb 25 07:59",""
"in273","A","Light Arrays","danielle","wilde","d@daniellewilde.com","inpaper273.pdf","4","letter","","","Danielle Wilde, Alvaro Cassinelli, Alexis Zerroug","Danielle","","Wilde","d@daniellewilde.com","independent pracititioner","Melbourne","","Australia","RMIT University","Melbourne","VIC","Australia","Alvaro","","Cassinelli","Alvaro_Cassinelli@ipc.i.u-tokyo.ac.jp","University of Tokyo","Tokyo","","Japan","","","","","Alexis","","Zerroug","alexis@k2.t.u-tokyo.ac.jp","University of Tokyo","Tokyo","","Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Danielle Wilde","d@daniellewilde.com","yes","The Light Arrays project explores the extension of the body through an array of visible light beams projecting on the environment a dynamic representation of the body, its movement and posture. Interestingly, these light cues are visible both for the user wearing the device as well as for others. The result is an experiential bridge between what we see and what we feel or know about the dynamic, moving body. The Light Arrays afford augmented proprioception, generated through the artificial visual feedback system; enhanced body interaction prompted by the interactively augmented body image (in time and space); as well as a clear visual representation of interpersonal and inter-structural | architectural space.","1. Bloomer, K.C., Moore, C.W. Body, Memory and Architecture. Yale University Press, New Haven, 1977. \ 2. Cassinelli, A., Reynolds, C., Ishikawa, M. Augmenting Spatial Awareness with Haptic Radar. ISWC, 61-64. IEEE, 2006 \ 3. Chalayan, H. Hussein Chalayan, Violette, R (ed). Rizzoli, NY (2011). \ 4. Forsythe, W. William Forsythe: Improvisation Technologies [Cd-Rom]. Hatje Cantz Publishers, Ostfildern, Germany, 1999/2000/2011. \ 5. Furniss, M. Motion Capture: An Overview Animation Journal 8:2 Spring, 2000. \ 6. Haseman, B. C. 2006. A manifesto for performative research. [onine] http://eprints.qut.edu.au/3999/ \ 7. Helmer, R., Mestrovic, M., Taylor, K., Philpot, B., Wilde, D., Farrow, D. Physiological Tracking, Wearable Interactive Systems and Human Performance. In Proc. 20th Int Conference on Artificial Reality and Telexistence, 57-62. The Virtual Reality Society of Japan, Tokyo, Japan, 2010. \ 8. Klooster, S., Overbeeke, K. Designing Products as an Integral Part of Choreography of Interaction: The Product's Form as an Integral Part of Movement. In 1st European workshop on Design and Semantics of Form and Movement, 23-35. Northumbria University, Newcastle, UK, 2005. \ 9. Marey, E. Etienne-Jules Marey (Photo Poche) Centre de la Photographie, Paris, France, 1994 \ 10. Merleau-Ponty, M. Phenomenology of Perception Routledge & Kegan Paul, London, UK 1962, 182. \ 11. Schibsted, E. LifeForm Wired 4:10 172-173 (October 1996) \ 12. Wilde, D. Extending Body & Imagination : moving to move. International Journal on Disability and Human Development 2011;10(1):31-36 ©2011 Walter de Gruyter, Berlin, New York. \ 13. Wilde, D. Swing That Thing : moving to move. The poetics of embodied engagement. PhD Diss., Monash University, Melbourne Australia with CSIRO, Australia (2011). See also http://www.daniellewilde.com \ 14. Wilde, D., Schiphorst, T., Klooster, S. Move to Design • Design to Move. A Conversation About Designing for the Body. Interactions 18, 4 ACM Press (2011). \ ","Light; embodied engagement; performative research; soft electronics; wearable technologies.","infile273-1.docx","","infile273-3.wmv","The Light Arrays extend the body through visible light beams, providing a dynamic representation of the body, movement and posture, to afford Augmented Proprioception and Enhanced body interaction","changes as per discussion with chair","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Interaction Styles, Theory and Methods, User-centered Design \ ","","FormatComplete","1","","Feb 25 03:32",""
