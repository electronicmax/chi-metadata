List of All CHI 2012 Videos (Juried) Final Submissions

"ID","Decision","Title","Contact given name","Contact family name","Contact Email","Document","Page length","Page size","Non-embedded fonts","Incomplete","Author list","Given name 1","Middle initial 1","Family name 1","Email 1","Primary Affiliation 1 - Institution","Primary Affiliation 1 - City","Primary Affiliation 1 - State or Province","Primary Affiliation 1 - Country","Secondary Affiliation (optional) 1 - Institution","Secondary Affiliation (optional) 1 - City","Secondary Affiliation (optional) 1 - State or Province","Secondary Affiliation (optional) 1 - Country","Given name 2","Middle initial 2","Family name 2","Email 2","Primary Affiliation 2 - Institution","Primary Affiliation 2 - City","Primary Affiliation 2 - State or Province","Primary Affiliation 2 - Country","Secondary Affiliation (optional) 2 - Institution","Secondary Affiliation (optional) 2 - City","Secondary Affiliation (optional) 2 - State or Province","Secondary Affiliation (optional) 2 - Country","Given name 3","Middle initial 3","Family name 3","Email 3","Primary Affiliation 3 - Institution","Primary Affiliation 3 - City","Primary Affiliation 3 - State or Province","Primary Affiliation 3 - Country","Secondary Affiliation (optional) 3 - Institution","Secondary Affiliation (optional) 3 - City","Secondary Affiliation (optional) 3 - State or Province","Secondary Affiliation (optional) 3 - Country","Given name 4","Middle initial 4","Family name 4","Email 4","Primary Affiliation 4 - Institution","Primary Affiliation 4 - City","Primary Affiliation 4 - State or Province","Primary Affiliation 4 - Country","Secondary Affiliation (optional) 4 - Institution","Secondary Affiliation (optional) 4 - City","Secondary Affiliation (optional) 4 - State or Province","Secondary Affiliation (optional) 4 - Country","Given name 5","Middle initial 5","Family name 5","Email 5","Primary Affiliation 5 - Institution","Primary Affiliation 5 - City","Primary Affiliation 5 - State or Province","Primary Affiliation 5 - Country","Secondary Affiliation (optional) 5 - Institution","Secondary Affiliation (optional) 5 - City","Secondary Affiliation (optional) 5 - State or Province","Secondary Affiliation (optional) 5 - Country","Given name 6","Middle initial 6","Family name 6","Email 6","Primary Affiliation 6 - Institution","Primary Affiliation 6 - City","Primary Affiliation 6 - State or Province","Primary Affiliation 6 - Country","Secondary Affiliation (optional) 6 - Institution","Secondary Affiliation (optional) 6 - City","Secondary Affiliation (optional) 6 - State or Province","Secondary Affiliation (optional) 6 - Country","Given name 7","Middle initial 7","Family name 7","Email 7","Primary Affiliation 7 - Institution","Primary Affiliation 7 - City","Primary Affiliation 7 - State or Province","Primary Affiliation 7 - Country","Secondary Affiliation (optional) 7 - Institution","Secondary Affiliation (optional) 7 - City","Secondary Affiliation (optional) 7 - State or Province","Secondary Affiliation (optional) 7 - Country","Given name 8","Middle initial 8","Family name 8","Email 8","Primary Affiliation 8 - Institution","Primary Affiliation 8 - City","Primary Affiliation 8 - State or Province","Primary Affiliation 8 - Country","Secondary Affiliation (optional) 8 - Institution","Secondary Affiliation (optional) 8 - City","Secondary Affiliation (optional) 8 - State or Province","Secondary Affiliation (optional) 8 - Country","Given name 9","Middle initial 9","Family name 9","Email 9","Primary Affiliation 9 - Institution","Primary Affiliation 9 - City","Primary Affiliation 9 - State or Province","Primary Affiliation 9 - Country","Secondary Affiliation (optional) 9 - Institution","Secondary Affiliation (optional) 9 - City","Secondary Affiliation (optional) 9 - State or Province","Secondary Affiliation (optional) 9 - Country","Given name 10","Middle initial 10","Family name 10","Email 10","Primary Affiliation 10 - Institution","Primary Affiliation 10 - City","Primary Affiliation 10 - State or Province","Primary Affiliation 10 - Country","Secondary Affiliation (optional) 10 - Institution","Secondary Affiliation (optional) 10 - City","Secondary Affiliation (optional) 10 - State or Province","Secondary Affiliation (optional) 10 - Country","Video Type","Contact Author Name","Contact Author Email Address","Abstract","References","Keywords","(required) Document in Source (Word, LaTeX, etc.)","(optional) Thumbnail Image","(required) Video Figure","Program Description","Presenter's Name","Presenter's email address","Summary of Changes","ACM Classification","Content Complete (AC use only)","Format Complete (Publications chair use only)","ACM General Terms (No Longer Required)","Program Number","Last Update","Notes"

"vi106","S","Supporting children with autism to participate throughout a design process","Laura","Benton","l.j.benton@bath.ac.uk","vipaper106.pdf","1","letter","","","Beate Grawemeyer, Emma Ashwin, Laura Benton, Mark Brosnan, Hilary Johnson","Beate","","Grawemeyer","b.grawemeyer@bath.ac.uk","University of Bath","Bath","","United Kingdom","","","","","Emma","","Ashwin","ela21@bath.ac.uk","University of Bath","Bath","","United Kingdom","","","","","Laura","","Benton","l.j.benton@bath.ac.uk","University of Bath","Bath","","United Kingdom","","","","","Mark","","Brosnan","pssmjb@bath.ac.uk","University of Bath","Bath","","United Kingdom","","","","","Hilary","","Johnson","H.Johnson@bath.ac.uk","University of Bath","Bath","","United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Laura Benton","l.j.benton@bath.ac.uk","A deficit in social communication is one of a number of core features of autism that can result in the exclusion of individuals with autism from the design process. Individuals with autism can be highly motivated by new technology, and the design of technologies for individuals with autism could potentially benefit from their direct input. We structured participatory design sessions using Cooperative Inquiry specifically to support the needs of individuals with autism. This video highlights how, when appropriately supported, the challenges of the social communication deficits associated with autism can be overcome and individuals with autism can take a full and active role within the design process.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Autism; participatory design; user interface design","vifile106-1.doc","vifile106-2.jpg","vifile106-3.mp4","This short film portrays a representative participatory design session involving children with autism collaborating to generate ideas for user interface characters or personas, as active participants within a design team.","Laura Benton","l.j.benton@bath.ac.uk","The video has been edited down to 75 seconds and focuses on the core message that young people with autism spectrum disorder are able to participate fully in a software design process, if the design sessions are structured in ways that support individuals to overcome social \ communication deficits.","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  User-centered design \ ","","FormatComplete","","14","Jan  6 09:11",""
"vi108","S","Haptic Lotus - A Theatre Experience for Blind and Sighted Audiences","Janet","van der Linden","j.vanderlinden@open.ac.uk","vipaper108.pdf","1","letter","","","Janet van der Linden, Terry Braun, Yvonne Rogers, Maria Oshodi, Adam Spiers, David McGoran, Rafael Cronin, Paul O'Dowd","Janet","","van der Linden","j.vanderlinden@open.ac.uk","The Open University","Milton Keynes","","United Kingdom","","","","","Terry","","Braun","terrybraun@beearts.org.uk","Braunarts","London","","United Kingdom","","","","","Yvonne","","Rogers","y.rogers@ucl.ac.uk","University College London","London","","UK","","","","","Maria","","Oshodi","extantad@btconnect.com","Extant, London, UK","London","","United Kingdom","","","","","Adam","","Spiers","adam.spiers@brl.ac.uk","Bristol Robotics Laboratory (BRL)","Bristol","","United Kingdom","","","","","David","","McGoran","davidmcgoran@gmail.com","University of the West of England","Bristol","","United Kingdom","","","","","Rafael","","Cronin","rscronin@imail.iu.edu","Indiana University","Bloomington","Indiana","United States","","","","","Paul","","O'Dowd","Paul.oDowd@brl.ac.uk","Bristol Robotics Laboratory","Bristol","","United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","j.vanderlinden@open.ac.uk","j.vanderlinden@open.ac.uk","How can new technologies be designed to facilitate comparable cultural experiences that are accessible by both blind and sighted audiences? An immersive theatre experience was designed to raise awareness and question perceptions of ‘blindness’, through enabling both sighted and blind members to experience a similar reality. We designed the Haptic Lotus, a novel device that changes its form in response to the audience’s journey through the dark. The device was deliberately designed to be suggestive rather than directive to encourage enactive exploration for both sighted and blind people. During a week of public performances in Battersea Arts Centre in London 150 sighted and blind people took part. People were seen actively probing the dark space around them and for many the Haptic Lotus provided a strong sense of reassurance in the dark. \  \ During a week of public performances in Battersea Arts Centre in London 150 sighted and blind people took part. People were seen actively probing the dark space around them and for many the Haptic Lotus provided a strong sense of reassurance in the dark. \ ","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Haptic technologies; sensory augmentation; computing for cultural experience; accessibility; blindness; immersive theatre; in the dark experience.","vifile108-1.doc","vifile108-2.jpg","vifile108-3.m4v","Can technologies facilitate comparable cultural experiences for both blind and sighted audiences? The Haptic Lotus is a device that changes its form as people walk through a dark immersive installation.","Janet van der Linden","j.vanderlinden@open.ac.uk","The video has been shortened to 75 seconds. Most of the changes are in the beginning, where interviews are cut, as the reviewers found these to be ‘boring’. ","H.5.2 [User Interfaces]: Haptic I/O \ ","","FormatComplete","","25","Jan 10 02:15",""
"vi109","S","Fast and Frugal Shopping Challenge","Vaiva","Kalnikaite","vaiva@interactables.com","vipaper109.pdf","1","letter","","","Khaled Bachour, Jon Bird, Vaiva Kalnikaite, Yvonne Rogers, Nicolas Villar, Stefan Kreitmayer","Khaled","","Bachour","khaled.bachour@gmail.com","The Open University","Milton Keynes","","United Kingdom","","","","","Jon","","Bird","jon.bird@ucl.ac.uk","UCL","London","","United Kingdom","","","","","Vaiva","","Kalnikaite","vaiva@interactables.com","Interactables","Cambridge","","United Kingdom","","","","","Yvonne","","Rogers","y.rogers@ucl.ac.uk","University College London","London","","United Kingdom","","","","","Nicolas","","Villar","nvillar@microsoft.com","Microsoft Research","Cambridge","","United Kingdom","","","","","Stefan","","Kreitmayer","s.kreitmayer@open.ac.uk","Open University","Milton Keynes","","United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Vaiva Kalnikaite","vaiva@interactables.com","There are a number of mobile shopping aids and recommender systems available, but none can be easily used for a weekly shop at a local supermarket. We present a minimal, mobile and fully functional lambent display that clips onto any shopping trolley handle, intended to nudge people when choosing what to buy. It provides salient information about the food miles for various scanned food items represented by varying lengths of lit LEDs on the handle and a changing emoticon comparing the average miles of all the products in the trolley against a social norm. A fast and frugal shopping challenge is presented, in the style of a humorous reality TV show, where the pros and cons of using various devices to help make purchase decisions are demonstrated by shoppers in a grocery store.","n/a \ ","Nudge; decision-making; persuasive technology; tangible embedded interaction; and mobile devices","vifile109-1.doc","vifile109-2.jpg","vifile109-3.mp4","A fast and frugal shopping challenge looks at the pros and cons of using various devices to help make purchase decisions in a grocery store.","Yvonne Rogers","y.rogers@ucl.ac.uk","- we have shortened the video to 75 seconds, while preserving the key message and showcasing the 'HCI innovation' quicker. \  \ - the focus of the shorter video is now on the design of the device and we introduced new sound effects to emphasize the interaction \ ","H5.2 [Information interfaces and presentation]: User Interfaces – user - centered design, evaluation /methodology, prototyping;","","FormatComplete","","19","Jan  9 22:58",""
"vi111","S","Anyone Can Sketch Vignettes!","Rubaiat Habib","Kazi","rubaiat@comp.nus.edu.sg","vipaper111.pdf","1","letter","","","Rubaiat Habib Kazi, Takeo Igarashi, Shengdong Zhao, Richard Davis, Toni-Jan Keith Monserrat","Rubaiat Habib","","Kazi","rubaiat@comp.nus.edu.sg","National University of Singapore","Singapore","","Singapore","JST ERATO Igarashi Design Interface Project","Tokyo","","Japan","Takeo","","Igarashi","takeo@acm.org","JST ERATO Igarashi Design Interface Project","Bunkyo","Tokyo","Japan","The University of Tokyo","Bunkyo","Tokyo","Japan","Shengdong","","Zhao","zhaosd@comp.nus.edu.sg","National University of Singapore","Singapore","","Singapore","","","","","Richard","","Davis","rcdavis@smu.edu.sg","Singapore Management University","Singapore","","Singapore","","","","","Toni-Jan Keith","","Monserrat","tjmonsi@gmail.com","National University of Singapore","Singapore","Singapore","Singapore","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Rubaiat Habib Kazi","rubaiat@comp.nus.edu.sg","Vignette is an interactive system that facilitates texture creation in pen-and-ink illustrations. Unlike existing systems, Vignette preserves illustrators’ workflow and style: users draw a fraction of a texture and use gestures to automatically fill regions with the texture. Our exploration of natural work-flow and gesture-based interaction was inspired by traditional way of creating illustrations. We currently support both 1D and 2D synthesis with stitching. Our system also has interactive refinement and editing capabilities to provide a higher level texture control, which helps artists achieve their desired vision. Vignette makes the process of illustration more enjoyable and that first time users can create rich textures from scratch within minutes.","1.  Kazi, R.H., Igarashi, T., Zhao, S., Davis, R., Vignette: Interactive Texture Design and Manipulation with Freeform Gestures for Pen-and-Ink Illustrations. In Proc. CHI 2012, ACM Press (2012)","Pen-and-ink illustration; sketch; vignette","vifile111-1.doc","vifile111-2.jpg","vifile111-3.mp4","Presents a sketch-based application for interactive pen-and-ink illustration. The novel interaction and workflow enables to create a wide range of paintings easily and quickly, along with preserving personal artistic style. \ ","Rubaiat Habib Kazi","rubaiat@comp.nus.edu.sg","We reduced the length of the video to 1:15 minutes.","H.5.2 [Information Interfaces And Presentation]: User Interfaces - Interaction styles;","","FormatComplete","","20","Jan  9 09:31",""
"vi112","S","Towards a Wearable Music System for Nomadic Musicians","Anders","Bouwer","andersbouwer@gmail.com","vipaper112.pdf","1","letter","","","Sharyselle Kock, Anders Bouwer, Tantra Rusiyanadi, Bayo Siregar","Sharyselle","","Kock","sharykock@gmail.com","University of Amsterdam","Amsterdam","","Netherlands","","","","","Anders","","Bouwer","andersbouwer@gmail.com","University of Amsterdam","Amsterdam","","Netherlands","","","","","Tantra","","Rusiyanadi","t.rusiyanadi@gmail.com","University of Amsterdam","Amsterdam","","Netherlands","","","","","Bayo","","Siregar","thedayafter20@hotmail.com","University of Amsterdam","Amsterdam","","Netherlands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Anders Bouwer","andersbouwer@gmail.com","This concept video shows the design of a wearable system for musicians to record their ideas while being away from their instruments, using an interactive shirt and belt. ","1. Holland, S. Learning About Harmony With Harmony Space: An Overview. In Smith, M., Wiggins G. (eds.). Music Education: An Artificial Intelligence Approach. Springer Verlag, London (1994), 24-40. ","Wearable technology; Music interaction; Gesture-based interfaces; Whole-body interaction","vifile112-1.doc","vifile112-2.jpg","vifile112-3.mp4","This concept video shows the design of a wearable system for musicians to record their ideas while being away from their instruments, using an interactive shirt and belt. ","Anders Bouwer","andersbouwer@gmail.com","As requested in the meta-review, we have shortened the video to 1:15. We agree that the pacing needed to be increased to improve the video, and we have done our best to achieve this. Regarding the scenes at the airport, however, we felt we needed to keep that element in, in order to maintain a story line.  \ As we found in interviews with (semi)-professional musicians, they often have musical ideas while they are away from their instruments and recording equipment. Therefore, being able to record musical ideas on the move was the main motivation for the design of the system, in terms of functionality, graphical design, and interaction methods. This makes it different from more (theatrical) performance-oriented systems like the systems that Laurie Anderson pioneered. Therefore, we tried to further clarify the motivation in our new version of the video.   \  \ We have made the airport scenes much shorter, and combined it with new screen texts to make the story flow better and faster. Furthermore, we have compressed many scenes and cut out many things that we felt were repeating earlier bits.  \ Unfortunately, we were not able to fix all issues, because some would have required shooting new material, for which we did not have enough time.  \  \ We thank the reviewers for their comments, and hope they are ok with the way we addressed them.  \ ","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Input devices and strategies \ H.5.5 [Information Interfaces And Presentation]: Sound and Music Computing -  Systems \ ","","FormatComplete","","15","Jan  9 09:49",""
"vi115","S","The Interactive Punching Bag","Marian","Petre","m.petre@open.ac.uk","vipaper115.pdf","1","letter","","","Marian Petre, Chris Baines, Michael Baker, Ed Copcutt, Adam Martindale, Taranjit Matharu, Max Petre Eastty","Marian","","Petre","m.petre@open.ac.uk","The Open University","Milton Keynes","","United Kingdom","","","","","Chris","","Baines","m.petre@open.ac.uk","The Open University","Milton Keynes","","United Kingdom","","","","","Michael","","Baker","m.petre@open.ac.uk","The Open University","Milton Keynes","","United Kingdom","","","","","Ed","","Copcutt","m.petre@open.ac.uk","The Open University","Milton Keynes","","United Kingdom","","","","","Adam","","Martindale","m.petre@open.ac.uk","The Open University","Milton Keynes","","United Kingdom","","","","","Taranjit","","Matharu","m.petre@open.ac.uk","The Open University","Milton Keynes","","United Kingdom","","","","","Max","","Petre Eastty","m.petre@open.ac.uk","The Open University","Milton Keynes","","United Kingdom","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Marian Petre","m.petre@open.ac.uk","The ‘interactive punching bag’ transforms a conventional punching bag into a programmable ‘smart device’ enhanced to provide various forms of stimulus and feedback (sound, lights, and displayed images). The physical characteristics of each punch are captured using impact sensors and accelerometers, and LEDs, speakers and an associated display can be used to provide different prompts and responses. Interactions are logged over time for analysis. The bag was devised as a means of investigating how to design interactions in the context of a fun, physical, familiar object. Preliminary studies suggest that users are surprised and engaged, and that first-time users spend more time in their first encounter if the bag is running an ‘unexpected’ program (e.g., giggling on impact rather than grunting). However, some users are sensitive about the nature of images and sounds associated with the bag, particularly where there is a conflict with social expectations or values. So far, the interactions that hold users’ attention are those, like the musical ‘punching bag keyboard’, that combine moderate physical activity with a creative element or an intellectual challenge. ","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Interactive punching bag; exertion games; interaction design","vifile115-1.doc","vifile115-2.jpg","vifile115-3.mov","The ‘interactive punching bag’ is a programmable device that adds sensors, sound, lights, and a display to a conventional punching bag.","Marian Petre","m.petre@open.ac.uk","The video has been shortened as required. \ Additional voice-over has been added that gives a preliminary answer to ‘What happens…’. \ The one-page extended abstract has been drafted to provide additional information about the construction of the bag and preliminary outcomes. \ ","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ ","","FormatComplete","","24","Jan  6 06:58",""
"vi117","A","Video Mediated Recruitment for Online Studies","Torben","Sko","torben.sko@gmail.com","vipaper117.pdf","1","letter","","","Torben Sko, Henry Gardner","Torben","","Sko","torben.sko@gmail.com","The Australian National University","Canberra","ACT","Australia","","","","","Henry","J","Gardner","Henry.Gardner@anu.edu.au","The Australian National University","Canberra","ACT","Australia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Torben Sko","torben.sko@gmail.com","More than ever, researchers are turning to the internet as a means to conduct HCI studies. Despite the promise of a worldwide audience, recruiting participants can still be a difficult task. In this video we discuss and illustrate that videos - through their sharable and entertaining nature - can greatly assist the recruitment process. Videos can also be a crucial part in developing an online presence, which may yield a community of followers and interested individuals. This community in turn can provide many long term benefits to the research, beyond just the recruitment phase.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","online usability testing; participant recruitment; video promotion; YouTube","vifile117-1.tex","vifile117-2.jpg","vifile117-3.mp4","We illustrate that videos can support online research by driving the recruitment process. They can also help build an online community which in turn can provide many long term benefits.","Torben Sko","torben.sko@gmail.com","Content from our other video submission was used to pad out the explanation of our own online work. The benefits of the online community was also elaborated upon, in order to make this contribution of the video clearer to follow. Many visual tweaks also occurred in order to make the visual style of the video more consistent throughout. ","H.5.2 [Information Interfaces and Presentation]: User Interfaces - Evaluation/Methodology;","","FormatComplete","","10","Jan  9 10:07",""
"vi118","A","The Design Evolution of LuminAR: A Compact and Kinetic Projected Augmented Reality Interface","Natan","Linder","linder@media.mit.edu","vipaper118.pdf","1","letter","","","Natan Linder, Pattie Maes","Natan","","Linder","linder@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","Pattie","","Maes","pattie@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Natan Linder","linder@media.mit.edu","LuminAR is a new form factor for a compact and kinetic projected augmented reality interface. This video presents the design evolution iterations of the LuminAR prototypes. In this video we document LuminAR’s design process, hardware and software implementation and demonstrate new kinetic interaction techniques. The work presented is motivated through a set of applications that explore scenarios for interactive and kinetic projected augmented reality interfaces. It also opens the door for further explorations of kinetic interaction and promotes the adoption of projected augmented reality as a commonplace user interface modality.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Augmented Reality; Kinetic Interfaces; Tangible Computing","vifile118-1.doc","vifile118-2.jpg","vifile118-3.mp4","LuminAR is kinetic projected augmented reality interface, in everyday objects, namely a light bulb and a task light. This video presents the design evolution iterations of the various LuminAR prototypes.","Natan Linder","linder@media.mit.edu","- combined LuminAR Swyp video into the main LuminAR video  \ - Per reviewer comments add more background in the beginning of the video as well as additional use cases","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Interaction styles \ ","","FormatComplete","","07","Jan  9 19:46",""
"vi122","S","Tongueduino: Hackable, High-bandwidth Sensory Augmentation","Gershon","Dublon","gershon@media.mit.edu","vipaper122.pdf","1","letter","","","Gershon Dublon, Joseph A Paradiso","Gershon","","Dublon","gershon@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","Joseph A","","Paradiso","joep@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Gershon Dublon","gershon@media.mit.edu","The tongue is known to have an extremely dense sensing resolution, as well as an extraordinary degree of neuroplasticity, the ability to adapt to and internalize new input. Research has shown that electro-tactile tongue displays paired with cameras can be used as vision prosthetics for the blind or visually impaired; users quickly learn to read and navigate through natural environments, and many describe the signals as an innate sense. However, existing displays are expensive and difficult to adapt. Tongueduino is an inexpensive, vinyl-cut tongue display designed to interface with many types of sensors besides cameras. Connected to a magnetometer, for example, the system provides a user with an internal sense of direction, like a migratory bird. Piezo whiskers allow a user to sense orientation, wind, and the lightest touch.  Through tongueduino, we hope to bring electro-tactile sensory substitution beyond the discourse of vision replacement, towards open-ended sensory augmentation that anyone can access.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","tongue display; sensory augmentation; sensory substitution; haptic display","vifile122-1.zip","vifile122-2.jpg","vifile122-3.mp4","The tongue has an extremely dense sensing resolution and extraordinary degree of neuroplasticity. Tongueduino is an electro-tactile tongue display that uses those characteristics to interface the user's body to electronic sensors.","Gershon Dublon","gershon@media.mit.edu","Most of the reviews suggested that I do more to illustrate what the tongue display is doing, and how it is mapping the sensor readings to the user's tongue. I added a segment that shows me moving through a space with my eyes closed, and included a picture-in-picture animation of the tongue display in several of the scenes.  \  \ I cut the video down to 75 seconds, removing some details while trying to focus the story to the essential elements. I responded to the criticism of the geeky scope and LED array footage  by removing about half of it. I removed all text subtitles, as requested, leaving the voiceover to tell the story. I did not include blooper takes, as one reviewer suggested I do, mostly for lack of space in the video between describing the project and illustrating some of its capabilities more clearly. ","H.5.2 [User Interfaces]: Haptic I/O;","","FormatComplete","","16","Jan 10 01:53",""
"vi124","A","Which Book Should I Pick?","Jin Wan","Park","jinpark@cau.ac.kr","vipaper124.pdf","1","letter","Verdana Helvetica,Bold","","Hyoyoung Kim, Dongseop Lee, Jin Wan Park","Hyoyoung","","Kim","greatinno@naver.com","Chung-Ang University","Seoul","","Korea, Republic of","","","","","Dongseop","","Lee","overlds@gmail.com","Chung-Ang University","Seoul","","Korea, Republic of","","","","","Jin Wan","","Park","jinpark@cau.ac.kr","Chung-Ang University","Seoul","","South Korea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Jin Wan Park","jinpark@cau.ac.kr","This video proposes readability visualization, genre visualization, and combined visualization to provide unconventional information for book selection. Data visualization was initiated for the practical purpose of delivering information, as it efficiently links visual perception and data so that readers are able to instantly recognize patterns in overcrowded data. In this interdisciplinary research we used the strength of data visualization, and this paper suggests three possible textual visualizations of a book, which may help users to find a desirable book, with the use of intuitive information out of a large volume of book data.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Data Visualization, Text Visualization, Information Aesthetics","vifile124-1.doc","vifile124-2.jpg","vifile124-3.mp4","This research suggests three possible textual visualizations of a book, which may help users to find a desirable book, with the use of intuitive information out of large book data.","Hyoyoung Kim","greatinno@naver.com","1) We make our video more slowly to give audiences enough time to read captions. \ 2) We put intro-movie in our whole video to make it clearer and more interesting. \ ","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Computer-supported cooperative work \ ","","FormatComplete","","09","Jan  9 00:39",""
"vi126","S","Plushbot: an Introduction to Computer Science","Yingdan","Huang","yingdanh@gmail.com","vipaper126.pdf","1","letter","Verdana Arial-BoldMT Verdana-Bold Verdana-Italic","","Yingdan Huang, Michael Eisenberg","Yingdan","","Huang","yingdan.huang@colorado.edu","University of Colorado at Boulder","Boulder","Colorado","United States","","","","","Michael","","Eisenberg","duck@cs.colorado.edu","University of Colorado Boulder","Boulder","Colorado","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Yingdan Huang","yingdan.huang@colorado.edu","We present the Plushbot project that focuses on providing a more motivating introduction of computer science to middle school students, employing tangible programming of plush toys as its central activity. About sixty students, ages 12-14, participated in a 7.5-week study in which they created and programmed their own plush toys. In order to achieve these, they learned and used several tools, including LilyPad Arduino, Modkit and a web-based application called Plushbot, which permits the user to integrate circuitry design with a pattern of plush toy pieces. Once a design is complete, the user can print the pattern and use it as a template for creating a plush toy. Plushbot is a system that allows children to create their own interactive plush toys with computational elements and ideas embedded.","Buechley, L. and Eisenberg, M. 2008. The LilyPad Arduino: Toward Wearable Engineering for Everyone. IEEE Pervasive Computing, 7:2, pp. 12-15. \  \ Modkit, available at: http://www.modk.it/.","Plushbot; stuffed toys; tangible computing; computer science education","vifile126-1.doc","vifile126-2.jpg","vifile126-3.mp4","Plushbot is a system that allows children to create their own interactive plush toys with computational elements and ideas embedded.","Yingdan Huang","yingdan.huang@colorado.edu","I shortened the video to 1 minute 15 seconds by: \ - speeding up the part that showed how to use the plushbot software; \ - speeding up the parts that showed printouts, pinning and cutting procedures; \ - deleting the part that showed a child is sewing (while I managed to keep 3 videos of children's activities since one reviewer likes them) \  \ I recorded the narration again to make the video sound happier. I put some subtitles to make it more clear what the plushbot application does.","H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous.  \ K.3.1 [Computers And Education]: Computer Uses in Education \ ","","FormatComplete","","18","Jan  9 22:38",""
"vi131","S","SIGCHI SPrAyCE: A Space Spray Input for Fast Shape Drawing.","Raphael Dokyun","Kim","dokyun.kim.ens@gmail.com","vipaper131.pdf","1","letter","","","Raphael Kim, Pattie Maes","Raphael","Dokyun","Kim","dokyun.kim.ens@gmail.com","MIT Media Lab Fluid Interface Group, Cambridge","Cambridge","Massachusetts","United States","ENSAM","Laval","","France","Pattie","","Maes","pattie@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Raphael Kim","dokyun.kim.ens@gmail.com","Current technological solutions that enable sharing some shape-based ideas are often time demanding and painful to use. The goal of this project is to create a new device, a new way of drawing in an intuitive way. A spray-based input is created to allow natural gestures to draw 3D objects and manipulate the drawing.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","3D; Arduino; Design; kinect; spray-based input","vifile131-1.docx","vifile131-2.jpg","vifile131-3.mp4","SPrAyce is a spray-based device allowing people to design in space. It's a new way of designing objects and shapes. ","Raphael Kim","dokyun.kim.ens@gmail.com","The video was entirely modified except the beginning (until ""Spray in Space"").","H.5.2 [Information Interfaces and Presentation (e.g., HCI)]: User Interfaces – Input devices and strategies, user-centered design, evaluation /methodology, prototyping.	","","FormatComplete","","21","Jan  4 09:17",""
"vi132","S","MAWL: Mobile Assisted Word-Learning","PRAMOD","VERMA","pramod@cs.jhu.edu","vipaper132.pdf","1","letter","","","PRAMOD VERMA","PRAMOD","","VERMA","pramod@cs.jhu.edu","Johns Hopkins University","Baltimore","Maryland","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","PRAMOD KUMAR VERMA","pramod@cs.jhu.edu","Word-learning is one of the basic steps in language \ learning. A general traditional approach for learning new \ words is to keep a dictionary and use it whenever one \ encounters a new word. This video demonstrates Mobile \ Assisted Word-Learning (MAWL)[1]: an augmented \ reality based collaborative social-networking interface for \ learning new words using a smartphone. MAWL keeps \ track and saves all textual contexts during reading process \ along with providing augmented reality-based assistance \ such as images, translation into native language, \ synonyms, antonyms, sentence usage etc. \ ","1. P. Verma. Mawl: mobile assisted word-learning. In MobileHCI ’11: Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services, pages 699–701, New York, NY, USA, 2011. ACM. \ ","Augmented Reality; Interaction Techniques; Mobile Social-Networking; Mobile Assisted \  Language Learning \ ","vifile132-1.tex","vifile132-2.jpg","vifile132-3.m4v","Word-learning is one of the basic steps in language \ learning. This video demonstrates Mobile Assisted Word-Learning \ (MAWL): An augmented reality based collaborative \ interface for learning new words using a smartphone. \ ","PRAMOD KUMAR VERMA","pramod@cs.jhu.edu","- conversion into short video","H.5.m [Information interfaces and presentation (e.g., \ HCI)]: Miscellaneous.","","FormatComplete","","26","Jan 10 14:33",""
"vi133","A","Communication Technologies for the Zombie Apocalypse: New Educational Initiatives","Jennifer","Golbeck","golbeck@cs.umd.edu","vipaper133.pdf","1","letter","","","Jennifer Golbeck","Jennifer","","Golbeck","golbeck@cs.umd.edu","University of Maryland, College Park","College Park","Maryland","United States","Human-Computer Interaction Lab","College Park","Maryland","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Jennifer Golbeck","golbeck@cs.umd.edu","The threat of the zombie apocalypse has finally begun to reach a level of popular concern, both in the media and in government organizations like the U.S. Centers for Disease Control and Prevention. The zombie apocalypse and subsequent destruction of modern communication technologies will present a unique challenge to future generations. This video describes new STEM initiatives that will enable today's children to maintain vital information links once the undead hordes are upon us.","none","communication technologies; zombies","vifile133-1.doc","","vifile133-3.mov","The zombie apocalypse will present a unique challenge as communication technologies fail. This video describes STEM initiatives that will prepare children to communicate when the undead hordes are upon us.","Jennifer Golbeck","golbeck@cs.umd.edu","minor tweaks, upload of abstract","H5.m [Information interfaces and presentation]: Miscellaneous","","FormatComplete","","01","Jan  9 13:02",""
"vi134","A","Experience ""panavi,"" Challenge to Master Professional Culinary Arts!","Daisuke","Uriu","uriu@kmd.keio.ac.jp","vipaper134.pdf","1","letter","","","Daisuke Uriu, Mizuki Namai, Satoru Tokuhisa, Ryo Kashiwagi, Masahiko Inami, Naohito Okude","Daisuke","","Uriu","uriu@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Mizuki","","Namai","mizukichen@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Satoru","","Tokuhisa","dangkang@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Ryo","","Kashiwagi","kashiwagi@toyo.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Masahiko","","Inami","inami@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Naohito","","Okude","okude@kmd.keio.ac.jp","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","Graduate School of Media Design, Keio University","Yokohama","Kanagawa","Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Daisuke Uriu","uriu@kmd.keio.ac.jp","This video introduces the user experience of ""panavi"" that supports cooking for domestic users to master professional culinary arts in their kitchens by managing temperature and pan movement properly. Utilizing a sensors-embedded frying pan wirelessly connected computer system, it analyzes sensors' data, recognizes users’ conditions, and provides the users situated navigation messages. In the video, a young lady tries to cook spaghetti Carbonara using panavi, and masters this ""difficult"" menu by enjoying cooking process. The full paper of this work is also published in CHI '12 conference proceedings.","Uriu, D., Namai, M., Tokuhisa, S., Kashiwagi, R., Inami, M., and Okude, N. panavi: Recipe medium with a sensors-embedded pan for domestic users to master professional culinary arts. Proc. CHI ’12.","Cooking; Kitchen; Interaction Design; User Experience","vifile134-1.zip","vifile134-2.jpg","vifile134-3.mp4","This video introduces the user experience of ""panavi"" that supports cooking for domestic users to master professional culinary arts in their kitchens by managing temperature and pan movement properly.","Daisuke Uriu","uriu@kmd.keio.ac.jp","English captions have been revised. ","No ACM Classifications were found.  Perhaps they are not formatted correctly?  The classifications should be formatted like this: \  \   A.1.2 [Second level descriptor]: Third level descriptor - Fourth level descriptor; \  \ with the code, then the second level descriptor in brackets, then a colon, then the third level descriptor, then a hyphen, then the fourth level descriptor, then a semicolon at the very end. \ ","","FormatComplete","","12","Jan  9 09:56",""
"vi135","A","TEROOS: A Wearable Avatar to Enhance Joint Activities (Video Preview)","Tadakazu","Kashiwabara","kashi@ayu.ics.keio.ac.jp","vipaper135.pdf","1","letter","","","Tadakazu Kashiwabara, Hirotaka Osawa, Kazuhiko Shinozawa, Michita Imai","Tadakazu","","Kashiwabara","kashi@ayu.ics.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","Hirotaka","","Osawa","osawa@ayu.ics.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","Kazuhiko","","Shinozawa","shino@atr.jp","ATR Intelligent Robotics and Communication Laboratories","Soraku-gun","Kyoto","Japan","","","","","Michita","","Imai","michita@ayu.ics.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Tadakazu Kashiwabara","kashi@ayu.ics.keio.ac.jp","This video shows a wearable avatar named TEROOS, which is mounted on the shoulder of a person. TEROOS allows the users who wear it and control it to remotely share a vision. Moreover, the avatar has an anthropomorphic face that enables the user who controls it to communicate with people that are physically around the user who wears it. We have conducted a eld test by using TEROOS and observed that the wearable avatar innovatively assisted the users to communicate during their joint activities such as route navigating, and buying goods at a shop. In addition, both users could easily identify objects that they discussed. Moreover, shop's stafs members communicated with the user controlling TEROOS and they exhibited a typical social behavior.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Wearable avatar; avatar communication; shared vision; social \ response; field test.","vifile135-1.tex","vifile135-2.jpg","vifile135-3.mp4","The video shows what communication style a wearable robot avatar offers to daily life situations. Two users can communicate by sharing their vision via the robot avatar.","Tadakazu Kashiwabara","kashi@ayu.ics.keio.ac.jp","Since PC's letter indicated that we should shorten the first scene in the video. So we shorten the duration of the first scene (about 8 second). \  \ We hope that this revision satisfies the AC's consideration. \ ","H.5.3 [Information Interfaces And Presentation]: Group and Organization Interfaces \ ","","FormatComplete","","06","Jan  8 02:54",""
"vi136","A","TimeBlocks: “Mom, can I have another block of time?”","Eiji","Hayashi","ehayashi@cs.cmu.edu","vipaper136.pdf","1","letter","","","Eiji Hayashi, Martina Rau, Zhe Han Neo, Nastasha Tan, Sriram Ramasubramanian, Eric Paulos","Eiji","","Hayashi","ehayashi@cs.cmu.edu","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","Martina","","Rau","marau@cs.cmu.edu","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","Zhe Han","","Neo","neozhehan@gmail.com","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","Nastasha","","Tan","nastasha@cmu.edu","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","Sriram","","Ramasubramanian","sramasub@andrew.cmu.edu","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","Eric","","Paulos","eric@paulos.net","Carnegie Mellon University","Pittsburgh","Pennsylvania","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Eiji Hayashi","ehayashi@cs.cmu.edu","Time is a difficult concept for parents to communicate with young children. We developed TimeBlocks, a novel tangible, playful object to facilitate communication about concepts of time with young children. TimeBlocks consists of a set of cubic blocks that function as a physical progress bar. Parents and children can physically manipulate the blocks to represent the concept of time. We evaluated TimeBlocks through a field study in which six families tried TimeBlocks for four days at their homes.  The results indicate that TimeBlocks played a useful role in facilitating the often challenging task of time-related communication between parents and children. We also report on a range of observed insightful novel uses of TimeBlocks in our study.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Tangible Interface; Design for Children","vifile136-1.docx","vifile136-2.jpg","vifile136-3.mp4","Time is a difficult concept for parents to communicate with young children. We developed TimeBlocks, a novel tangible, playful object to facilitate communication about concepts of time with young children. ","Eiji Hayashi","ehayashi@cs.cmu.edu","We made the following changes: \ - Re-record some of the scripts to make them clearer \ - Added texts to show the quotes more clearly \ - Removed the recap part in the end \ - Modified scripts in the last part to accommodate the removal \ - Changed the video size to 1152x648 considering the license of iStockPhoto images, which are included in our video.","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Interaction styles \ ","","FormatComplete","","04","Jan  9 12:25",""
"vi137","A","Pet Video Chat: Monitoring and Interacting with Dogs over Distance","Jennifer","Golbeck","golbeck@cs.umd.edu","vipaper137.pdf","1","letter","","","Jennifer Golbeck, Carman Neustaedter","Jennifer","","Golbeck","golbeck@cs.umd.edu","University of Maryland, College Park","College Park","Maryland","United States","","","","","Carman","","Neustaedter","carmster@gmail.com","Simon Fraser University","Surrey","British Columbia","Canada","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Jennifer Golbeck","golbeck@cs.umd.edu","Companies are now making video-communication systems that allow pet owners to see, and, in some cases, even interact with their pets when they are separated by distance. Such ‘doggie cams’ show promise, yet it is not clear how pet video chat systems should be designed (if at all) in order to meet the real needs of pet owners.  To investigate the potential of interactive dog cams, we then designed our own pet video chat system that augments a Skype audio-video connection with remote interaction features and evaluated it with pet owners to understand its usage.  Our results show promise for pet video chat systems that allow owners to see and interact with their pets while away. ","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","video chat; pets; dogs","vifile137-1.doc","","vifile137-3.mov","We designed a pet video chat system that augments a Skype audio-video connection with remote interaction features and evaluated it with pet owners to understand its usage.  ","Jennifer Golbeck","golbeck@cs.umd.edu","Uploaded abstract, a few minor video changes","No ACM Classifications were found.  Perhaps they are not formatted correctly?  The classifications should be formatted like this: \  \   A.1.2 [Second level descriptor]: Third level descriptor - Fourth level descriptor; \  \ with the code, then the second level descriptor in brackets, then a colon, then the third level descriptor, then a hyphen, then the fourth level descriptor, then a semicolon at the very end. \ ","","FormatComplete","","02","Jan  9 22:25",""
"vi138","A","Designing Visualizations to Facilitate Multisyllabic Speech with Children with Autism and Speech Delays","Joshua","Hailpern","joshua@hailpern.com","vipaper138.pdf","1","letter","","","Joshua Hailpern, Andrew Harris, Reed LaBotz, Brianna Birman, Karrie Karahalios, Laura DeThorne, Jim Halle","Joshua","","Hailpern","joshua@hailpern.com","University of Illinois at Urbana Champaign","Urbana","Illinois","United States","","","","","Andrew","","Harris","harris78@illinois.edu","University of Illinois at Urbana-Champaign","Urbana","Illinois","United States","","","","","Reed","","LaBotz","labotz1@illinois.edu","University of Illinois at Urbana-Champaign","Urbana","Illinois","United States","","","","","Brianna","","Birman","birman1@illinois.edu","University of Illinois at Urbana-Champaign","Urbana","Illinois","United States","","","","","Karrie","","Karahalios","kkarahal@cs.uiuc.edu","University of Illinois","Urbana","Illinois","United States","","","","","Laura","","DeThorne","lauras@illinois.edu","University of Illinois at Urbana-Champaign","Urbana","Illinois","United States","","","","","Jim","","Halle","halle@illinois.edu","University of Illinois at Urbana-Champaign","Urbana","Illinois","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Joshua Hailpern","joshua@hailpern.com","The ability of children to combine syllables represents an important developmental milestone. This ability is often delayed or impaired in a variety of clinical groups including children with autism spectrum disorders (ASD) and speech delays (SPD). This video illustrates some of the features of VocSyl, a real-time voice visualization system to shape multisyllabic speech. VocSyl was designed using the Task Centered User Interface Design methodology from the beginning to the end of the design process. Children with Autism and Speech Delays, targeted users of the software, were directly involved in the development process, thus allowing us to focus on what these children demonstrate they require.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Visualization; Autism; Children; Syllable; Speech","vifile138-1.doc","vifile138-2.jpg","vifile138-3.mp4","VocSyl is a real-time voice visualization system to help teach multisyllabic speech to children with autism and speech delays.","Karrie Karahalios","kkarahal@cs.uiuc.edu","We cut the features presented (by half, we only show 2 now), and added music per request.","H 5.2 [Information Interfaces and Presentation]: Screen design - Voice I/O;  K4.2 [Social Issues]: Assistive technologies for persons with disabilities","","FormatComplete","","03","Dec 12 02:05",""
"vi139","A","PINOKY: A Ring-like Device that Gives Movement to Any Plush Toy","Yuta","Sugiura","yuta.sugiura@gmail.com","vipaper139.pdf","1","letter","","","Yuta Sugiura, Calista Lee, Masayasu Ogata, Anusha Withana, Yasutoshi Makino, Daisuke Sakamoto, Masahiko Inami, Takeo Igarashi","Yuta","","Sugiura","yuta.sugiura@gmail.com","Keio University","Yokohama","","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","","Japan","Calista","","Lee","calistalxy@gmail.com","Keio University","Yokohama","Kanagawa","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","Tokyo","Japan","Masayasu","","Ogata","ogatite@gmail.com","Keio University","Yokohama","","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","","Japan","Anusha","","Withana","anusha@kmd.keio.ac.jp","Keio University","Yokohama","Kanagawa","Japan","","","","","Yasutoshi","","Makino","makino@sdm.keio.ac.jp","Keio University","Yokohama","","Japan","","","","","Daisuke","","Sakamoto","d.sakamoto@gmail.com","The University of Tokyo","Bunkyo","Tokyo","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","Tokyo","Japan","Masahiko","","Inami","inami@inami.info","Keio University","Tokyo","","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","","Japan","Takeo","","Igarashi","takeo@acm.org","The University of Tokyo","Bunkyo","Tokyo","Japan","JST ERATO IGARASHI Design Interface Project","Bunkyo","Tokyo","Japan","","","","","","","","","","","","","","","","","","","","","","","","","Full","Yuta Sugiura","yuta.sugiura@gmail.com","Everyone has owned or have been in contact with plush toys in their life, and plush toys play an integral part in many areas, for example in a child's growing up process, in the medical field, and as a form of communication media. In order to enhance the interaction experience with plush toys, we created the PINOKY. PINOKY is a wireless, ring-like device that can be externally attached to any plush toy as an accessory that animates the toy by moving its limbs. It is a non-intrusive device, and users can instantly convert their personal plush toys into soft robots. Currently, there are several interactions, such as letting the user control the toy remotely, or inputting the desired movement by moving the toy, and having the data recorded and played back. ","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Interactive Plush Toy; Tangible User Interface; Robots; Ubiquitous \ Computing","vifile139-1.doc","vifile139-2.jpg","vifile139-3.mp4","PINOKY is a wireless ring-like device that can be externally attached to any plush toy as an accessory that animates the toy by moving its limbs.","Yuta Sugiura","yuta.sugiura@gmail.com","We compressed more tightly in 1:30-2:12 part.","H.5.m [Information interfaces and presentation (e.g., HCI)]: Miscellaneous.","","FormatComplete","","11","Jan  9 14:32",""
"vi140","A","EyeRing: An Eye on a Finger","Suranga","Nanayakkara","suranga@sutd.edu.sg","vipaper140.pdf","1","letter","","","Suranga Nanayakkara, Roy Shilkrot, Pattie Maes","Suranga","","Nanayakkara","suranga@sutd.edu.sg","Singapore University of Technology and Design","Dover","","Singapore","MIT Media Lab","Cambridge","Massachusetts","United States","Roy","","Shilkrot","roys@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","Pattie","","Maes","pattie@media.mit.edu","MIT Media Lab","Cambridge","Massachusetts","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Suranga Nanayakkara","suranga@sutd.edu.sg","Finger-worn devices are a greatly underutilized form of interaction with the surrounding world. By putting a camera on a finger we show that many visual analysis applications, for visually impaired people as well as the sighted, prove seamless and easy. We present EyeRing, a ring mounted camera, to enable applications such as identifying currency and navigating, as well as helping sighted people to tour an unknown city or intuitively translate signage. The ring apparatus is autonomous, however our system also includes a mobile phone or computation device to which it connects wirelessly, and an earpiece for information retrieval. Finally, we will discuss how different finger worn sensors may be extended and applied to other domains.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Pointing-based Interaction; Wearable Assistive Device; Intuitive Interfaces","vifile140-1.doc","vifile140-2.jpg","vifile140-3.m4v","EYERING: a finger-worn personal assistant with  visual analysis capabilities, that aid visually impaired people as well as the sighted.","Suranga Nanayakkara","suranga@sutd.edu.sg"," The authors would like to thank the associate editor and reviewers for their valuable comments and very much appreciate their time and effort. As per AC's comments, we made the following changes to the video.  \  \ - Technical details of the software was included. \ - The computer voice was updated with clearer and louder voice. \  \ Our video has been accepted at a full video and we include the following additional information. \ - Introduction \ - Some frames showing the hardware design","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems \ I.4.8 [Image Processing And Computer Vision]: Scene Analysis \ K.4.2 [Computers And Society]: Social Issues \ ","","FormatComplete","","08","Jan  6 04:57",""
"vi141","S","WatchIt: Simple gestures for interacting with a watchstrap","Simon","PERRAULT","perrault@telecom-paristech.fr","vipaper141.pdf","1","letter","Helvetica,Bold","","Simon PERRAULT, Sylvain Malacria, Yves GUIARD, Eric Lecolinet","Simon","T","PERRAULT","perrault@telecom-paristech.fr","TELECOM ParisTech - CNRS LTCI UMR 5141","Paris","","France","","","","","Sylvain","","Malacria","sylvain@malacria.fr","TELECOM ParisTech - CNRS LTCI UMR 5141, Paris","Paris","","France","University of Canterbury","Christchurch","Canterbury","New Zealand","Yves","","GUIARD","yves.guiard@telecom-paristech.fr","TELECOM ParisTech - CNRS LTCI UMR 5141","Paris","","France","","","","","Eric","","Lecolinet","eric.lecolinet@enst.fr","Telecom ParisTech – CNRS LTCI UMR 5141","Paris","","France","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Simon Perrault","simon.perrault@telecom-paristech.fr","We present WatchIt, a new interaction technique for wristwatch computers, a category of devices that badly suffers from a scarcity of input surface area. WatchIt considerably increases this surface by extending it from the touch screen to the wristband. The video shows a mockup of how simple gestures on the external and/or internal bands may allow the user to scroll a list (one-finger slide), to select an item (tap), and to set a continuous parameter like the volume of music playing (two-finger slide), avoiding the drawback of screen occlusion by the finger. Also shown is the prototype we are currently using to investigate the usability of our new interaction technique.","No references","Digital jewelry; wearable computing; watch, watchstrap; watchband; watch bracelet; input","vifile141-1.doc","vifile141-2.png","vifile141-3.mp4","WatchIt is a new way to interact with interactive wristwatch. The watchband bracelet becomes interactive, thus avoiding the fat finger problem and occlusion.","Eric Lecolinet","eric.lecolinet@telecom-paristech.fr","The reviewers of the video asked for the following changes: \ 1- Due to the acceptance format, the video is now 30 seconds shorter (1:14). \ 2- We extended the music track to the end of the video instead of the end of the mockup section. \ 3- We checked the video on a lot of machines and it seemed smooth.","H.5.2 [Information Interfaces And Presentation]: User Interfaces -  Input Devices and Strategies \ ","","FormatComplete","","23","Jan  9 13:06",""
"vi142","A","Ferro Tale: Electromagnetic Animation Interface","Nan","Zhao","nanzhao@mit.edu","vipaper142.pdf","1","letter","","","Nan Zhao, Xiang Cao, Jaturont Jamigranont","Nan","","Zhao","nanzhao@mit.edu","Microsoft Research Asia","Beijing","","China","MIT Media Lab","Cambridge","Massachusetts","United States","Xiang","","Cao","xiangc@microsoft.com","Microsoft Research Asia","Beijing","","China","","","","","Jaturont","","Jamigranont","jaturontj@gmail.com","Massachusetts College of Art and Design","Boston","Massachusetts","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Nan Zhao","nanzhao@media.mit.edu","In this video we demonstrate the idea and the prototype \ of an electromagnetic animation interface, ferro tale. \  \ Ferromagnetic particles, such as iron ﬁlings, have very \ fascinating characteristics. Therefore they are widely used \ in art, education and as toys. Besides their potential to \ enable visual and tactile feedback and to be used as a \ medium for high resolution tangible input, peoples natural \ desire to engage and explore the behavior of this material \ makes them interesting for HCI. \  \ Inspired by the expressiveness of sand drawing, we want to \ explore ways to use an electromagnetic array, camera \ feedback, computer vision, and ferromagnetic particles to \ produce animations. The currently used magnetic \ actuation device consists of a 3 by 3 coil array. Even with \ such a small number of actuators, we are able \ demonstrate several animation examples.","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Electromagnetic interface; actuated display; animation \ tool; haptic display","vifile142-1.zip","vifile142-2.jpg","vifile142-3.mp4","Inspired by the expressiveness of sand drawing, we explore ways to use an electromagnetic array, camera feedback, computer vision, and ferromagnetic particles to produce animations.","Nan Zhao","nanzhao@media.mit.edu","We compressed the credits to 10 seconds and edited the entire video so that it is 2min18sec. We changed the middle part that describes user interaction and technical performance to make the movie faster paced. ","B.4.2 [Input/output And Data Communications]: Input/output Devices \ ","","FormatComplete","","13","Jan 10 02:09",""
"vi145","A","An Augmented Multi-touch System Using Hand and Finger Identification","Dominik","Kaeser","dpk@pixar.com","vipaper145.pdf","1","letter","","","Peter Kung, Dominik Kaeser, Craig Schroeder, Tony DeRose, Donald Greenberg, Kenrick Kin","Peter","","Kung","pfk5@cornell.edu","Cornell University","Ithaca","New York","United States","","","","","Dominik","","Kaeser","dpk@pixar.com","Pixar Animation Studios","Emeryville","California","United States","","","","","Craig","","Schroeder","cas43@cs.stanford.edu","University of California, Los Angeles","Los Angeles","California","United States","","","","","Tony","","DeRose","derose@pixar.com","Pixar Animation Studios","Emeryville","California","United States","","","","","Donald","","Greenberg","dpg@graphics.cornell.edu","Cornell University","Ithaca","New York","United States","","","","","Kenrick","","Kin","kenrick.kin@gmail.com","Pixar Animation Studios","Emeryville","California","United States","University of California, Berkeley","Berkeley","California","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Full","Dominik Kaeser","dominik.kaeser@gmail.com","With the advent of devices such as smart phones and tablet computers, multi-touch applications are rapidly becoming commonplace. However, existing multi-touch sensors are not able to report which finger, or which hand, is responsible for each of the touches. To overcome this deficiency we introduce a multi-touch system that is capable of identifying the finger and hand corresponding to each touch. The system consists of a commercially available capacitive multi-touch display augmented with an infrared depth camera mounted above the surface of the display. We performed a user study to measure the accuracy of the system and found that our algorithm was correct on 92.7% of the trials.","None","Multitouch; Finger Identification; User Interfaces; Camera-based interaction; Hand tracking","vifile145-1.tex","vifile145-2.jpg","vifile145-3.mp4","We introduce a multitouch system capable of identifying the finger and hand corresponding to each touch, and show how we use it in a multitouch 3D authoring tool.","Kenrick Kin","kenrick@pixar.com","We cut the video down to less than 2 minutes, as the reviewers requested. We would like to thank the reviewers for their efforts.","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ ","","FormatComplete","","05","Jan  8 19:44",""
"vi147","S","Pen-in-Hand Command: NUI for Real-Time Strategy eSports","William","Hamilton","luin.uial@gmail.com","vipaper147.pdf","1","letter","","","William Hamilton, Andruid Kerne, Jonathan Moeller","William","","Hamilton","luin.uial@gmail.com","Interface Ecology Lab, Texas A&M University","College Station","Texas","United States","","","","","Andruid","","Kerne","andruid@ecologylab.net","Interface Ecology Lab, Texas A&M University","College Station","Texas","United States","","","","","Jonathan","","Moeller","jmoeller@gmail.com","Interface Ecology Lab","College Station","Texas","United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","William Hamilton","bill@ecologylab.net","Electronic Sports (eSports) is the professional play and spectating of digital games. Real-time strategy games are a form of eSport that require particularly high- performance and precise interaction. Prior eSports HCI has been keyboard and mouse based. We investigate the real-time strategy eSports context to design novel interactions with embodied modalities, because of its rigorous needs and requirements, and the centrality of the human-computer interface as the medium of game mechanics. To sense pen + multi-touch interaction, we augment a Wacom Cintiq with a ZeroTouch multi-finger sensor. We used this modality to design new pen + touch interaction for play in real-time strategy eSports.","1. Moeller, J., Kerne, A. 2012 ZeroTouch: An Optical Multi-Touch and Free-Air Interaction Architecture. Proc. CHI 2012. In Press. ","eSports; embodied interaction; real-time strategy games; multi-touch + pen","vifile147-1.pages","vifile147-2.jpg","vifile147-3.mp4","We investigate the design of embodied interaction in the context of real-time strategy eSports. Specifically, we look at pen + multi-touch interaction using a Wacom Cintiq augmented with a ZeroTouch sensor.","Bill Hamilton","bill@ecologylab.net","The video has been edited down to fit in the short video category. There is very little downtime in the progression now. No sound effects were added as these were not recorded in the original shooting, would be hard to match up with the video, and would not significantly alter the information content of the video.","H.5.2 [Information Interfaces And Presentation]: User Interfaces \ ","","FormatComplete","","17","Jan  9 14:15",""
"vi150","S","Looking Glass: A Field Study on Noticing Interactivity of a Shop Window","Jörg","Müller","joerg.mueller@tu-berlin.de","vipaper150.pdf","1","letter","","","Jörg Müller, Robert Walter, Gilles Bailly, Michael Nischt, Florian Alt","Jörg","","Müller","joerg.mueller@tu-berlin.de","Quality and Usability Lab, Telekom Innovation Laboratories, TU Berlin","Berlin","","Germany","","","","","Robert","","Walter","rwalter83@googlemail.com","Quality and Usability Lab, Telekom Innovation Laboratories, TU Berlin","Berlin","","Germany","","","","","Gilles","","Bailly","gillesbailly1@gmail.com","Quality and Usability Lab, Telekom Innovation Laboratories, TU Berlin","Berlin","","Germany","","","","","Michael","","Nischt","michael.nischt@tu-berlin.de","Quality and Usability Lab, Telekom Innovation Laboratories, TU Berlin","Berlin","","Germany","","","","","Florian","","Alt","florian.alt@vis.uni-stuttgart.de","University of Stuttgart","Stuttgart","","Germany","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Short","Jörg Müller","joerg.mueller@tu-berlin.de","In this paper we present our findings from a lab and a field study investigating how passers-by notice the interactivity of public displays. We designed an interactive installation that uses visual feedback to the incidental movements of passers-by to communicate its interactivity. In the field study, three displays were installed during three weeks in shop windows, and data about 502 interaction sessions were collected. Our observations show: (1) Significantly more passers-by interact when immediately showing the mirrored user image (+90%) or silhouette (+47%) compared to a traditional attract sequence with call-to-action. (2) Passers-by often notice inter- activity late and have to walk back to interact (the landing effect). (3) If somebody is already interacting, others begin interaction behind the ones already interacting, forming multiple rows (the honeypot effect). ","ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \ ","Interactivity; Noticing Interactivity; Public Displays; User \ Representation","vifile150-1.doc","vifile150-2.jpg","vifile150-3.mp4","This video shows how passers-by interact with the Looking Glass, an interactive shop window.","Jörg","Müller","Shortened.","H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous.","","FormatComplete","","22","Jan  9 05:57",""
